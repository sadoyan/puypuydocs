{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PuyPuy Metrics collector tool, which works with multiple time series databases . OpenTSDB KairosDB InfluxDB Prometheus Graphite It uses REST and Pickle protocols with bulk uploads to talk to endpoints, so make sure your endpoint i configured properly. Main idea behind PuyPuyis simplicity and less as possible dependencies, it is tested on Debian and Ubuntu systems, but should work on any Linux system. To install PuyPuyjust clone our repository. Base program requires only pycurl as external dependency. On Debian/Ubuntu you can install it via apt-get apt-get install python3-pycurl On RedHat systems: yum install python3-pycurl Via python pip: pip3 install pycurl Some checks requires additional modules for example check_mysql requires MySQLdb. So make sure to install it before using MySQL check Debian/Ubuntu : apt-get install python3-mysqldb Python pip: pip3 install MySQL-python Make your changes if needed in config.ini and run ./puypuy.sh start Python daemon process will start, run all python scripts from checks_available directory as well as all check_* files scripts_available directory. Main Config PuyPuy uses simple ini files to configure main service and all checks. Configs are splitted into sections. Section [SelfConfig] contains base config parameters like checks interval, log/pid file location as well as some basic tags. [SelfConfig] check_period_seconds = 5 log_file = /var/log/puypuy.log pid_file = /var/run/puypuy.pid cluster_name = PuyPuy host_group = workers tmpdir = /tmp/puypuy_tmp cluster_name and host_group are placeholders for tags for better manageability. In section [TSDB] you should set correct backend and uri. Back End Config To make it run you need to change uuid to one which you got during registration and start PuyPuy, optionally change run user from puypuy.sh and start ./puypuy.sh start PuyPuycan for with number of other open source backends. All configs are done at TSDB section of config.ini. Only one TSDB can be set at once, so make sure that all other are ether commented out or deleted from config file. OpenTSDB [TSDB] tsdtype : OpenTSDB address : http://opentsdb_address:4242 datapoints : /api/put user : netangels pass : bololo auth : False As PuyPuysend metrics with small bulks you should enable chunked requests in opentsdb.conf tsd.http.request.enable_chunked = true OpenTSDB is designed to run in private networks and does not supports authentication, but if you want it to be public available, you can use any proxy server like Haproxy or NginX with basic auth enabled and configure credentials in config.ini. If you do not need authentication, just set auth param to False and some placeholders as user/pass. Do not delete user/pass/auth parameters. KairosDB [TSDB] address : http://kairosdb_address:8088 datapoints : /api/v1/datapoints user : netangels pass : bololo auth : True tsdtype : KairosDB Enable or disable auth: in accordance to your KairosDB setup InfluxDB [TSDB] address : http://influxdb_address:8086 auth : False user : netangels pass : bololo database : test tsdtype : InfluxDB Enable or disable authentication. Prometheus Prometheus' configuration does not need any special parameters, so just enabling it is enough. tsdtype: Prometheus Graphite Carbon [TSDB] address : carbon_host:2004 user : netangels pass : bololo auth : false tsdtype : Carbon PuyPuyuses Carbon pickle, default port is 2004 PuyPuy is completely stateless, so if you want to scale Backend, you can use any load balancing mechanism including DNS Round Robin. For all types of REST Backens (OpenTSDB, KairosDB, InfluxDB) config fields user/pass are mandatory even if you do not user authentication at backend. So Do not delete authentication parameters , just write something meaningless and use it as placeholder. Configure modules By default, all checks are disabled . To enable check you need to create symlink or copy check module from OE-AGENT_HOME/checks_available to OE-AGENT_HOME/checks_enable checks-available cd $OE-AGENT_HOME/checks_enabled ln -s ../checks_available/check_cpustats.py ./ ../puypuy.sh restart Some checks need to be configured before you can use it, for example check_nginx.py needs to know NginX status url and username password if authentication on NginX status is enabled. All config files are located in conf directory. conf/webservers.ini is where check_nginx.py will look for configuration parameters. [NginX] address : http://127.0.0.1:8888 stats : /nginx_status auth : True user : netangels pass : bololo Some checks depend on non-standard python modules, like check_mysql.py depends on MySQL-python , so be sure to install all dependent modules before running checks. information about modules that should be installed before using checks are inside module files as comments. head checks - available / check_mysql . py '' ' This check required Python MySQLDB, On Debian like systems do apt-get install python3-mysqldb or pip3 install MySQL-python '' ' Create own python module Create file in checks_enabled directory with name check_checkname.py, inside script import lib.basecheck and subclass Check inherited from lib.basecheck.CheckBase . in subclass you should have function precheck, where your actual check should leave. Example below demonstrates how you can send single metric with random value from 100 to 200 using custom module Create scripts which which send metrics as it comes : import lib.puylogger import lib.basecheck import random check_type = 'system' class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : value = random . randint ( 100 , 200 ) self . local_vars . append ({ 'name' : 'my_check_name' , 'timestamp' : self . timestamp , 'value' : value , 'check_type' : check_type }) except Exception as e : lib . puylogger . print_message ( __name__ + ' Error : ' + str ( e )) pass This will import needed libs to generate and send to time series server needed json files, so you do not have to deal with generating and pushing it manually. Create scripts which calculates value rates : import lib.puylogger import lib.basecheck import random check_type = 'system' class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : value = random . randint ( 100 , 200 ) rated = self . rate . record_value_rate ( 'my_check_name' , value , self . timestamp ) self . local_vars . append ({ 'name' : 'my_check_name' , 'timestamp' : self . timestamp , 'value' : rated , 'check_type' : check_type }) except Exception as e : lib . puylogger . print_message ( __name__ + ' Error : ' + str ( e )) pass Create custom non python module To run custom script like Bash, Perl etc.. Create scripts in format check_name.extension in folder scripts_enabled. All is needed from custom is to system out values in right order, Below is sample Bash scripts, which generates random number and send to collector for graphing: Make sure to have check_style parameter (stack/rate). This is for telling main program if it should calculate value rates or just push data as it comes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/bin/bash myvalue = $RANDOM mytype = random_gen check_type = my_bash_random check_style = stack myvalue2 = $RANDOM mytype2 = random_gen2 check_type2 = my_bash_random2 check_style2 = rate echo $mytype $myvalue $check_type $check_style echo -n $mytype2 $myvalue2 $check_type2 $check_style2 import lib.getconfig import lib.pushdata import lib.basecheck warn_level = int ( lib . getconfig . getparam ( 'System Thresholds' , 'load_high' )) crit_level = int ( lib . getconfig . getparam ( 'System Thresholds' , 'load_severe' )) check_type = 'system' reaction = - 3 class Check ( lib . basecheck . CheckBase ): def precheck ( self ): cpucount = 0 procstats = open ( \"/proc/stat\" , \"r\" ) for line in procstats : if 'cpu' in line : cpucount += 1 cpucount -= 1 procstats . close () try : loadavg = open ( \"/proc/loadavg\" , \"r\" ) proc_loadavg = loadavg . readline () . split () curr_level = float ( proc_loadavg [ 0 ]) * 100 / cpucount if curr_level < warn_level : health_value = 0 err_type = 'OK' health_message = err_type + ': System Load average is at ' + str ( curr_level ) + ' percent of available resources' self . jsondata . send_special ( \"Load-Average\" , self . timestamp , health_value , health_message , err_type ) if warn_level <= curr_level < crit_level : health_value = 8 err_type = 'WARNING' health_message = err_type + ': System Load average is at ' + str ( curr_level ) + ' percent of available resources' self . jsondata . send_special ( \"Load-Average\" , self . timestamp , health_value , health_message , err_type ) if curr_level >= crit_level : health_value = 16 err_type = 'ERROR' health_message = err_type + ': System Load average is at ' + str ( curr_level ) + ' percent of available resources' self . jsondata . send_special ( \"Load-Average\" , self . timestamp , health_value , health_message , err_type ) self . local_vars . append ({ 'name' : 'sys_load_1' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 0 ]}) self . local_vars . append ({ 'name' : 'sys_load_5' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 1 ], 'reaction' : reaction }) self . local_vars . append ({ 'name' : 'sys_load_15' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 2 ], 'reaction' : reaction }) loadavg . close () except Exception as e : lib . pushdata . print_error ( __name__ , ( e )) pass","title":"Home"},{"location":"#puypuy","text":"Metrics collector tool, which works with multiple time series databases . OpenTSDB KairosDB InfluxDB Prometheus Graphite It uses REST and Pickle protocols with bulk uploads to talk to endpoints, so make sure your endpoint i configured properly. Main idea behind PuyPuyis simplicity and less as possible dependencies, it is tested on Debian and Ubuntu systems, but should work on any Linux system. To install PuyPuyjust clone our repository. Base program requires only pycurl as external dependency. On Debian/Ubuntu you can install it via apt-get apt-get install python3-pycurl On RedHat systems: yum install python3-pycurl Via python pip: pip3 install pycurl Some checks requires additional modules for example check_mysql requires MySQLdb. So make sure to install it before using MySQL check Debian/Ubuntu : apt-get install python3-mysqldb Python pip: pip3 install MySQL-python Make your changes if needed in config.ini and run ./puypuy.sh start Python daemon process will start, run all python scripts from checks_available directory as well as all check_* files scripts_available directory.","title":"PuyPuy"},{"location":"#main-config","text":"PuyPuy uses simple ini files to configure main service and all checks. Configs are splitted into sections. Section [SelfConfig] contains base config parameters like checks interval, log/pid file location as well as some basic tags. [SelfConfig] check_period_seconds = 5 log_file = /var/log/puypuy.log pid_file = /var/run/puypuy.pid cluster_name = PuyPuy host_group = workers tmpdir = /tmp/puypuy_tmp cluster_name and host_group are placeholders for tags for better manageability. In section [TSDB] you should set correct backend and uri.","title":"Main Config"},{"location":"#back-end-config","text":"To make it run you need to change uuid to one which you got during registration and start PuyPuy, optionally change run user from puypuy.sh and start ./puypuy.sh start PuyPuycan for with number of other open source backends. All configs are done at TSDB section of config.ini. Only one TSDB can be set at once, so make sure that all other are ether commented out or deleted from config file.","title":"Back End Config"},{"location":"#opentsdb","text":"[TSDB] tsdtype : OpenTSDB address : http://opentsdb_address:4242 datapoints : /api/put user : netangels pass : bololo auth : False As PuyPuysend metrics with small bulks you should enable chunked requests in opentsdb.conf tsd.http.request.enable_chunked = true OpenTSDB is designed to run in private networks and does not supports authentication, but if you want it to be public available, you can use any proxy server like Haproxy or NginX with basic auth enabled and configure credentials in config.ini. If you do not need authentication, just set auth param to False and some placeholders as user/pass. Do not delete user/pass/auth parameters.","title":"OpenTSDB"},{"location":"#kairosdb","text":"[TSDB] address : http://kairosdb_address:8088 datapoints : /api/v1/datapoints user : netangels pass : bololo auth : True tsdtype : KairosDB Enable or disable auth: in accordance to your KairosDB setup","title":"KairosDB"},{"location":"#influxdb","text":"[TSDB] address : http://influxdb_address:8086 auth : False user : netangels pass : bololo database : test tsdtype : InfluxDB Enable or disable authentication.","title":"InfluxDB"},{"location":"#prometheus","text":"Prometheus' configuration does not need any special parameters, so just enabling it is enough. tsdtype: Prometheus","title":"Prometheus"},{"location":"#graphite-carbon","text":"[TSDB] address : carbon_host:2004 user : netangels pass : bololo auth : false tsdtype : Carbon PuyPuyuses Carbon pickle, default port is 2004 PuyPuy is completely stateless, so if you want to scale Backend, you can use any load balancing mechanism including DNS Round Robin. For all types of REST Backens (OpenTSDB, KairosDB, InfluxDB) config fields user/pass are mandatory even if you do not user authentication at backend. So Do not delete authentication parameters , just write something meaningless and use it as placeholder.","title":"Graphite Carbon"},{"location":"#configure-modules","text":"By default, all checks are disabled . To enable check you need to create symlink or copy check module from OE-AGENT_HOME/checks_available to OE-AGENT_HOME/checks_enable checks-available cd $OE-AGENT_HOME/checks_enabled ln -s ../checks_available/check_cpustats.py ./ ../puypuy.sh restart Some checks need to be configured before you can use it, for example check_nginx.py needs to know NginX status url and username password if authentication on NginX status is enabled. All config files are located in conf directory. conf/webservers.ini is where check_nginx.py will look for configuration parameters. [NginX] address : http://127.0.0.1:8888 stats : /nginx_status auth : True user : netangels pass : bololo Some checks depend on non-standard python modules, like check_mysql.py depends on MySQL-python , so be sure to install all dependent modules before running checks. information about modules that should be installed before using checks are inside module files as comments. head checks - available / check_mysql . py '' ' This check required Python MySQLDB, On Debian like systems do apt-get install python3-mysqldb or pip3 install MySQL-python '' '","title":"Configure modules"},{"location":"#create-own-python-module","text":"Create file in checks_enabled directory with name check_checkname.py, inside script import lib.basecheck and subclass Check inherited from lib.basecheck.CheckBase . in subclass you should have function precheck, where your actual check should leave. Example below demonstrates how you can send single metric with random value from 100 to 200 using custom module Create scripts which which send metrics as it comes : import lib.puylogger import lib.basecheck import random check_type = 'system' class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : value = random . randint ( 100 , 200 ) self . local_vars . append ({ 'name' : 'my_check_name' , 'timestamp' : self . timestamp , 'value' : value , 'check_type' : check_type }) except Exception as e : lib . puylogger . print_message ( __name__ + ' Error : ' + str ( e )) pass This will import needed libs to generate and send to time series server needed json files, so you do not have to deal with generating and pushing it manually. Create scripts which calculates value rates : import lib.puylogger import lib.basecheck import random check_type = 'system' class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : value = random . randint ( 100 , 200 ) rated = self . rate . record_value_rate ( 'my_check_name' , value , self . timestamp ) self . local_vars . append ({ 'name' : 'my_check_name' , 'timestamp' : self . timestamp , 'value' : rated , 'check_type' : check_type }) except Exception as e : lib . puylogger . print_message ( __name__ + ' Error : ' + str ( e )) pass","title":"Create own python module"},{"location":"#create-custom-non-python-module","text":"To run custom script like Bash, Perl etc.. Create scripts in format check_name.extension in folder scripts_enabled. All is needed from custom is to system out values in right order, Below is sample Bash scripts, which generates random number and send to collector for graphing: Make sure to have check_style parameter (stack/rate). This is for telling main program if it should calculate value rates or just push data as it comes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/bin/bash myvalue = $RANDOM mytype = random_gen check_type = my_bash_random check_style = stack myvalue2 = $RANDOM mytype2 = random_gen2 check_type2 = my_bash_random2 check_style2 = rate echo $mytype $myvalue $check_type $check_style echo -n $mytype2 $myvalue2 $check_type2 $check_style2 import lib.getconfig import lib.pushdata import lib.basecheck warn_level = int ( lib . getconfig . getparam ( 'System Thresholds' , 'load_high' )) crit_level = int ( lib . getconfig . getparam ( 'System Thresholds' , 'load_severe' )) check_type = 'system' reaction = - 3 class Check ( lib . basecheck . CheckBase ): def precheck ( self ): cpucount = 0 procstats = open ( \"/proc/stat\" , \"r\" ) for line in procstats : if 'cpu' in line : cpucount += 1 cpucount -= 1 procstats . close () try : loadavg = open ( \"/proc/loadavg\" , \"r\" ) proc_loadavg = loadavg . readline () . split () curr_level = float ( proc_loadavg [ 0 ]) * 100 / cpucount if curr_level < warn_level : health_value = 0 err_type = 'OK' health_message = err_type + ': System Load average is at ' + str ( curr_level ) + ' percent of available resources' self . jsondata . send_special ( \"Load-Average\" , self . timestamp , health_value , health_message , err_type ) if warn_level <= curr_level < crit_level : health_value = 8 err_type = 'WARNING' health_message = err_type + ': System Load average is at ' + str ( curr_level ) + ' percent of available resources' self . jsondata . send_special ( \"Load-Average\" , self . timestamp , health_value , health_message , err_type ) if curr_level >= crit_level : health_value = 16 err_type = 'ERROR' health_message = err_type + ': System Load average is at ' + str ( curr_level ) + ' percent of available resources' self . jsondata . send_special ( \"Load-Average\" , self . timestamp , health_value , health_message , err_type ) self . local_vars . append ({ 'name' : 'sys_load_1' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 0 ]}) self . local_vars . append ({ 'name' : 'sys_load_5' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 1 ], 'reaction' : reaction }) self . local_vars . append ({ 'name' : 'sys_load_15' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 2 ], 'reaction' : reaction }) loadavg . close () except Exception as e : lib . pushdata . print_error ( __name__ , ( e )) pass","title":"Create custom non python module"},{"location":"agent/activemq/","text":"Apache ActiveMQ is a popular and powerful open source messaging and Integration Patterns server. It exposes its performance metrics via Jolokia agent out of the box. All you need is to configure Agent with appropriate parameters and start it. By Default Apache ActiveMQ sends metrics via 0.0.0.0:8161/api/jolokia/read and uses admin : admin as user/pass. So if default configuration is not changed Agent will work without extra config. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_activemq.py ./ Configure [ActiveMQ] stats : http://127.0.0.1:8161/api/jolokia/read brokername : localhost user : admin pass : admin auth : True If you have changed default configuration of Apache ActiveMQ , pleas make sure that all params in Agent config matches it. Especially on clustered installations, you will need to change brokername: localhost with appropriate BrokerName of your ActiveMQ instance. Provides Name Description Type Unit activemq_daemonthreadcount Amount if running Java daemon threads current None activemq_heap_committed Java heap committed memory current Bytes activemq_heap_max Java heap max memory current Bytes activemq_heap_used Java heap used memory current Bytes activemq_memorypercentusage ActiveMQ used memory percentage current Percent activemq_nonheap_committed Java non heap committed memory current Bytes activemq_nonheap_max Java non heap max memory current Bytes activemq_nonheap_used Java non heap used memory current Bytes activemq_peakthreadcount Peak amount of running Java threads current None activemq_storepercentusage Percentage os storage usage current Percent activemq_threadcount Amount of running Java non daemon threads current None activemq_totalconnectionscount Active connections count current None activemq_totalconsumercount Active consumers count current None activemq_totaldequeuecount Active dequeues count current None activemq_totalenqueuecount Active enqueues count current None activemq_totalmessagecount Current messages count current None activemq_totalproducercount Active producers count current None activemq_{cms/g1_old}_collectioncount CMS or G1 Old gen collections count counter None activemq_{cms/g1_old}_collectiontime CMS or G1 Old gen collections time rate Milliseconds activemq_{cms/g1_old}_lastgcinfo CMS or G1 Old gen last GC info current Milliseconds activemq_{parneq/g1_young}_collectioncount ParNew or G1 Young gen collections count counter None activemq_{parneq/g1_young}_collectiontime ParNew or G1 Young gen collections time rate Milliseconds activemq_{parneq/g1_young}_lastgcinfo ParNew or G1 Young gen last GC info current Milliseconds","title":"ActiveMQ"},{"location":"agent/activemq/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_activemq.py ./","title":"Install"},{"location":"agent/activemq/#configure","text":"[ActiveMQ] stats : http://127.0.0.1:8161/api/jolokia/read brokername : localhost user : admin pass : admin auth : True If you have changed default configuration of Apache ActiveMQ , pleas make sure that all params in Agent config matches it. Especially on clustered installations, you will need to change brokername: localhost with appropriate BrokerName of your ActiveMQ instance.","title":"Configure"},{"location":"agent/activemq/#provides","text":"Name Description Type Unit activemq_daemonthreadcount Amount if running Java daemon threads current None activemq_heap_committed Java heap committed memory current Bytes activemq_heap_max Java heap max memory current Bytes activemq_heap_used Java heap used memory current Bytes activemq_memorypercentusage ActiveMQ used memory percentage current Percent activemq_nonheap_committed Java non heap committed memory current Bytes activemq_nonheap_max Java non heap max memory current Bytes activemq_nonheap_used Java non heap used memory current Bytes activemq_peakthreadcount Peak amount of running Java threads current None activemq_storepercentusage Percentage os storage usage current Percent activemq_threadcount Amount of running Java non daemon threads current None activemq_totalconnectionscount Active connections count current None activemq_totalconsumercount Active consumers count current None activemq_totaldequeuecount Active dequeues count current None activemq_totalenqueuecount Active enqueues count current None activemq_totalmessagecount Current messages count current None activemq_totalproducercount Active producers count current None activemq_{cms/g1_old}_collectioncount CMS or G1 Old gen collections count counter None activemq_{cms/g1_old}_collectiontime CMS or G1 Old gen collections time rate Milliseconds activemq_{cms/g1_old}_lastgcinfo CMS or G1 Old gen last GC info current Milliseconds activemq_{parneq/g1_young}_collectioncount ParNew or G1 Young gen collections count counter None activemq_{parneq/g1_young}_collectiontime ParNew or G1 Young gen collections time rate Milliseconds activemq_{parneq/g1_young}_lastgcinfo ParNew or G1 Young gen last GC info current Milliseconds","title":"Provides"},{"location":"agent/cassandra/","text":"Apache Cassandra is massively scalable Open-Source NoSQL database, initially created by Facebook for their messaging system and it is opensource and contributed to Apache Software Foundation. Cassandra's native way of matrics collection is via JMX, but we prefered to use a great project, named Jolokia to collect metrics from Cassandra. As the matter of fact we use Jolokia very actively and we are very thankful them for creating such a great tool. Cassandra Jolokia integration is very easy and works perfectly, to grab JMX metrics via user friendly HTTP/Json interface. Agent have two modules for Cassandra: check_cassandra.py and check_cassandra3.py . first one is for collecting metrics from Cassandra 2.0xx and Cassandra 2.1xx, the second is for Cassandra 2.2 and upper. Enablling Cassandra checks has two parts: Configure Caassandra to expose metrics via Jolokia Enable one of cassandra checks and confiugre Agent with Jolokia access parameters. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_cassandra.py ./ or cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_cassandra3.py ./ Configure Cassandra with Jolokia First download Jolokia jolokia-jvm-VESION-agent.jar from https://jolokia.org/download.html and copy it to All nodes of Cassandra cluster. cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar Now we need to edit cassandra-env.sh and add javaagent JVM option: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/etc/cassandra/jolokia/jolokia.properties\" Now we need to configure Jolokia: For packaged Cassandra installations copy-paste of code below will do the trick. If you have tarball Cassandra installation, just replace /etc/cassandra with actual location of your config files . mkdir /etc/cassandra/jolokia cat > /etc/cassandra/jolokia/jolokia.policy < <-EOF <?xml version= \"1.0\" encoding= \"utf-8\" ? > <restrict> <http> <method> get </method> </http> <commands> <command> read </command> <command> list </command> </commands> </restrict> EOF cat > /etc/cassandra/jolokia/jolokia.properties < <-EOF host= 0.0.0.0 port= 7777 agentContext= /jolokia backlog= 100 policyLocation= file:///etc/cassandra/jolokia/jolokia.policy historyMaxEntries= 10 debug= false debugMaxEntries= 100 maxDepth= 15 maxCollectionSize= 1000 maxObjects= 0 EOF Now you need to Cassandra daemon. Agent Cassandra check is enabled as any other check, so copy or symlinc apropriate cassandra check from checks_available to checks_enabled . Edit conf/bigdata.ini, it already contains reasonable defaults to work out of the box, but if your Cassandra and Jolokia are configured in different way, than described below, just replace default parameters with desired ones. [Cassandra] jolokia : http://127.0.0.1:7777/jolokia/read Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides For older versions of Cassandra check_cassandra.py Name Description Type Unit cassa_{cms or g1_old}_collection_count CMS or G1 old generations GC count counter None cassa_{cms or g1_old}_collection_time CMS or G1 old generations GC time rate Milliseconds cassa_{cms or g1_old}_lastgcinfo CMS or G1 old generations last GC info gauge Milliseconds cassa_daemonthreadcount Running Java daemon threads gauge None cassa_heap_committed Java Heap committed gauge Bytes cassa_heap_max Java Heap Max gauge Bytes cassa_heap_used Java Heap Used gauge Bytes cassa_keycachehits Cassandra Key cache hits rate OPS cassa_keycacherequests Cassandra Key cache requests rate OPS cassa_mutationstage Cassandra mutations requests rate OPS cassa_native_transport_requests Cassandra native transport (CQL) requests rate OPS cassa_nonheap_committed Java non Heap committed gauge Bytes cassa_nonheap_max Java non Heap Max gauge Bytes cassa_nonheap_used Java non Heap Used gauge Bytes cassa_{parnew or g1_young}_collection_count ParNew or G1 young generations GC count counter None cassa_{parnew or g1_young}_collection_time ParNew or G1 young generations GC time rate Milliseconds cassa_{parnew or g1_young}_lastgcinfo ParNew or G1 young generations GC lastgcinfo gauge Milliseconds cassa_peakthreadcount Peak amount of running daemon threads gauge None cassa_pending_compactions Cassandra pending compactions gauge None cassa_readstage Cassandra queries at read stage rate OPS cassa_requestresponsestage Cassandra requests and request/response stage rate OPS cassa_threadcount Running non daemon threads count gauge None cassa_totalstartedthreadcount Total started threads count counter None For newer versions of Cassandra check_cassandra3.py Name Description Type Unit cassa_{cms or g1_old}_collection_count CMS or G1 old generations GC count counter None cassa_{cms or g1_old}_collection_time CMS or G1 old generations GC time rate Milliseconds cassa_{cms or g1_old}_lastgcinfo CMS or G1 old generations last GC info gauge Milliseconds cassa_compaction_pending Cassandra pending compactions gauge None cassa_cql_preparedstatementsexecuted Cassandra prepared CQL statements execution rate OPS cassa_cql_regularstatementsexecuted Cassandra regular CQL statements execution rate OPS cassa_daemonthreadcount Running Java daemon threads count gauge None cassa_heap_committed Java Heap Used gauge Bytes cassa_heap_max Java Heap Max gauge Bytes cassa_heap_used Java Heap Used gauge Bytes cassa_hits_keycache Cassandra Key cache hits rate OPS cassa_hits_rowcache Cassandra Row cache hits rate OPS cassa_nonheap_committed Java non Heap Committed gauge Bytes cassa_nonheap_max Java non Heap Max gauge Bytes cassa_nonheap_used Java non Heap Used gauge Bytes cassa_{parnew or g1_young}_collection_count Parnew or G1 young generations GC count counter None cassa_{parnew or g1_young}_collection_time Parnew or G1 young generations GC time rate Milliseconds cassa_{parnew or g1_young}_lastgcinfo Parnew or G1 young generations Last GC info gauge Milliseconds cassa_peakthreadcount Cassandra Peak threads count gauge None cassa_requests_keycache Cassandra Key cashe requests rate OPS cassa_requests_rowcache Cassandra Row cashe requests rate OPS cassa_threadcount Running non daemon threads count gauge None cassa_totalstartedthreadcount Total started threads count counter None cassa_latency_casread Latency of CASRead Statements gauge Microseconds cassa_latency_caswrite Latency of CASWrite Statements gauge Microseconds cassa_latency_rangeslice Latency of RangeSlice Statements gauge Microseconds cassa_latency_read Latency of Read Statements gauge Microseconds cassa_latency_viewwrite Latency of ViewWrite Statements gauge Microseconds cassa_latency_write Latency of Write Statements gauge Microseconds","title":"Cassandra"},{"location":"agent/cassandra/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_cassandra.py ./ or cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_cassandra3.py ./","title":"Install"},{"location":"agent/cassandra/#configure","text":"Cassandra with Jolokia First download Jolokia jolokia-jvm-VESION-agent.jar from https://jolokia.org/download.html and copy it to All nodes of Cassandra cluster. cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar Now we need to edit cassandra-env.sh and add javaagent JVM option: JVM_OPTS = \" $JVM_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/etc/cassandra/jolokia/jolokia.properties\" Now we need to configure Jolokia: For packaged Cassandra installations copy-paste of code below will do the trick. If you have tarball Cassandra installation, just replace /etc/cassandra with actual location of your config files . mkdir /etc/cassandra/jolokia cat > /etc/cassandra/jolokia/jolokia.policy < <-EOF <?xml version= \"1.0\" encoding= \"utf-8\" ? > <restrict> <http> <method> get </method> </http> <commands> <command> read </command> <command> list </command> </commands> </restrict> EOF cat > /etc/cassandra/jolokia/jolokia.properties < <-EOF host= 0.0.0.0 port= 7777 agentContext= /jolokia backlog= 100 policyLocation= file:///etc/cassandra/jolokia/jolokia.policy historyMaxEntries= 10 debug= false debugMaxEntries= 100 maxDepth= 15 maxCollectionSize= 1000 maxObjects= 0 EOF Now you need to Cassandra daemon. Agent Cassandra check is enabled as any other check, so copy or symlinc apropriate cassandra check from checks_available to checks_enabled . Edit conf/bigdata.ini, it already contains reasonable defaults to work out of the box, but if your Cassandra and Jolokia are configured in different way, than described below, just replace default parameters with desired ones. [Cassandra] jolokia : http://127.0.0.1:7777/jolokia/read","title":"Configure"},{"location":"agent/cassandra/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/cassandra/#provides","text":"For older versions of Cassandra check_cassandra.py Name Description Type Unit cassa_{cms or g1_old}_collection_count CMS or G1 old generations GC count counter None cassa_{cms or g1_old}_collection_time CMS or G1 old generations GC time rate Milliseconds cassa_{cms or g1_old}_lastgcinfo CMS or G1 old generations last GC info gauge Milliseconds cassa_daemonthreadcount Running Java daemon threads gauge None cassa_heap_committed Java Heap committed gauge Bytes cassa_heap_max Java Heap Max gauge Bytes cassa_heap_used Java Heap Used gauge Bytes cassa_keycachehits Cassandra Key cache hits rate OPS cassa_keycacherequests Cassandra Key cache requests rate OPS cassa_mutationstage Cassandra mutations requests rate OPS cassa_native_transport_requests Cassandra native transport (CQL) requests rate OPS cassa_nonheap_committed Java non Heap committed gauge Bytes cassa_nonheap_max Java non Heap Max gauge Bytes cassa_nonheap_used Java non Heap Used gauge Bytes cassa_{parnew or g1_young}_collection_count ParNew or G1 young generations GC count counter None cassa_{parnew or g1_young}_collection_time ParNew or G1 young generations GC time rate Milliseconds cassa_{parnew or g1_young}_lastgcinfo ParNew or G1 young generations GC lastgcinfo gauge Milliseconds cassa_peakthreadcount Peak amount of running daemon threads gauge None cassa_pending_compactions Cassandra pending compactions gauge None cassa_readstage Cassandra queries at read stage rate OPS cassa_requestresponsestage Cassandra requests and request/response stage rate OPS cassa_threadcount Running non daemon threads count gauge None cassa_totalstartedthreadcount Total started threads count counter None For newer versions of Cassandra check_cassandra3.py Name Description Type Unit cassa_{cms or g1_old}_collection_count CMS or G1 old generations GC count counter None cassa_{cms or g1_old}_collection_time CMS or G1 old generations GC time rate Milliseconds cassa_{cms or g1_old}_lastgcinfo CMS or G1 old generations last GC info gauge Milliseconds cassa_compaction_pending Cassandra pending compactions gauge None cassa_cql_preparedstatementsexecuted Cassandra prepared CQL statements execution rate OPS cassa_cql_regularstatementsexecuted Cassandra regular CQL statements execution rate OPS cassa_daemonthreadcount Running Java daemon threads count gauge None cassa_heap_committed Java Heap Used gauge Bytes cassa_heap_max Java Heap Max gauge Bytes cassa_heap_used Java Heap Used gauge Bytes cassa_hits_keycache Cassandra Key cache hits rate OPS cassa_hits_rowcache Cassandra Row cache hits rate OPS cassa_nonheap_committed Java non Heap Committed gauge Bytes cassa_nonheap_max Java non Heap Max gauge Bytes cassa_nonheap_used Java non Heap Used gauge Bytes cassa_{parnew or g1_young}_collection_count Parnew or G1 young generations GC count counter None cassa_{parnew or g1_young}_collection_time Parnew or G1 young generations GC time rate Milliseconds cassa_{parnew or g1_young}_lastgcinfo Parnew or G1 young generations Last GC info gauge Milliseconds cassa_peakthreadcount Cassandra Peak threads count gauge None cassa_requests_keycache Cassandra Key cashe requests rate OPS cassa_requests_rowcache Cassandra Row cashe requests rate OPS cassa_threadcount Running non daemon threads count gauge None cassa_totalstartedthreadcount Total started threads count counter None cassa_latency_casread Latency of CASRead Statements gauge Microseconds cassa_latency_caswrite Latency of CASWrite Statements gauge Microseconds cassa_latency_rangeslice Latency of RangeSlice Statements gauge Microseconds cassa_latency_read Latency of Read Statements gauge Microseconds cassa_latency_viewwrite Latency of ViewWrite Statements gauge Microseconds cassa_latency_write Latency of Write Statements gauge Microseconds","title":"Provides"},{"location":"agent/ceph/","text":"Ceph is high performance distributed storage system, for storing petabytes of data on commodity hardware. Agent uses Ceph built in tools to expose statistics and send to PuyPuy servers. Configuration is very minimal and easy : All that is needed is to tell Agent the username, which is allowed to grab statistics (Typically client.admin) and path to keyring. If you run Ceph, you already have installed all needed dependencies, so nothing else is needed to add. Agent will look for configuration in file bigdata.ini . Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_ceph.py ./ Configure Make sure that /etc/ceph/ceph.client.admin.keyring is readable for user, which runs Agent. If you want to use another keyring or ceph user, change client and keyring paramaters to your desired ones. It takes cople of seconds, afterwords you can create graphs with these metrics : [Ceph] client : client.admin keyring : /etc/ceph/ceph.client.admin.keyring Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit ceph_num_bytes Amount of free space in Ceph gauge Bytes ceph_num_pgs Total amount of placement groups gauge None ceph_raw_bytes Total raw space for ceph cluster gauge Bytes ceph_raw_bytes_avail Amount of used raw available replication is taken to account gauge Bytes ceph_raw_bytes_used Amount of used raw space replication is taken to account gauge Bytes ceph_io_sec I/O operations per second for entire cluster rate OPS ceph_read_bytes_sec Read bytes per second for entire cluster rate Bytes ceph_write_bytes_sec Write bytes per second for entire cluster rate Bytes ceph_degraded_objects Number of degraded objects gauge None ceph_degraded_ratio Ratio of degraded objects gauge Float ceph_degraded_total Number of total degraded objects gauge None ceph_recovering_bytes_per_sec Speed of recovery in bytes gauge Bytes ceph_num_objects_recovered Recovered objects gauge None ceph_recovering_keys_per_sec Recovered Keys rate None ceph_degraded_percent Percentage of degraded objects gauge Percent ceph_misplaced_percent Percentage of misplaced objects gauge Percent There isn no necessity to run check_ceph.py on all nodes of Ceph of cluster. Statistics from all nodes will be the same, as above mentioned stats are global at cluster level.","title":"Ceph"},{"location":"agent/ceph/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_ceph.py ./","title":"Install"},{"location":"agent/ceph/#configure","text":"Make sure that /etc/ceph/ceph.client.admin.keyring is readable for user, which runs Agent. If you want to use another keyring or ceph user, change client and keyring paramaters to your desired ones. It takes cople of seconds, afterwords you can create graphs with these metrics : [Ceph] client : client.admin keyring : /etc/ceph/ceph.client.admin.keyring","title":"Configure"},{"location":"agent/ceph/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/ceph/#provides","text":"Name Description Type Unit ceph_num_bytes Amount of free space in Ceph gauge Bytes ceph_num_pgs Total amount of placement groups gauge None ceph_raw_bytes Total raw space for ceph cluster gauge Bytes ceph_raw_bytes_avail Amount of used raw available replication is taken to account gauge Bytes ceph_raw_bytes_used Amount of used raw space replication is taken to account gauge Bytes ceph_io_sec I/O operations per second for entire cluster rate OPS ceph_read_bytes_sec Read bytes per second for entire cluster rate Bytes ceph_write_bytes_sec Write bytes per second for entire cluster rate Bytes ceph_degraded_objects Number of degraded objects gauge None ceph_degraded_ratio Ratio of degraded objects gauge Float ceph_degraded_total Number of total degraded objects gauge None ceph_recovering_bytes_per_sec Speed of recovery in bytes gauge Bytes ceph_num_objects_recovered Recovered objects gauge None ceph_recovering_keys_per_sec Recovered Keys rate None ceph_degraded_percent Percentage of degraded objects gauge Percent ceph_misplaced_percent Percentage of misplaced objects gauge Percent There isn no necessity to run check_ceph.py on all nodes of Ceph of cluster. Statistics from all nodes will be the same, as above mentioned stats are global at cluster level.","title":"Provides"},{"location":"agent/coredns/","text":"Coredns is a fast and flexible, cloud native DNS server, written in Go programing language Configuration of coredns check is stored k8s.ini file in conf directory. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_coredns.py ./ Configure If you are using default installation of ethd service, no additional configuration is needed. If you need to monitor etc in non default location, edit conf/k8s.ini section coredns and set metrics parameter with value matching your needs. Before enabling check_coredns module you should enable metrics plugin at Coredns. Snippet above is an example of how metrics interface can be enabled in coredns { prome t heus localhos t : 9253 } When config file is changes , you should restart coredns daemon to apply new settings. The metrics path at coredns is fixed to /metrics so make sure full URL of coredns metrics interface is written in conf/k8s.ini [coredns] metrics : http://127.0.0.1:9253/metrics Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit coredns_go_gc_duration_seconds_count A summary of the GC invocation durations. counter Seconds coredns_go_gc_duration_seconds_sum A summary of the GC invocation durations. sum Seconds coredns_go_goroutines Number of goroutines that currently exist. gauge None coredns_go_memstats_alloc_bytes Number of bytes allocated and still in use. gauge Bytes coredns_go_memstats_alloc_bytes_total Number of bytes allocated and still in use. total Bytes coredns_go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table. gauge Bytes coredns_go_memstats_frees_total Total number of frees. counter None coredns_go_memstats_gc_cpu_fraction The fraction of this program's available CPU time used by the GC since the program started. gauge None coredns_go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata. gauge Bytes coredns_go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use. gauge Bytes coredns_go_memstats_heap_idle_bytes Number of heap bytes waiting to be used. gauge Bytes coredns_go_memstats_heap_inuse_bytes Number of heap bytes that are in use. gauge Bytes coredns_go_memstats_heap_objectsNumber of allocated objects. gauge integer coredns_go_memstats_heap_released_bytes Number of heap bytes released to OS. gauge Bytes coredns_go_memstats_heap_sys_bytes Number of heap bytes obtained from system. gauge Bytes coredns_go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection. gauge Seconds coredns_go_memstats_lookups_total Total number of pointer lookups. counter None coredns_go_memstats_mallocs_total Total number of mallocs. counter None coredns_go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures. gauge Bytes coredns_go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system. gauge Bytes coredns_go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures. gauge Bytes coredns_go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system. gauge Bytes coredns_go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place. gauge Bytes coredns_go_memstats_other_sys_bytes Number of bytes used for other system allocations. gauge Bytes coredns_go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator. gauge Bytes coredns_go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator. gauge Bytes coredns_go_memstats_sys_bytes Number of bytes obtained from system. gauge Bytes coredns_go_threads Number of OS threads created. gauge None coredns_health_request_duration_seconds_count Time each request took. counter Seconds coredns_health_request_duration_seconds_sum Time each request took. sum Seconds coredns_panic_count_total A metrics that counts the number of panics. counter None coredns_process_cpu_seconds_total Total user and system CPU time spent in seconds. counter Seconds coredns_process_max_fds Maximum number of open file descriptors. gauge None coredns_process_open_fds Number of open file descriptors. gauge None coredns_process_resident_memory_bytes Resident memory size in bytes. gauge Bytes coredns_process_start_time_seconds Start time of the process since unix epoch in seconds. gauge Seconds coredns_process_virtual_memory_bytes Virtual memory size in bytes. gauge Bytes coredns_process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes. gauge Bytes","title":"Coredns"},{"location":"agent/coredns/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_coredns.py ./","title":"Install"},{"location":"agent/coredns/#configure","text":"If you are using default installation of ethd service, no additional configuration is needed. If you need to monitor etc in non default location, edit conf/k8s.ini section coredns and set metrics parameter with value matching your needs. Before enabling check_coredns module you should enable metrics plugin at Coredns. Snippet above is an example of how metrics interface can be enabled in coredns { prome t heus localhos t : 9253 } When config file is changes , you should restart coredns daemon to apply new settings. The metrics path at coredns is fixed to /metrics so make sure full URL of coredns metrics interface is written in conf/k8s.ini [coredns] metrics : http://127.0.0.1:9253/metrics","title":"Configure"},{"location":"agent/coredns/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/coredns/#provides","text":"Name Description Type Unit coredns_go_gc_duration_seconds_count A summary of the GC invocation durations. counter Seconds coredns_go_gc_duration_seconds_sum A summary of the GC invocation durations. sum Seconds coredns_go_goroutines Number of goroutines that currently exist. gauge None coredns_go_memstats_alloc_bytes Number of bytes allocated and still in use. gauge Bytes coredns_go_memstats_alloc_bytes_total Number of bytes allocated and still in use. total Bytes coredns_go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table. gauge Bytes coredns_go_memstats_frees_total Total number of frees. counter None coredns_go_memstats_gc_cpu_fraction The fraction of this program's available CPU time used by the GC since the program started. gauge None coredns_go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata. gauge Bytes coredns_go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use. gauge Bytes coredns_go_memstats_heap_idle_bytes Number of heap bytes waiting to be used. gauge Bytes coredns_go_memstats_heap_inuse_bytes Number of heap bytes that are in use. gauge Bytes coredns_go_memstats_heap_objectsNumber of allocated objects. gauge integer coredns_go_memstats_heap_released_bytes Number of heap bytes released to OS. gauge Bytes coredns_go_memstats_heap_sys_bytes Number of heap bytes obtained from system. gauge Bytes coredns_go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection. gauge Seconds coredns_go_memstats_lookups_total Total number of pointer lookups. counter None coredns_go_memstats_mallocs_total Total number of mallocs. counter None coredns_go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures. gauge Bytes coredns_go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system. gauge Bytes coredns_go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures. gauge Bytes coredns_go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system. gauge Bytes coredns_go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place. gauge Bytes coredns_go_memstats_other_sys_bytes Number of bytes used for other system allocations. gauge Bytes coredns_go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator. gauge Bytes coredns_go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator. gauge Bytes coredns_go_memstats_sys_bytes Number of bytes obtained from system. gauge Bytes coredns_go_threads Number of OS threads created. gauge None coredns_health_request_duration_seconds_count Time each request took. counter Seconds coredns_health_request_duration_seconds_sum Time each request took. sum Seconds coredns_panic_count_total A metrics that counts the number of panics. counter None coredns_process_cpu_seconds_total Total user and system CPU time spent in seconds. counter Seconds coredns_process_max_fds Maximum number of open file descriptors. gauge None coredns_process_open_fds Number of open file descriptors. gauge None coredns_process_resident_memory_bytes Resident memory size in bytes. gauge Bytes coredns_process_start_time_seconds Start time of the process since unix epoch in seconds. gauge Seconds coredns_process_virtual_memory_bytes Virtual memory size in bytes. gauge Bytes coredns_process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes. gauge Bytes","title":"Provides"},{"location":"agent/couch/","text":"CouchBase Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_couchbase_ { VERSION } .py ./ Configure Edit ${PUYPUY_HOME}/conf/bigdata.ini and change auth parameters and ip address of Couchbase servers to values matching your actual node running node parameters. Also its required to write comma separated list of buckets which you want to monitor, so please make sure to change buckets: to names of buckets which you want to monitor. [CouchBase] stats : http://127.0.0.1:8091/pools/default/buckets buckets : default [CouchBase5x] stats : http://127.0.0.1:8091/pools/default/buckets buckets : beer-sample, gamesim-sample, travel-sample user : admin pass : adminadmin auth : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit couchbase_clusterwide_itemcount Per bucket clusterwide items count gauge None couchbase_clusterwide_memused Per bucket used memory fo entire cluster gauge None couchbase_clusterwide_opspersec OPeration per second executed on entire cluster rate OPS couchbase_clusterwide_quotapercentused Per bucker quota usage for entire cluster gauge Percent couchbase_cmd_get Per buicket GETs executen on current node rate OPS couchbase_couch_docs_data_size Size of couch documents associated with a node gauge Bytes couchbase_curr_items Amount of items on current node gauge None couchbase_curr_items_tot Write bytes per second for entire cluster gauge None couchbase_ep_bg_fetched Number of disk fetches performed on node counter None couchbase_get_hits Get hits performent on current node rate OPS couchbase_mem_used Current node's used memory gauge Bytes couchbase_ops Operations per second performed against entire cluster gauge OPS couchbase_vb_replica_curr_items Number of replicated items/documents curent None CouchDB Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_couchdb_ { VERSION } .py ./ Configure Edit ${PUYPUY_HOME}/conf/bigdata.ini and change auth parameters and ip address of CouchDB servers to values matching your actual node running node parameters. For CouchDB 2x check you can set parameter detailed to True/False . When detailed is set to True agent will send metrics about HTTP status and response codes and, which will significantly increase number of metrics. [CouchDB] stats : http://127.0.0.1:5984/_stats [CouchDB2] stats : http://127.0.0.1:5984 user : admin pass : admin auth : True detailed = True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit couchdb_bulk_requests Bulk requests per second on current node rate OPS couchdb_database_reads Database reads per second on current node rate OPS couchdb_database_writes Database writes per second on current node rate OPS couchdb_document_inserts Inserted documents per second on current node rate OPS couchdb_document_writes Written documents per second on current node rate OPS couchdb_requests Total maount of requests per second on current node rate OPS couchdb_requests_methods Amount of http requests on curent node by HTTP methods rate OPS couchdb_status_codes Amount of http requests on curent node by HTTP status codes rate OPS couchdb_temporary_view_reads Temperory view reads on current node per second rate OPS couchdb_view_reads View reads on current node per second rate OPS","title":"CouchBase, CouchDB"},{"location":"agent/couch/#couchbase","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_couchbase_ { VERSION } .py ./ Configure Edit ${PUYPUY_HOME}/conf/bigdata.ini and change auth parameters and ip address of Couchbase servers to values matching your actual node running node parameters. Also its required to write comma separated list of buckets which you want to monitor, so please make sure to change buckets: to names of buckets which you want to monitor. [CouchBase] stats : http://127.0.0.1:8091/pools/default/buckets buckets : default [CouchBase5x] stats : http://127.0.0.1:8091/pools/default/buckets buckets : beer-sample, gamesim-sample, travel-sample user : admin pass : adminadmin auth : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit couchbase_clusterwide_itemcount Per bucket clusterwide items count gauge None couchbase_clusterwide_memused Per bucket used memory fo entire cluster gauge None couchbase_clusterwide_opspersec OPeration per second executed on entire cluster rate OPS couchbase_clusterwide_quotapercentused Per bucker quota usage for entire cluster gauge Percent couchbase_cmd_get Per buicket GETs executen on current node rate OPS couchbase_couch_docs_data_size Size of couch documents associated with a node gauge Bytes couchbase_curr_items Amount of items on current node gauge None couchbase_curr_items_tot Write bytes per second for entire cluster gauge None couchbase_ep_bg_fetched Number of disk fetches performed on node counter None couchbase_get_hits Get hits performent on current node rate OPS couchbase_mem_used Current node's used memory gauge Bytes couchbase_ops Operations per second performed against entire cluster gauge OPS couchbase_vb_replica_curr_items Number of replicated items/documents curent None","title":"CouchBase"},{"location":"agent/couch/#couchdb","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_couchdb_ { VERSION } .py ./ Configure Edit ${PUYPUY_HOME}/conf/bigdata.ini and change auth parameters and ip address of CouchDB servers to values matching your actual node running node parameters. For CouchDB 2x check you can set parameter detailed to True/False . When detailed is set to True agent will send metrics about HTTP status and response codes and, which will significantly increase number of metrics. [CouchDB] stats : http://127.0.0.1:5984/_stats [CouchDB2] stats : http://127.0.0.1:5984 user : admin pass : admin auth : True detailed = True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit couchdb_bulk_requests Bulk requests per second on current node rate OPS couchdb_database_reads Database reads per second on current node rate OPS couchdb_database_writes Database writes per second on current node rate OPS couchdb_document_inserts Inserted documents per second on current node rate OPS couchdb_document_writes Written documents per second on current node rate OPS couchdb_requests Total maount of requests per second on current node rate OPS couchdb_requests_methods Amount of http requests on curent node by HTTP methods rate OPS couchdb_status_codes Amount of http requests on curent node by HTTP status codes rate OPS couchdb_temporary_view_reads Temperory view reads on current node per second rate OPS couchdb_view_reads View reads on current node per second rate OPS","title":"CouchDB"},{"location":"agent/custom/","text":"Custom Checks Create file in checks_enabled directory with name check_checkname.py, inside script you should have class Check which is inherited from lib.basecheck.CheckBase and function precheck(self) which will override precheck() in main class. (Here you actual check should live). Your check should contain some minimal imports in order to talk to main program: Example below is simple check which gets system's Load Average and sends it to PuyPuy import lib.getconfig import lib.pushdata import lib.basecheck import lib.puylogger check_type = 'system' reaction = - 3 class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : loadavg = open ( \"/proc/loadavg\" , \"r\" ) proc_loadavg = loadavg . readline () . split () self . local_vars . append ({ 'name' : 'sys_load_1' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 0 ]}) self . local_vars . append ({ 'name' : 'sys_load_5' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 1 ]}) self . local_vars . append ({ 'name' : 'sys_load_15' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 2 ]}) loadavg . close () except Exception as e : lib . pushdata . print_error ( __name__ , ( e )) pass This will import libs to generate data for back-end needed, so you do not have to deal with generating and pushing it manually. Create scripts which calculates value rates : import lib.getconfig import lib.pushdata import lib.basecheck import lib.puylogger check_type = 'system' reaction = - 3 class Check ( lib . basecheck . CheckBase ): def precheck ( self ): local_vars = [] rate = lib . record_rate . ValueRate () timestamp = int ( datetime . datetime . now () . strftime ( \" %s \" )) name1 = 'SomeName' name2 = 'OtherName' value1 = 10 value2 = 20 value_rate1 = self . rate . record_value_rate ( name1 , value1 , self . timestamp ) value_rate2 = self . rate . record_value_rate ( name2 , value2 , self . timestamp ) self . local_vars . append ({ 'name' : name1 , 'timestamp' : self . timestamp , 'value' : value_rate1 }) self . local_vars . append ({ 'name' : name2 , 'timestamp' : self . timestamp , 'value' : value_rate2 }) Custom Script To run custom script like Bash, Perl etc.. Create scripts in format check_name.extension in folder scripts_enabled. All is needed from custom is to system out values in right order, Below is sample Bash script, which generates random number and send to collector for graphing: Make sure to have check_style parameter (stack/rate). This is for telling main program if it should calculate value rates or just push data as it comes. #!/bin/bash myvalue = $RANDOM mytype = random_gen check_type = my_bash_random check_style = stack myvalue2 = $RANDOM mytype2 = random_gen2 check_type2 = my_bash_random2 check_style2 = rate echo $mytype $myvalue $check_type $check_style echo -n $mytype2 $myvalue2 $check_type2 $check_style2 PuyPuy Specific As PuyPuy is completely push based and our servers does not have any direct access to your infrastructure, we need special check which will determine if particular host is alive or not. Thus we made small module, which will call our servers and get and send response times to PuyPuy. We will generate host alive parameter based based on information sent by check_puypuy.py . If you want to have host aliveness test, enable check_puypuy.py as you will do with any other python check and restart Agent: cd ${ agent_home } /checks enabled ln -s ../checks-available/check_puypuy.py ./ PuyPuy is dynamic system based on machine learning, but if you want to have statically defined alerts you can use send_special method in your python module. Example below demonstrates how custom alerts can be configured, its taken from check_network_bytes module: import glob import lib.getconfig import lib.pushdata import lib.record_rate import lib.puylogger import lib.basecheck check_type = 'system' check_localhost = lib . getconfig . getparam ( 'Network Stats' , 'localhost' ) rated = lib . getconfig . getparam ( 'Network Stats' , 'rated' ) class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : ifaces = glob . glob ( \"/sys/class/net/*\" ) iflist = [] for index in range ( 0 , len ( ifaces )): if check_localhost is False : iface = ifaces [ index ] . split ( '/' )[ 4 ] if \"/lo\" not in ifaces [ index ]: iflist . append ( iface ) else : iface = ifaces [ index ] . split ( '/' )[ 4 ] iflist . append ( iface ) for nic in iflist : rxb = open ( \"/sys/class/net/\" + nic + \"/statistics/rx_bytes\" , \"r\" ) txb = open ( \"/sys/class/net/\" + nic + \"/statistics/tx_bytes\" , \"r\" ) rx = int ( rxb . read ()) tx = int ( txb . read ()) if rx is not 0 or tx is not 0 : txname = 'bytes_tx' rxname = 'bytes_rx' if rated is True : rxrate = self . rate . record_value_rate ( rxname + nic , rx , self . timestamp ) txrate = self . rate . record_value_rate ( txname + nic , tx , self . timestamp ) self . local_vars . append ({ 'name' : rxname , 'timestamp' : self . timestamp , 'value' : rxrate , 'chart_type' : 'Rate' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) self . local_vars . append ({ 'name' : txname , 'timestamp' : self . timestamp , 'value' : txrate , 'chart_type' : 'Rate' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) else : self . local_vars . append ({ 'name' : rxname , 'timestamp' : self . timestamp , 'value' : rxrate , 'chart_type' : 'Counter' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) self . local_vars . append ({ 'name' : txname , 'timestamp' : self . timestamp , 'value' : txrate , 'chart_type' : 'Counter' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) rxb . close () txb . close () except Exception as e : lib . pushdata . print_error ( __name__ , ( e )) pass You can disable or change dynamic alerting for particular checks, by passing reaction parameter to jsondata.gen_data . Arguments for reaction parameter are followings: reaction = -3 # (Disables dynamic alerting and learning on this check) reaction = -1 # (Disables dynamic alerting if values are smaller than expected) reaction = -2 # (Disables dynamic alerting if values are bigger than expected) reaction = 0 # (Default : Enable dynamic alerting and learning on this check) jsondata.gen_data(txname, timestamp, value, lib.pushdata.hostname, check_type, cluster_name, reaction) We have created another PuyPuy specific optional parameter. This is to tell back-end type of incoming messages. It accepts \"Rate\" and \"Counter\" arguments. Rate : is used to tell PuyPuy that incoming metrics are rated so back-end knows better how to calculate dynamic rules. Counter : Is set when we have increasing counter for metrics values. This is needed to do better calculation of regression, and to reset it when next value is smaller than previous. If you find this not suitable for your needs, do not set parameter even when your metrics values are increasing counter, but keep in mind to manually drop regression when you counter resets. Otherwise regression counter will think that something happens as new values are out of expected regression scopes and will set high level of alerting to check.","title":"Custom Checks"},{"location":"agent/custom/#custom-checks","text":"Create file in checks_enabled directory with name check_checkname.py, inside script you should have class Check which is inherited from lib.basecheck.CheckBase and function precheck(self) which will override precheck() in main class. (Here you actual check should live). Your check should contain some minimal imports in order to talk to main program: Example below is simple check which gets system's Load Average and sends it to PuyPuy import lib.getconfig import lib.pushdata import lib.basecheck import lib.puylogger check_type = 'system' reaction = - 3 class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : loadavg = open ( \"/proc/loadavg\" , \"r\" ) proc_loadavg = loadavg . readline () . split () self . local_vars . append ({ 'name' : 'sys_load_1' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 0 ]}) self . local_vars . append ({ 'name' : 'sys_load_5' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 1 ]}) self . local_vars . append ({ 'name' : 'sys_load_15' , 'timestamp' : self . timestamp , 'value' : proc_loadavg [ 2 ]}) loadavg . close () except Exception as e : lib . pushdata . print_error ( __name__ , ( e )) pass This will import libs to generate data for back-end needed, so you do not have to deal with generating and pushing it manually. Create scripts which calculates value rates : import lib.getconfig import lib.pushdata import lib.basecheck import lib.puylogger check_type = 'system' reaction = - 3 class Check ( lib . basecheck . CheckBase ): def precheck ( self ): local_vars = [] rate = lib . record_rate . ValueRate () timestamp = int ( datetime . datetime . now () . strftime ( \" %s \" )) name1 = 'SomeName' name2 = 'OtherName' value1 = 10 value2 = 20 value_rate1 = self . rate . record_value_rate ( name1 , value1 , self . timestamp ) value_rate2 = self . rate . record_value_rate ( name2 , value2 , self . timestamp ) self . local_vars . append ({ 'name' : name1 , 'timestamp' : self . timestamp , 'value' : value_rate1 }) self . local_vars . append ({ 'name' : name2 , 'timestamp' : self . timestamp , 'value' : value_rate2 })","title":"Custom Checks"},{"location":"agent/custom/#custom-script","text":"To run custom script like Bash, Perl etc.. Create scripts in format check_name.extension in folder scripts_enabled. All is needed from custom is to system out values in right order, Below is sample Bash script, which generates random number and send to collector for graphing: Make sure to have check_style parameter (stack/rate). This is for telling main program if it should calculate value rates or just push data as it comes. #!/bin/bash myvalue = $RANDOM mytype = random_gen check_type = my_bash_random check_style = stack myvalue2 = $RANDOM mytype2 = random_gen2 check_type2 = my_bash_random2 check_style2 = rate echo $mytype $myvalue $check_type $check_style echo -n $mytype2 $myvalue2 $check_type2 $check_style2","title":"Custom Script"},{"location":"agent/custom/#puypuy-specific","text":"As PuyPuy is completely push based and our servers does not have any direct access to your infrastructure, we need special check which will determine if particular host is alive or not. Thus we made small module, which will call our servers and get and send response times to PuyPuy. We will generate host alive parameter based based on information sent by check_puypuy.py . If you want to have host aliveness test, enable check_puypuy.py as you will do with any other python check and restart Agent: cd ${ agent_home } /checks enabled ln -s ../checks-available/check_puypuy.py ./ PuyPuy is dynamic system based on machine learning, but if you want to have statically defined alerts you can use send_special method in your python module. Example below demonstrates how custom alerts can be configured, its taken from check_network_bytes module: import glob import lib.getconfig import lib.pushdata import lib.record_rate import lib.puylogger import lib.basecheck check_type = 'system' check_localhost = lib . getconfig . getparam ( 'Network Stats' , 'localhost' ) rated = lib . getconfig . getparam ( 'Network Stats' , 'rated' ) class Check ( lib . basecheck . CheckBase ): def precheck ( self ): try : ifaces = glob . glob ( \"/sys/class/net/*\" ) iflist = [] for index in range ( 0 , len ( ifaces )): if check_localhost is False : iface = ifaces [ index ] . split ( '/' )[ 4 ] if \"/lo\" not in ifaces [ index ]: iflist . append ( iface ) else : iface = ifaces [ index ] . split ( '/' )[ 4 ] iflist . append ( iface ) for nic in iflist : rxb = open ( \"/sys/class/net/\" + nic + \"/statistics/rx_bytes\" , \"r\" ) txb = open ( \"/sys/class/net/\" + nic + \"/statistics/tx_bytes\" , \"r\" ) rx = int ( rxb . read ()) tx = int ( txb . read ()) if rx is not 0 or tx is not 0 : txname = 'bytes_tx' rxname = 'bytes_rx' if rated is True : rxrate = self . rate . record_value_rate ( rxname + nic , rx , self . timestamp ) txrate = self . rate . record_value_rate ( txname + nic , tx , self . timestamp ) self . local_vars . append ({ 'name' : rxname , 'timestamp' : self . timestamp , 'value' : rxrate , 'chart_type' : 'Rate' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) self . local_vars . append ({ 'name' : txname , 'timestamp' : self . timestamp , 'value' : txrate , 'chart_type' : 'Rate' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) else : self . local_vars . append ({ 'name' : rxname , 'timestamp' : self . timestamp , 'value' : rxrate , 'chart_type' : 'Counter' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) self . local_vars . append ({ 'name' : txname , 'timestamp' : self . timestamp , 'value' : txrate , 'chart_type' : 'Counter' , 'check_type' : check_type , 'reaction' : 0 , 'extra_tag' :{ 'device' : nic }}) rxb . close () txb . close () except Exception as e : lib . pushdata . print_error ( __name__ , ( e )) pass You can disable or change dynamic alerting for particular checks, by passing reaction parameter to jsondata.gen_data . Arguments for reaction parameter are followings: reaction = -3 # (Disables dynamic alerting and learning on this check) reaction = -1 # (Disables dynamic alerting if values are smaller than expected) reaction = -2 # (Disables dynamic alerting if values are bigger than expected) reaction = 0 # (Default : Enable dynamic alerting and learning on this check) jsondata.gen_data(txname, timestamp, value, lib.pushdata.hostname, check_type, cluster_name, reaction) We have created another PuyPuy specific optional parameter. This is to tell back-end type of incoming messages. It accepts \"Rate\" and \"Counter\" arguments. Rate : is used to tell PuyPuy that incoming metrics are rated so back-end knows better how to calculate dynamic rules. Counter : Is set when we have increasing counter for metrics values. This is needed to do better calculation of regression, and to reset it when next value is smaller than previous. If you find this not suitable for your needs, do not set parameter even when your metrics values are increasing counter, but keep in mind to manually drop regression when you counter resets. Otherwise regression counter will think that something happens as new values are out of expected regression scopes and will set high level of alerting to check.","title":"PuyPuy Specific"},{"location":"agent/docker/","text":"Container allows developers to package up an application with all needed parts, such as libraries and other dependencies, and ship it all out as one package. Docker is the pioneer and the most popular solution for creating, sharing and using containers. PuyPuy works with native Dockers HTTP API to get metrics from running containers. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_docker_stats.py ./ Configure Server To collect Docker metrics about all your containers, you will run one PuyPuy Agent on every host. In order to start collecting metrics from Docker you should first configure Docker server to expose metrics via HTTP socket. In general its just adding -H tcp://{SERVER_IP}:{PORT} parameter to dockerd at startup. For SystemV and Upstart servers you should add following to /etc/default/docker file DOCKER_OPTS = \"-H tcp://127.0.0.1:3141\" If you aur using SystemD servers like Debian 8 or newer, you should edit /lib/systemd/system/docker.service with following parameters : ExecStart = /usr/bin/dockerd -H tcp://127.0.0.1:3141 -H fd:// After restarting docker daemon you can configure OE-Agent to get stats about containers from http://127.0.0.1:3141 Agent Now when HOST server exposes its containers metrics via HTTP, you can enable check_docker_stats and restart OE-Agent . Config file of check_docker_stats module is conf/docker.ini . If you have followed docker configuration examples above, check_docker_stats will works with already set up default settings. [Docker] stats : http://127.0.0.1:3141/containers detailed : True memstats : True prettynames : True If you have configure another HOST:PORT for dockerd, please make sure to edit conf/docker.ini to match you configuration parameters. Provides Based on configuration of System and Agent, following metrics are collected from containers if details flag is set to True and Memory metrics are enabled: Name Description Type Unit docker_bytes_rx_eth0 Amounts of received bytes rate Bytes docker_bytes_tx_eth0 Amounts of sent bytes rate Bytes docker_container_cpu_usage Containers CPU usage gauge Percent docker_cpu_throttled_periods Throttled Periods of containers CPU counter Milliseconds docker_cpu_throttled_time Throttled time in milliseconds of containers CPU counter Milliseconds docker_master_cpu_usage Master CPU usage in percent gauge Percent docker_mem_cur_usage Containers current memory usage gauge Bytes docker_mem_max_usage Containers max memory usage gauge Bytes docker_mem_total_active_anon The amount of anonymous active memory gauge Bytes docker_mem_total_active_file The amount of anonymous file cache memory gauge Bytes docker_mem_total_cache Block device/cache used memory of control group gauge Bytes docker_mem_total_inactive_anon The amount of anonymous inactive memory gauge Bytes docker_mem_total_inactive_file The amount of anonymous inactive file cache gauge Bytes docker_mem_total_mapped_file Memory mapped by the processes in the control group gauge Bytes docker_mem_total_rss Memory that doesn\u2019t correspond to disk, heaps, and anon gauge Bytes docker_mem_total_swap Total amount of containers swapped memory gauge Bytes docker_mem_total_unevictable The amount of memory that cannot be reclaimed gauge Bytes docker_rx_dropped_eth0 RX dropped traffic rate None docker_rx_errors_eth0 RX network errors rate None docker_rx_packets_eth0 RX packets rate None docker_tx_dropped_eth0 TX dropped traffic rate None docker_tx_errors_eth0 TX network errors rate None docker_tx_packets_eth0 TX packets rate None If details is set to False, these metrics will be collected from containers. Name Description Type Unit docker_bytes_rx_eth0 Amounts of received bytes rate Bytes docker_bytes_tx_eth0 Amounts of sent bytes rate Bytes docker_container_cpu_usage Containers CPU usage gauge Percent docker_cpu_throttled_periods Throttled Periods of containers CPU counter Milliseconds docker_cpu_throttled_time Throttled time in milliseconds of containers CPU counter Milliseconds docker_master_cpu_usage Master CPU usage in percent gauge Percent docker_mem_cur_usage Containers current memory usage gauge Bytes docker_mem_max_usage Containers max memory usage gauge Bytes Each of metrics contains container TAG which is ether container ID or Name. If prettynames parameter in config file is set to False, you will see long container ID's at container TAG of dashboard Containers Memory utilization In order to be able to track containers memory utilization cgroup_enable=memory kernel parameter should be set at Servers boot. Because memory control via cgroups is resource intensive operation, most of Linux distributions, disables it by default. So make sure that server is booted with cgroup_enable=memory parameter, otherwise container's memory utilization metrics will not available. To enable Kernel control via cgroups add following parameters to /etc/default/grub. GRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\" Run update-grub and reboot server. Otherwise just set memstats: False in conf/docker.ini .","title":"Docker Containers"},{"location":"agent/docker/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_docker_stats.py ./","title":"Install"},{"location":"agent/docker/#configure","text":"Server To collect Docker metrics about all your containers, you will run one PuyPuy Agent on every host. In order to start collecting metrics from Docker you should first configure Docker server to expose metrics via HTTP socket. In general its just adding -H tcp://{SERVER_IP}:{PORT} parameter to dockerd at startup. For SystemV and Upstart servers you should add following to /etc/default/docker file DOCKER_OPTS = \"-H tcp://127.0.0.1:3141\" If you aur using SystemD servers like Debian 8 or newer, you should edit /lib/systemd/system/docker.service with following parameters : ExecStart = /usr/bin/dockerd -H tcp://127.0.0.1:3141 -H fd:// After restarting docker daemon you can configure OE-Agent to get stats about containers from http://127.0.0.1:3141 Agent Now when HOST server exposes its containers metrics via HTTP, you can enable check_docker_stats and restart OE-Agent . Config file of check_docker_stats module is conf/docker.ini . If you have followed docker configuration examples above, check_docker_stats will works with already set up default settings. [Docker] stats : http://127.0.0.1:3141/containers detailed : True memstats : True prettynames : True If you have configure another HOST:PORT for dockerd, please make sure to edit conf/docker.ini to match you configuration parameters.","title":"Configure"},{"location":"agent/docker/#provides","text":"Based on configuration of System and Agent, following metrics are collected from containers if details flag is set to True and Memory metrics are enabled: Name Description Type Unit docker_bytes_rx_eth0 Amounts of received bytes rate Bytes docker_bytes_tx_eth0 Amounts of sent bytes rate Bytes docker_container_cpu_usage Containers CPU usage gauge Percent docker_cpu_throttled_periods Throttled Periods of containers CPU counter Milliseconds docker_cpu_throttled_time Throttled time in milliseconds of containers CPU counter Milliseconds docker_master_cpu_usage Master CPU usage in percent gauge Percent docker_mem_cur_usage Containers current memory usage gauge Bytes docker_mem_max_usage Containers max memory usage gauge Bytes docker_mem_total_active_anon The amount of anonymous active memory gauge Bytes docker_mem_total_active_file The amount of anonymous file cache memory gauge Bytes docker_mem_total_cache Block device/cache used memory of control group gauge Bytes docker_mem_total_inactive_anon The amount of anonymous inactive memory gauge Bytes docker_mem_total_inactive_file The amount of anonymous inactive file cache gauge Bytes docker_mem_total_mapped_file Memory mapped by the processes in the control group gauge Bytes docker_mem_total_rss Memory that doesn\u2019t correspond to disk, heaps, and anon gauge Bytes docker_mem_total_swap Total amount of containers swapped memory gauge Bytes docker_mem_total_unevictable The amount of memory that cannot be reclaimed gauge Bytes docker_rx_dropped_eth0 RX dropped traffic rate None docker_rx_errors_eth0 RX network errors rate None docker_rx_packets_eth0 RX packets rate None docker_tx_dropped_eth0 TX dropped traffic rate None docker_tx_errors_eth0 TX network errors rate None docker_tx_packets_eth0 TX packets rate None If details is set to False, these metrics will be collected from containers. Name Description Type Unit docker_bytes_rx_eth0 Amounts of received bytes rate Bytes docker_bytes_tx_eth0 Amounts of sent bytes rate Bytes docker_container_cpu_usage Containers CPU usage gauge Percent docker_cpu_throttled_periods Throttled Periods of containers CPU counter Milliseconds docker_cpu_throttled_time Throttled time in milliseconds of containers CPU counter Milliseconds docker_master_cpu_usage Master CPU usage in percent gauge Percent docker_mem_cur_usage Containers current memory usage gauge Bytes docker_mem_max_usage Containers max memory usage gauge Bytes Each of metrics contains container TAG which is ether container ID or Name. If prettynames parameter in config file is set to False, you will see long container ID's at container TAG of dashboard Containers Memory utilization In order to be able to track containers memory utilization cgroup_enable=memory kernel parameter should be set at Servers boot. Because memory control via cgroups is resource intensive operation, most of Linux distributions, disables it by default. So make sure that server is booted with cgroup_enable=memory parameter, otherwise container's memory utilization metrics will not available. To enable Kernel control via cgroups add following parameters to /etc/default/grub. GRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\" Run update-grub and reboot server. Otherwise just set memstats: False in conf/docker.ini .","title":"Provides"},{"location":"agent/elastic/","text":"Agent supports 2 modules for ElasticSearch monitoring: check_elasticsearch.py check_elasticsearch1x.py For Clusters of ElasticSearch 1.xx version use check_elasticsearch1x.py (deprecated). ElasticSearch 2.xx and higher : check_elasticsearch.py module. You cannot use both modules on the same machine at the same time. In order to enable ElasticSearch, copy or symlink checks_available to checks_enabled and restart Agent ElasticSearch v1 and v2+ have different monitoring API's and thus links for getting statistics are different. Both checks will be obvious at {AGENT_HOME}/config/bigdata.ini for configuration options. ElasticSearch Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_elasticsearch.py ./ Configure [ElasticSearch] host : http://127.0.0.1:9200 stats : /_nodes/_local/stats Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit elasticsearch_fetch_time rated time spent on fetching rate Milliseconds elasticsearch_fetch_total Total time spent on fetching gauge Milliseconds elasticsearch_gc_old_count Old generation garbage collections count rate None elasticsearch_gc_old_time_ms Old generation garbage collections time gauge Milliseconds elasticsearch_gc_young_count Young generation garbage collections count rate None elasticsearch_gc_young_time_ms Young generation garbage collections time gauge Milliseconds elasticsearch_get_time rated time spent on getting rate Milliseconds elasticsearch_get_total rated time spent on getting gauge Milliseconds elasticsearch_heap_commited ElasticSearch JVM heap committed gauge Bytes elasticsearch_heap_used ElasticSearch JVM heap used gauge Bytes elasticsearch_http_connections Current HTTP connections count gauge None elasticsearch_index_time rated time spent on indexing rate Milliseconds elasticsearch_index_total Total time spent on indexing gauge Milliseconds elasticsearch_merge_docs Amount of merged docs per second gauge None elasticsearch_merge_size Size of merged docs per second rate Bytes elasticsearch_merge_time Time spent on merging rate Milliseconds elasticsearch_non_heap_commited ElasticSearch non JVM heap committed gauge Bytes elasticsearch_non_heap_used ElasticSearch non JVM heap used gauge Bytes elasticsearch_open_files ElasticSearch daemon open files descriptors count gauge None elasticsearch_query_cache_evictions Query cache evictions count per second gauge None elasticsearch_query_cache_hit Query cache hits count per second gauge None elasticsearch_query_query_cache_mis Query cache miss count per second gauge None elasticsearch_refresh_time rated time spent on refreshing rate Bytes elasticsearch_refresh_total Total time spent on refreshing rate Milliseconds elasticsearch_search_search_time rated time spent on searching rate Bytes elasticsearch_search_total Total time spent on searching rate Milliseconds elasticsearch_cluster_docs Total Amount of docs in cluster gauge None elasticsearch_cluster_ingest_rate rate of inserting documents rate OPS elasticsearch_cluster_shards Total Amount of shards in cluster gauge None elasticsearch_cluster_storage_usage Cluster wide storage usage gauge Bytes ElasticSearch 1.x Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_elasticsearch1x.py ./ Configure [ElasticSearch] host : http://127.0.0.1:9200 stats : /_nodes/_local/stats/?all=true Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit elasticsearch_fetch_time rated time spent on fetching rate Milliseconds elasticsearch_fetch_total Total time spent on fetching gauge Milliseconds elasticsearch_filter_cache_evictions Evictions per second from filter cache rate None elasticsearch_gc_old_count Old generation garbage collections count gauge None elasticsearch_gc_old_time_ms Time spent on Old generation garbage collections since last check gauge Milliseconds elasticsearch_gc_young_count Young generation garbage collections count gauge None elasticsearch_gc_young_time_ms Time spent on Young generation garbage collections since last check gauge Milliseconds elasticsearch_get_time rated time spent on getting rate Milliseconds elasticsearch_get_total Total time spent on getting gauge Milliseconds elasticsearch_heap_committed ElasticSearch JVM heap committed gauge Bytes elasticsearch_heap_used ElasticSearch JVM heap used gauge Bytes elasticsearch_http_connections Current HTTP connections count gauge None elasticsearch_index_time rated time spent on indexing rate Milliseconds elasticsearch_index_total Total time spent on indexing gauge Milliseconds elasticsearch_merge_docs Amount of merged docs per second rate None elasticsearch_merge_size Size of merged docs per second rate Bytes elasticsearch_merge_time Time spent on merging rate Milliseconds elasticsearch_non_heap_committed ElasticSearch non JVM heap committed gauge Bytes elasticsearch_non_heap_used ElasticSearch non JVM heap used gauge Bytes elasticsearch_open_files ElasticSearch daemon open files descriptors count gauge None elasticsearch_refresh_time rated time spent on refreshing rate Milliseconds elasticsearch_refresh_total Total time spent on refreshing gauge Milliseconds elasticsearch_search_search_time rated time spent on searching rate Milliseconds elasticsearch_search_total Total time spent on searching gauge Milliseconds elasticsearch_cluster_docs Total Amount of docs in cluster gauge None elasticsearch_cluster_ingest_rate rate of inserting documents rate OPS elasticsearch_cluster_shards Total Amount of shards in cluster gauge None elasticsearch_cluster_storage_usage Cluster wide storage usage gauge Bytes","title":"ElasticSearch"},{"location":"agent/elastic/#elasticsearch","text":"","title":"ElasticSearch"},{"location":"agent/elastic/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_elasticsearch.py ./","title":"Install"},{"location":"agent/elastic/#configure","text":"[ElasticSearch] host : http://127.0.0.1:9200 stats : /_nodes/_local/stats","title":"Configure"},{"location":"agent/elastic/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/elastic/#provides","text":"Name Description Type Unit elasticsearch_fetch_time rated time spent on fetching rate Milliseconds elasticsearch_fetch_total Total time spent on fetching gauge Milliseconds elasticsearch_gc_old_count Old generation garbage collections count rate None elasticsearch_gc_old_time_ms Old generation garbage collections time gauge Milliseconds elasticsearch_gc_young_count Young generation garbage collections count rate None elasticsearch_gc_young_time_ms Young generation garbage collections time gauge Milliseconds elasticsearch_get_time rated time spent on getting rate Milliseconds elasticsearch_get_total rated time spent on getting gauge Milliseconds elasticsearch_heap_commited ElasticSearch JVM heap committed gauge Bytes elasticsearch_heap_used ElasticSearch JVM heap used gauge Bytes elasticsearch_http_connections Current HTTP connections count gauge None elasticsearch_index_time rated time spent on indexing rate Milliseconds elasticsearch_index_total Total time spent on indexing gauge Milliseconds elasticsearch_merge_docs Amount of merged docs per second gauge None elasticsearch_merge_size Size of merged docs per second rate Bytes elasticsearch_merge_time Time spent on merging rate Milliseconds elasticsearch_non_heap_commited ElasticSearch non JVM heap committed gauge Bytes elasticsearch_non_heap_used ElasticSearch non JVM heap used gauge Bytes elasticsearch_open_files ElasticSearch daemon open files descriptors count gauge None elasticsearch_query_cache_evictions Query cache evictions count per second gauge None elasticsearch_query_cache_hit Query cache hits count per second gauge None elasticsearch_query_query_cache_mis Query cache miss count per second gauge None elasticsearch_refresh_time rated time spent on refreshing rate Bytes elasticsearch_refresh_total Total time spent on refreshing rate Milliseconds elasticsearch_search_search_time rated time spent on searching rate Bytes elasticsearch_search_total Total time spent on searching rate Milliseconds elasticsearch_cluster_docs Total Amount of docs in cluster gauge None elasticsearch_cluster_ingest_rate rate of inserting documents rate OPS elasticsearch_cluster_shards Total Amount of shards in cluster gauge None elasticsearch_cluster_storage_usage Cluster wide storage usage gauge Bytes","title":"Provides"},{"location":"agent/elastic/#elasticsearch-1x","text":"","title":"ElasticSearch 1.x"},{"location":"agent/elastic/#install_1","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_elasticsearch1x.py ./","title":"Install"},{"location":"agent/elastic/#configure_1","text":"[ElasticSearch] host : http://127.0.0.1:9200 stats : /_nodes/_local/stats/?all=true","title":"Configure"},{"location":"agent/elastic/#restart_1","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/elastic/#provides_1","text":"Name Description Type Unit elasticsearch_fetch_time rated time spent on fetching rate Milliseconds elasticsearch_fetch_total Total time spent on fetching gauge Milliseconds elasticsearch_filter_cache_evictions Evictions per second from filter cache rate None elasticsearch_gc_old_count Old generation garbage collections count gauge None elasticsearch_gc_old_time_ms Time spent on Old generation garbage collections since last check gauge Milliseconds elasticsearch_gc_young_count Young generation garbage collections count gauge None elasticsearch_gc_young_time_ms Time spent on Young generation garbage collections since last check gauge Milliseconds elasticsearch_get_time rated time spent on getting rate Milliseconds elasticsearch_get_total Total time spent on getting gauge Milliseconds elasticsearch_heap_committed ElasticSearch JVM heap committed gauge Bytes elasticsearch_heap_used ElasticSearch JVM heap used gauge Bytes elasticsearch_http_connections Current HTTP connections count gauge None elasticsearch_index_time rated time spent on indexing rate Milliseconds elasticsearch_index_total Total time spent on indexing gauge Milliseconds elasticsearch_merge_docs Amount of merged docs per second rate None elasticsearch_merge_size Size of merged docs per second rate Bytes elasticsearch_merge_time Time spent on merging rate Milliseconds elasticsearch_non_heap_committed ElasticSearch non JVM heap committed gauge Bytes elasticsearch_non_heap_used ElasticSearch non JVM heap used gauge Bytes elasticsearch_open_files ElasticSearch daemon open files descriptors count gauge None elasticsearch_refresh_time rated time spent on refreshing rate Milliseconds elasticsearch_refresh_total Total time spent on refreshing gauge Milliseconds elasticsearch_search_search_time rated time spent on searching rate Milliseconds elasticsearch_search_total Total time spent on searching gauge Milliseconds elasticsearch_cluster_docs Total Amount of docs in cluster gauge None elasticsearch_cluster_ingest_rate rate of inserting documents rate OPS elasticsearch_cluster_shards Total Amount of shards in cluster gauge None elasticsearch_cluster_storage_usage Cluster wide storage usage gauge Bytes","title":"Provides"},{"location":"agent/etcd/","text":"Etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. Configuration of etcd check is stored k8s.ini file in conf directory. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_etcd.py ./ Configure If you are using default installation of etcd service, no additional configuration is needed. If you need to monitor etc in non default location, edit conf/k8s.ini section etcd and set metrics parameter with value matching your needs. [etcd] metrics : http://127.0.0.1:2379/metrics Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit etcd_debugging_mvcc_db_compaction_pause_duration_milliseconds_count DB compaction pause duration. count Milliseconds etcd_debugging_mvcc_db_compaction_pause_duration_milliseconds_sum DB compaction pause duration. counter Milliseconds etcd_debugging_mvcc_db_compaction_total_duration_milliseconds_count DB compaction total duration. count Milliseconds etcd_debugging_mvcc_db_compaction_total_duration_milliseconds_sum DB compaction total duration. counter Milliseconds etcd_debugging_mvcc_index_compaction_pause_duration_milliseconds_count Index compaction pause duration. count Milliseconds etcd_debugging_mvcc_index_compaction_pause_duration_milliseconds_sum Index compaction pause duration. counter Milliseconds etcd_debugging_snap_save_marshalling_duration_seconds_count The marshalling cost distributions of save called by snapshot. count Seconds etcd_debugging_snap_save_marshalling_duration_seconds_sum The marshalling cost distributions of save called by snapshot. counter Seconds etcd_debugging_snap_save_total_duration_seconds_count The total latency distributions of save called by snapshot. count Seconds etcd_debugging_snap_save_total_duration_seconds_sum The total latency distributions of save called by snapshot. counter Seconds etcd_disk_backend_commit_duration_seconds_count The latency distributions of commit called by backend. count Seconds etcd_disk_backend_commit_duration_seconds_sum The latency distributions of commit called by backend. counter Seconds etcd_disk_backend_defrag_duration_seconds_count The latency distribution of backend defragmentation. count Seconds etcd_disk_backend_defrag_duration_seconds_sum The latency distribution of backend defragmentation. counter Seconds etcd_disk_backend_snapshot_duration_seconds_count The latency distribution of backend snapshots. count Seconds etcd_disk_backend_snapshot_duration_seconds_sum The latency distribution of backend snapshots. counter Seconds etcd_disk_wal_fsync_duration_seconds_count The latency distributions of fsync called by wal. count Seconds etcd_disk_wal_fsync_duration_seconds_sum The latency distributions of fsync called by wal. counter Seconds etcd_go_gc_duration_seconds_count A summary of the GC invocation durations count Seconds etcd_go_gc_duration_seconds_sum A summary of the GC invocation durations counter Seconds etcd_mvcc_hash_duration_seconds_count The latency distribution of storage hash operation. count Seconds etcd_mvcc_hash_duration_seconds_sum The latency distribution of storage hash operation. counter Seconds etcd_mvcc_hash_rev_duration_seconds_count The latency distribution of storage hash by revision operation. count Seconds etcd_mvcc_hash_rev_duration_seconds_sum The latency distribution of storage hash by revision operation. counter Seconds etcd_process_cpu_seconds_total Total user and system CPU time spent in seconds counter Seconds etcd_process_max_fds Maximum number of open file descriptors gauge None etcd_process_open_fds Number of open file descriptors gauge None etcd_process_resident_memory_bytes Resident memory size in bytes. gauge Bytes etcd_process_start_time_seconds Start time of the process since unix epoch in seconds. gauge Seconds etcd_process_virtual_memory_bytes Virtual memory size in bytes. gauge Bytes etcd_snap_db_fsync_duration_seconds_count The latency distributions of fsyncing .snap.db file count Seconds etcd_snap_db_fsync_duration_seconds_sum The latency distributions of fsyncing .snap.db file counter Seconds etcd_snap_db_save_total_duration_seconds_count The total latency distributions of v3 snapshot save count Seconds etcd_snap_db_save_total_duration_seconds_sum The total latency distributions of v3 snapshot save count Seconds","title":"Etcd"},{"location":"agent/etcd/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_etcd.py ./","title":"Install"},{"location":"agent/etcd/#configure","text":"If you are using default installation of etcd service, no additional configuration is needed. If you need to monitor etc in non default location, edit conf/k8s.ini section etcd and set metrics parameter with value matching your needs. [etcd] metrics : http://127.0.0.1:2379/metrics","title":"Configure"},{"location":"agent/etcd/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/etcd/#provides","text":"Name Description Type Unit etcd_debugging_mvcc_db_compaction_pause_duration_milliseconds_count DB compaction pause duration. count Milliseconds etcd_debugging_mvcc_db_compaction_pause_duration_milliseconds_sum DB compaction pause duration. counter Milliseconds etcd_debugging_mvcc_db_compaction_total_duration_milliseconds_count DB compaction total duration. count Milliseconds etcd_debugging_mvcc_db_compaction_total_duration_milliseconds_sum DB compaction total duration. counter Milliseconds etcd_debugging_mvcc_index_compaction_pause_duration_milliseconds_count Index compaction pause duration. count Milliseconds etcd_debugging_mvcc_index_compaction_pause_duration_milliseconds_sum Index compaction pause duration. counter Milliseconds etcd_debugging_snap_save_marshalling_duration_seconds_count The marshalling cost distributions of save called by snapshot. count Seconds etcd_debugging_snap_save_marshalling_duration_seconds_sum The marshalling cost distributions of save called by snapshot. counter Seconds etcd_debugging_snap_save_total_duration_seconds_count The total latency distributions of save called by snapshot. count Seconds etcd_debugging_snap_save_total_duration_seconds_sum The total latency distributions of save called by snapshot. counter Seconds etcd_disk_backend_commit_duration_seconds_count The latency distributions of commit called by backend. count Seconds etcd_disk_backend_commit_duration_seconds_sum The latency distributions of commit called by backend. counter Seconds etcd_disk_backend_defrag_duration_seconds_count The latency distribution of backend defragmentation. count Seconds etcd_disk_backend_defrag_duration_seconds_sum The latency distribution of backend defragmentation. counter Seconds etcd_disk_backend_snapshot_duration_seconds_count The latency distribution of backend snapshots. count Seconds etcd_disk_backend_snapshot_duration_seconds_sum The latency distribution of backend snapshots. counter Seconds etcd_disk_wal_fsync_duration_seconds_count The latency distributions of fsync called by wal. count Seconds etcd_disk_wal_fsync_duration_seconds_sum The latency distributions of fsync called by wal. counter Seconds etcd_go_gc_duration_seconds_count A summary of the GC invocation durations count Seconds etcd_go_gc_duration_seconds_sum A summary of the GC invocation durations counter Seconds etcd_mvcc_hash_duration_seconds_count The latency distribution of storage hash operation. count Seconds etcd_mvcc_hash_duration_seconds_sum The latency distribution of storage hash operation. counter Seconds etcd_mvcc_hash_rev_duration_seconds_count The latency distribution of storage hash by revision operation. count Seconds etcd_mvcc_hash_rev_duration_seconds_sum The latency distribution of storage hash by revision operation. counter Seconds etcd_process_cpu_seconds_total Total user and system CPU time spent in seconds counter Seconds etcd_process_max_fds Maximum number of open file descriptors gauge None etcd_process_open_fds Number of open file descriptors gauge None etcd_process_resident_memory_bytes Resident memory size in bytes. gauge Bytes etcd_process_start_time_seconds Start time of the process since unix epoch in seconds. gauge Seconds etcd_process_virtual_memory_bytes Virtual memory size in bytes. gauge Bytes etcd_snap_db_fsync_duration_seconds_count The latency distributions of fsyncing .snap.db file count Seconds etcd_snap_db_fsync_duration_seconds_sum The latency distributions of fsyncing .snap.db file counter Seconds etcd_snap_db_save_total_duration_seconds_count The total latency distributions of v3 snapshot save count Seconds etcd_snap_db_save_total_duration_seconds_sum The total latency distributions of v3 snapshot save count Seconds","title":"Provides"},{"location":"agent/fdb/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_foundationdb.py ./ Configure Configuration of FoundationDB check is located at bigdata.ini . You only need to set right path for fdbcli binary, by default for packaged installation it is /usr/bin/fdbcli . If you have compilled FoundationDB from source or used oher mechanism to install it, just locate fdbcli change default path in config file. Restart Agent. ./puypuy.sh restart check_foundationdb module should run without making changes in configuration, but according to your specific needs, you can edit conf/bindata.ini and make changes in section FoundationDB [FoundationDB] fdbclipath : /usr/bin/fdbcli Provides Name Description Type Unit fdb_bytes_read Bytes read from FoundationDB rate Bytes fdb_bytes_written Bytes written to FoundationDB rate Bytes fdb_connected_clients Connected clients gauge None fdb_keys_read FoundationDB read key per second rate OPS fdb_latency_commit_seconds Latency of Commits gauge Millisecond fdb_latency_read_seconds Latency of Reads gauge Millisecond fdb_least_operating_space_bytes_log_server Least operating space bytes log server gauge Bytes fdb_least_operating_space_bytes_storage_server Least operating space bytes Storage server gauge Bytes fdb_memory_committed_bytes FoundationDB committed memory gauge Bytes fdb_memory_free_bytes FoundationDB free memory gauge Bytes fdb_memory_total_bytes FoundationDB total memory gauge Bytes fdb_moving_data Data which is being moved rate Bytes fdb_operations_read_requests Read requests per second rate OPS fdb_operations_reads Reads per second rate OPS fdb_partitions_count Amount of partitions gauge None fdb_partitions_size_avg Average size of partition gauge Bytes fdb_total_disk_used_bytes Used disk bytes gauge Bytes fdb_total_kv_size_bytes Size of key/values gauge Bytes fdb_transactions_conflicted Amount of conflicted transactions gauge None fdb_transactions_started Started transactions gauge None fdb_worst_queue_bytes_log_server Size of worst queue log server gauge Bytes fdb_worst_queue_bytes_storage_server Size of worst queue storage server gauge Bytes","title":"FoundationDB"},{"location":"agent/fdb/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_foundationdb.py ./","title":"Install"},{"location":"agent/fdb/#configure","text":"Configuration of FoundationDB check is located at bigdata.ini . You only need to set right path for fdbcli binary, by default for packaged installation it is /usr/bin/fdbcli . If you have compilled FoundationDB from source or used oher mechanism to install it, just locate fdbcli change default path in config file. Restart Agent. ./puypuy.sh restart check_foundationdb module should run without making changes in configuration, but according to your specific needs, you can edit conf/bindata.ini and make changes in section FoundationDB [FoundationDB] fdbclipath : /usr/bin/fdbcli","title":"Configure"},{"location":"agent/fdb/#provides","text":"Name Description Type Unit fdb_bytes_read Bytes read from FoundationDB rate Bytes fdb_bytes_written Bytes written to FoundationDB rate Bytes fdb_connected_clients Connected clients gauge None fdb_keys_read FoundationDB read key per second rate OPS fdb_latency_commit_seconds Latency of Commits gauge Millisecond fdb_latency_read_seconds Latency of Reads gauge Millisecond fdb_least_operating_space_bytes_log_server Least operating space bytes log server gauge Bytes fdb_least_operating_space_bytes_storage_server Least operating space bytes Storage server gauge Bytes fdb_memory_committed_bytes FoundationDB committed memory gauge Bytes fdb_memory_free_bytes FoundationDB free memory gauge Bytes fdb_memory_total_bytes FoundationDB total memory gauge Bytes fdb_moving_data Data which is being moved rate Bytes fdb_operations_read_requests Read requests per second rate OPS fdb_operations_reads Reads per second rate OPS fdb_partitions_count Amount of partitions gauge None fdb_partitions_size_avg Average size of partition gauge Bytes fdb_total_disk_used_bytes Used disk bytes gauge Bytes fdb_total_kv_size_bytes Size of key/values gauge Bytes fdb_transactions_conflicted Amount of conflicted transactions gauge None fdb_transactions_started Started transactions gauge None fdb_worst_queue_bytes_log_server Size of worst queue log server gauge Bytes fdb_worst_queue_bytes_storage_server Size of worst queue storage server gauge Bytes","title":"Provides"},{"location":"agent/hadoop/","text":"Hadoop Monitoring with Puypuy Puypuy uses Hadoop's native JMX-to-JSON HTTP interface to gather performance metrics from both the NameNode and DataNodes in an HDFS cluster. All Hadoop-related checks share a single configuration file: hadoop.ini . \ud83d\udfe6 HDFS NameNode \ud83d\udd27 Installation cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hadoop_namenode.py ./ In production environments, the NameNode typically listens on a non-loopback interface. Ensure you use the correct external IP address of the NameNode: \u2699\ufe0f Configuration [Hadoop-NameNode] jmx = http://${NAMENODE_IP}:50070/jmx \ud83d\udd04 Restart Agent ${ PUYPUY_HOME } /puypuy.sh restart \ud83d\udcca Metrics Provided Name Description Type Unit namenode_addblockops Adblock operations per second rate OPS namenode_blockcapacity HDFS Block Capacity gauge None namenode_blockstotal HDFS Total blocks gauge None namenode_capacityremaining HDFS remaining free space gauge Bytes namenode_capacitytotal HDFS Total capacity gauge Bytes namenode_capacityused HDFS Used space gauge Bytes namenode_corruptblocks HDFS corrupt blocks gauge None namenode_createfileops NameNode Create file operations on nameNode rate OPS namenode_deletefileops NameNode Delete file operations on nameNode rate OPS namenode_fileinfoops NameNode File information requests rate OPS namenode_filesdeleted NameNode deleted files rate OPS namenode_filesrenamed NameNode rename file operations rate OPS namenode_filestotal Amount of files in HDFS gauge None namenode_getblocklocations NameNode Get Block Location operations rate OPS namenode_getlistingops NameNode Get LIsting operations rate OPS namenode_heap_committed Java Heap memory committed gauge Bytes namenode_heap_init Java Heap memory init gauge Bytes namenode_heap_max Java Heap memory max gauge Bytes namenode_heap_used Java Heap memory used gauge Bytes namenode_lastgc_duration Last garbage collections duration gauge Milliseconds namenode_missingblocks NameNode missing blocks gauge None namenode_nondfsusedspace Non HDFS disk space usage gauge Bytes namenode_nonheap_committed Java Non Heap memory committed gauge Bytes namenode_nonheap_init Java Non Heap memory init gauge Bytes namenode_nonheap_max Java Non Heap memory max gauge Bytes namenode_nonheap_used Java Non Heap memory used gauge Bytes namenode_numdeaddatanodes Number of dead DataNodes in cluster gauge None namenode_numdecomdeaddatanodes Number of decommissioned dead DataNodes in cluster gauge None namenode_numdecomlivedatanodes Number of decommissioned live DataNodes in cluster gauge None namenode_numdecommissioningdatanodes Number of decommissioning DataNodes in cluster gauge None namenode_numlivedatanodes Number of live DataNodes in cluster gauge None namenode_numstaledatanodes Number of stale DataNodes in cluster gauge None namenode_numstalestorages Number of staled Storages in cluster gauge None namenode_openfiledescriptorcount NaeNode process open files descriptors count gauge None namenode_pendingreplicationblocks Amount of pending for replication blocks in HDFS gauge None namenode_percentremaining HDFS Storage space remaining gauge Percent namenode_receivedbytes Namenode received bytes gauge Bytes namenode_scheduledreplicationblocks Amount of blocks scheduled for replication gauge None namenode_sentbytes NameNode sent bytes gauge Bytes namenode_transactionsnumops NameNode transactions count gauge None namenode_underreplicatedblocks HDFS under replicated blocks count gauge None \ud83d\udfe9 HDFS DataNode Most DataNode installations bind to 0.0.0.0:50075, so no custom configuration is typically required. \ud83d\udd27 Installation cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hadoop_datanode.py ./ \u2699\ufe0f Configuration Usually HDFS DataNode binds on 0.0.0.0:50075, so no extra configuration is needed. If you have specific case, please make sure to change 127.0.0.1 to IP address matching you DataNode bind address. [Hadoop-Datanode] jmx : http://127.0.0.1:50075/jmx \ud83d\udd04 Restart Agent ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit datanode_bytesread DataNode read bytes per second rate Bytes datanode_byteswritten DataNode write bytes per second rate Bytes datanode_capacity Disk space on current DataNode gauge Bytes datanode_dfsused Current DataNode\u2019s used disk space gauge Bytes datanode_du_percent Current DataNodes disk usage in percents gauge Percent datanode_heap_committed DataNode JVM heap committed gauge Bytes datanode_heap_init DataNode JVM heap init gauge Bytes datanode_heap_max DataNode JVM Heap max gauge Bytes datanode_heap_used DataNode JVM heap used gauge Bytes datanode_lastgc_duration Duration of last garbage collection gauge Milliseconds datanode_nonheap_committed DataNode JVM non heap committed gauge Bytes datanode_nonheap_init DataNode JVM non Heap init gauge Bytes datanode_nonheap_max DataNode JVM non heap max gauge Bytes datanode_nonheap_used Datanode JVM non Heap used gauge Bytes datanode_openfiles Datanode daemon\u2019s open files descriptors count gauge None datanode_space_remaining Disk space remaining on current DataNode gauge Bytes datanode_totalreadtime Read operations time on current DataNode rate Milliseconds datanode_totalwritetime Write operations time on current DataNode rate Milliseconds \ud83d\udca1 Best Practices \ud83d\udd10 Security: Always restrict \u055d/jmx\u055d to internal networks or use firewalls. \ud83d\udcc8 Dashboards: Visualize metrics in Grafana or similar for better observability. \ud83d\udea8 Troubleshooting: Watch for high GC times, under-replication, or dead DataNodes as early warnings of cluster instability. \ud83d\udcc8 Example Grafana Dashboard","title":"Hadoop"},{"location":"agent/hadoop/#hadoop-monitoring-with-puypuy","text":"Puypuy uses Hadoop's native JMX-to-JSON HTTP interface to gather performance metrics from both the NameNode and DataNodes in an HDFS cluster. All Hadoop-related checks share a single configuration file: hadoop.ini .","title":"Hadoop Monitoring with Puypuy"},{"location":"agent/hadoop/#hdfs-namenode","text":"","title":"\ud83d\udfe6 HDFS NameNode"},{"location":"agent/hadoop/#installation","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hadoop_namenode.py ./ In production environments, the NameNode typically listens on a non-loopback interface. Ensure you use the correct external IP address of the NameNode: \u2699\ufe0f Configuration [Hadoop-NameNode] jmx = http://${NAMENODE_IP}:50070/jmx \ud83d\udd04 Restart Agent ${ PUYPUY_HOME } /puypuy.sh restart \ud83d\udcca Metrics Provided Name Description Type Unit namenode_addblockops Adblock operations per second rate OPS namenode_blockcapacity HDFS Block Capacity gauge None namenode_blockstotal HDFS Total blocks gauge None namenode_capacityremaining HDFS remaining free space gauge Bytes namenode_capacitytotal HDFS Total capacity gauge Bytes namenode_capacityused HDFS Used space gauge Bytes namenode_corruptblocks HDFS corrupt blocks gauge None namenode_createfileops NameNode Create file operations on nameNode rate OPS namenode_deletefileops NameNode Delete file operations on nameNode rate OPS namenode_fileinfoops NameNode File information requests rate OPS namenode_filesdeleted NameNode deleted files rate OPS namenode_filesrenamed NameNode rename file operations rate OPS namenode_filestotal Amount of files in HDFS gauge None namenode_getblocklocations NameNode Get Block Location operations rate OPS namenode_getlistingops NameNode Get LIsting operations rate OPS namenode_heap_committed Java Heap memory committed gauge Bytes namenode_heap_init Java Heap memory init gauge Bytes namenode_heap_max Java Heap memory max gauge Bytes namenode_heap_used Java Heap memory used gauge Bytes namenode_lastgc_duration Last garbage collections duration gauge Milliseconds namenode_missingblocks NameNode missing blocks gauge None namenode_nondfsusedspace Non HDFS disk space usage gauge Bytes namenode_nonheap_committed Java Non Heap memory committed gauge Bytes namenode_nonheap_init Java Non Heap memory init gauge Bytes namenode_nonheap_max Java Non Heap memory max gauge Bytes namenode_nonheap_used Java Non Heap memory used gauge Bytes namenode_numdeaddatanodes Number of dead DataNodes in cluster gauge None namenode_numdecomdeaddatanodes Number of decommissioned dead DataNodes in cluster gauge None namenode_numdecomlivedatanodes Number of decommissioned live DataNodes in cluster gauge None namenode_numdecommissioningdatanodes Number of decommissioning DataNodes in cluster gauge None namenode_numlivedatanodes Number of live DataNodes in cluster gauge None namenode_numstaledatanodes Number of stale DataNodes in cluster gauge None namenode_numstalestorages Number of staled Storages in cluster gauge None namenode_openfiledescriptorcount NaeNode process open files descriptors count gauge None namenode_pendingreplicationblocks Amount of pending for replication blocks in HDFS gauge None namenode_percentremaining HDFS Storage space remaining gauge Percent namenode_receivedbytes Namenode received bytes gauge Bytes namenode_scheduledreplicationblocks Amount of blocks scheduled for replication gauge None namenode_sentbytes NameNode sent bytes gauge Bytes namenode_transactionsnumops NameNode transactions count gauge None namenode_underreplicatedblocks HDFS under replicated blocks count gauge None","title":"\ud83d\udd27 Installation"},{"location":"agent/hadoop/#hdfs-datanode","text":"Most DataNode installations bind to 0.0.0.0:50075, so no custom configuration is typically required. \ud83d\udd27 Installation cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hadoop_datanode.py ./ \u2699\ufe0f Configuration Usually HDFS DataNode binds on 0.0.0.0:50075, so no extra configuration is needed. If you have specific case, please make sure to change 127.0.0.1 to IP address matching you DataNode bind address. [Hadoop-Datanode] jmx : http://127.0.0.1:50075/jmx \ud83d\udd04 Restart Agent ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit datanode_bytesread DataNode read bytes per second rate Bytes datanode_byteswritten DataNode write bytes per second rate Bytes datanode_capacity Disk space on current DataNode gauge Bytes datanode_dfsused Current DataNode\u2019s used disk space gauge Bytes datanode_du_percent Current DataNodes disk usage in percents gauge Percent datanode_heap_committed DataNode JVM heap committed gauge Bytes datanode_heap_init DataNode JVM heap init gauge Bytes datanode_heap_max DataNode JVM Heap max gauge Bytes datanode_heap_used DataNode JVM heap used gauge Bytes datanode_lastgc_duration Duration of last garbage collection gauge Milliseconds datanode_nonheap_committed DataNode JVM non heap committed gauge Bytes datanode_nonheap_init DataNode JVM non Heap init gauge Bytes datanode_nonheap_max DataNode JVM non heap max gauge Bytes datanode_nonheap_used Datanode JVM non Heap used gauge Bytes datanode_openfiles Datanode daemon\u2019s open files descriptors count gauge None datanode_space_remaining Disk space remaining on current DataNode gauge Bytes datanode_totalreadtime Read operations time on current DataNode rate Milliseconds datanode_totalwritetime Write operations time on current DataNode rate Milliseconds \ud83d\udca1 Best Practices \ud83d\udd10 Security: Always restrict \u055d/jmx\u055d to internal networks or use firewalls. \ud83d\udcc8 Dashboards: Visualize metrics in Grafana or similar for better observability. \ud83d\udea8 Troubleshooting: Watch for high GC times, under-replication, or dead DataNodes as early warnings of cluster instability. \ud83d\udcc8 Example Grafana Dashboard","title":"\ud83d\udfe9 HDFS DataNode"},{"location":"agent/hashicorp/","text":"Nomad Nomad exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_hashicorp_nomad_py to checks_enabled and restart Agent. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hashicorp_nomad_py ./ Configure At most of cases there is no need to configure Agent , but if you have non default installation of Nomad, or if you need to monitor remote Nomad, edit conf/hashicorp.ini and make your changes at Hashicorp-Nomad section. Nomad also exposes metrics per running job, which fo some installations can create tens even hundreds os metrics. If you do not want to monitor these metrics set jobstats: False st config file. [Hashicorp-Nomad] telemetery : http://127.0.0.1:4646/v1/metrics jobstats : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit nomad_client_allocated_cpu Total amount of CPU shares the scheduler has allocated to task gauge MHz nomad_client_unallocated_cpu Total amount of CPU shares free for the scheduler to allocate to tasks gauge MHz nomad_client_allocated_memory Total amount of memory the scheduler has allocated to tasks gauge Megabytes nomad_client_unallocated_memory Total amount of memory free for the scheduler to allocate to tasks gauge Megabytes nomad_client_allocated_disk Total amount of disk space the scheduler has allocated to tasks gauge Megabytes nomad_client_unallocated_disk Total amount of disk space free for the scheduler to allocate to tasks gauge Megabytes nomad_client_allocated_network Total amount of bandwidth the scheduler has allocated to tasks on the given device gauge Megabits nomad_client_unallocated_network Total amount of bandwidth free for the scheduler to allocate to tasks on the given device gauge Megabits nomad_job_summary_queued Number of queued allocations for a job gauge None nomad_job_summary_complete Number of complete allocations for a job gauge None nomad_job_summary_failed Number of failed allocations for a job gauge None nomad_job_summary_running Number of running allocations for a job gauge None nomad_job_summary_starting Number of starting allocations for a job gauge None nomad_job_summary_lost Number of lost allocations for a job gauge None nomad_runtime_num_goroutines Number of goroutines and general load pressure indicator gauge None nomad_runtime_alloc_bytes Memory utilization gauge Bytes nomad_runtime_heap_objects Number of objects on the heap. General memory pressure indicator gauge None nomad_heartbeat_active Number of active heartbeat timers. Each timer represents a Nomad Client connection gauge None Consul Consul exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_hashicorp_consul_py to checks_enabled and restart Agent. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hashicorp_consul_py ./ Configure At most of cases there is no need to configure Agent , but if you have non default installation of Consul, or if you need to monitor remote Consul, edit conf/hashicorp.ini and make your changes at Hashicorp-Consul section. Consul also exposes detailed metrics, with rates and counters, so if youwant to see these metrics set detailed: True for getting rated stats set getrates: True [Hashicorp-Consul] telemetery : http://127.0.0.1:8500/v1/agent/metrics detailed : True getrates : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit consul_memberlist_tcp_connect This metric counts the number of times an agent has initiated a push/pull sync with an other agent. counter integer consul_memberlist_tcp_sent This metric measures the total number of bytes sent by an agent through the TCP protocol. counter bytes consul_memberlist_udp_received This metric measures the total number of bytes received by an agent through the UDP protocol. counter bytes consul_memberlist_udp_sent This metric measures the total number of bytes sent by an agent through the UDP protocol. counter bytes consul_rpc_accept_conn This metric counts the number of RPC prorocol accepted connections counter integer consul_rpc_request This metric counts the number of RPC prorocol requests counter integer consul_runtime_alloc_bytes This metric measures runtime bytes allocated by Agent counter bytes consul_runtime_free_count This metric measures runtime bytes freed by Agent counter bytes consul_runtime_heap_objects This metric measures amount of objects in Agent's heap counter bytes consul_runtime_sys_bytes This metric measures runtime system bytes freed by Agent counter bytes consul_runtime_total_gc_pause_ns This metric measures Agent's GC pauses. counter nanosecond consul_runtime_total_gc_runs This metric measures Agent's GC runs. counter integer consul_session_ttl_active This metric measures active TTL sessions. counter integer Detailed Name Description Type Unit consul_fsm.coordinate.batch.update This measures the time it takes to apply the given batch coordinate update to the FSM. gauge millisecond consul_http_get_v1_agent_checks This metric gives the number Agen'ts check HTTP GET requests rate\\counter integer consul_http_get_v1_agent_metrics This metric gives the number Agen'ts metric HTTP GET requests rate\\counter integer consul_http_get_v1_agent_self This metric gives the number Agen'ts self HTTP GET requests rate\\counter integer consul_http_get_v1_agent_services This metric gives the number Agen'ts service HTTP GET requests rate\\counter integer consul_memberlist_gossip This metric gives the number of gossips (messages) broadcasted to a set of randomly selected nodes. rate\\counter integer consul_memberlist_probenode This metric measures the time taken to perform a single round of failure detection on a select agent. rate\\counter integer consul_raft_fsm_apply This metric gives the number of logs committed since the last interval. rate\\counter integer consul_raft_rpc_appendentries This metric measures the time taken to process an append entries RPC call from an agent. rate\\counter millisecond consul_raft_rpc_appendentries_processlogs This metric measures the time taken to add any outstanding logs for an agent, since the last appendEntries was invoked rate\\counter millisecond consul_raft_rpc_appendentries_storelogs This metric measures the time taken to process the outstanding log entries of an agent. rate\\counter millisecond consul_raft_rpc_processheartbeat This metric measures the time taken to process a heartbeat request. rate\\counter millisecond consul_runtime_gc_pause_ns This metric measures the Golang GC runtime pauses. rate\\counter millisecond consul_serf_coordinate_adjustment_ms This metric measures the coordinate adjustments in milliseconds. rate\\counter millisecond consul_serf_queue_event This metric measures events in sef queue. rate\\counter integer consul_serf_queue_intent This metric measures intents in sef queue. rate\\counter integer consul_serf_queue_query This metric measures queries in sef queue. rate\\counter integer Vault Vault exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_hashicorp_consul_py to checks_enabled and restart Agent. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hashicorp_vault_py ./ Configure At most of cases there is no need to change telemetry link, but if you have non default installation of Vault, or if you need to monitor remote Vault, edit conf/hashicorp.ini and make your changes at Hashicorp-Vault section. Also it is very important to set correct token in config file, or Vault will deny requests from PuyPuy Agent Vault also exposes detailed metrics, with rates and counters, so if youwant to see these metrics set detailed: True for getting rated stats set getrates: True [Hashicorp-Vault] telemetery : http://127.0.0.1:8200/v1/sys/metrics token : s.HqQb7CFNBT1wHWLHD0DrOx6P detailed : True getrates : False Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit vault_expire_num_leases This metric gives the number of expired leases. gauge integer vault_runtime_alloc_bytes This metric shows amount of memory allocated by Vault process. gauge Bytes vault_runtime_free_count This metric shows Number of freed objects gauge integer vault_runtime_heap_objects This metric gives the number of objects in Vaulr process's heap. gauge integer vault_runtime_malloc_count This metric shows cumulative count of allocated heap objects gauge integer vault_runtime_num_goroutines Number of goroutines and general load pressure indicator gauge None vault_runtime_sys_bytes This includes what is being used by Vault's heap and what has been reclaimed but not given back to the operating system. gauge Bytes vault_runtime_total_gc_pause_ns This metric measures the Golang GC runtime pauses. counter millisecond vault_runtime_total_gc_runs This metric measures Agent's GC runs. counter integer Detailed Name Description Type Unit vault_audit_log_request Duration of time taken by all audit log requests across all audit log devices counter\\rate milliseconds vault_audit_log_response Duration of time taken by audit log responses across all audit log devices counter\\rate milliseconds vault_barrier_get Duration of time taken by GET operations at the barrier counter\\rate milliseconds vault_barrier_put Duration of time taken by PUT operations at the barrier counter\\rate milliseconds vault_barrier_delete Duration of time taken by DELETE operations at the barrier counter\\rate milliseconds vault_barrier_list Duration of time taken by LIST operations at the barrier counter\\rate milliseconds vault_core_check_token Duration of time taken by token checks handled by Vault core counter\\rate milliseconds vault_core_fetch_acl_and_token Duration of time taken by ACL and corresponding token entry fetches handled by Vault core counter\\rate milliseconds vault_core_handle_request Duration of time taken by requests handled by Vault core counter\\rate milliseconds vault_policy_get_policy Time taken to GET a policy counter\\rate milliseconds vault_policy_list_policy Time taken to LIST a policy counter\\rate milliseconds vault_policy_set_policy Time taken to SET a policy counter\\rate milliseconds vault_policy_delete_policy Time taken to DELETE a policy counter\\rate milliseconds vault_token_lookup The time taken to look up a token counter\\rate milliseconds vault_rollback_attempt_auth_token_ Time taken to perform a rollback operation for the token auth method counter\\rate milliseconds vault_rollback_attempt_auth_ldap_ Time taken to perform a rollback operation for the LDAP auth method counter\\rate milliseconds vault_rollback_attempt_cubbyhole_ Time taken to perform a rollback operation for the Cubbyhole secret backend counter\\rate milliseconds vault_rollback_attempt_identity_ Time taken to perform a rollback operation for the Identity backend counter\\rate milliseconds vault_rollback_attempt_secret_ Time taken to perform a rollback operation for the K/V secret backend counter\\rate milliseconds vault_rollback_attempt_sys_ Time taken to perform a rollback operation for the system backend counter\\rate milliseconds vault_route_read_sys_ Time taken to perform a route rollback operation for the system backend counter\\rate milliseconds vault_route_rollback_auth_token_ Time taken to perform a route rollback operation for the token auth method counter\\rate milliseconds vault_route_rollback_cubbyhole_ Time taken to perform a route rollback operation for the Cubbyhole secret backend counter\\rate milliseconds vault_route_rollback_identity_ Time taken to perform a route rollback operation for the Identity counter\\rate milliseconds vault_route_rollback_secret_ Time taken to perform a route rollback operation for the K/V secret backend counter\\rate milliseconds vault_route_rollback_sys_ Time taken to perform a route rollback operation for the system backend counter\\rate milliseconds vault_route_rollback_ldap_ Time taken to perform a route rollback operation for the LDAP auth method counter\\rate milliseconds","title":"Hashicorp"},{"location":"agent/hashicorp/#nomad","text":"Nomad exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_hashicorp_nomad_py to checks_enabled and restart Agent.","title":"Nomad"},{"location":"agent/hashicorp/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hashicorp_nomad_py ./","title":"Install"},{"location":"agent/hashicorp/#configure","text":"At most of cases there is no need to configure Agent , but if you have non default installation of Nomad, or if you need to monitor remote Nomad, edit conf/hashicorp.ini and make your changes at Hashicorp-Nomad section. Nomad also exposes metrics per running job, which fo some installations can create tens even hundreds os metrics. If you do not want to monitor these metrics set jobstats: False st config file. [Hashicorp-Nomad] telemetery : http://127.0.0.1:4646/v1/metrics jobstats : True","title":"Configure"},{"location":"agent/hashicorp/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/hashicorp/#provides","text":"Name Description Type Unit nomad_client_allocated_cpu Total amount of CPU shares the scheduler has allocated to task gauge MHz nomad_client_unallocated_cpu Total amount of CPU shares free for the scheduler to allocate to tasks gauge MHz nomad_client_allocated_memory Total amount of memory the scheduler has allocated to tasks gauge Megabytes nomad_client_unallocated_memory Total amount of memory free for the scheduler to allocate to tasks gauge Megabytes nomad_client_allocated_disk Total amount of disk space the scheduler has allocated to tasks gauge Megabytes nomad_client_unallocated_disk Total amount of disk space free for the scheduler to allocate to tasks gauge Megabytes nomad_client_allocated_network Total amount of bandwidth the scheduler has allocated to tasks on the given device gauge Megabits nomad_client_unallocated_network Total amount of bandwidth free for the scheduler to allocate to tasks on the given device gauge Megabits nomad_job_summary_queued Number of queued allocations for a job gauge None nomad_job_summary_complete Number of complete allocations for a job gauge None nomad_job_summary_failed Number of failed allocations for a job gauge None nomad_job_summary_running Number of running allocations for a job gauge None nomad_job_summary_starting Number of starting allocations for a job gauge None nomad_job_summary_lost Number of lost allocations for a job gauge None nomad_runtime_num_goroutines Number of goroutines and general load pressure indicator gauge None nomad_runtime_alloc_bytes Memory utilization gauge Bytes nomad_runtime_heap_objects Number of objects on the heap. General memory pressure indicator gauge None nomad_heartbeat_active Number of active heartbeat timers. Each timer represents a Nomad Client connection gauge None","title":"Provides"},{"location":"agent/hashicorp/#consul","text":"Consul exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_hashicorp_consul_py to checks_enabled and restart Agent.","title":"Consul"},{"location":"agent/hashicorp/#install_1","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hashicorp_consul_py ./","title":"Install"},{"location":"agent/hashicorp/#configure_1","text":"At most of cases there is no need to configure Agent , but if you have non default installation of Consul, or if you need to monitor remote Consul, edit conf/hashicorp.ini and make your changes at Hashicorp-Consul section. Consul also exposes detailed metrics, with rates and counters, so if youwant to see these metrics set detailed: True for getting rated stats set getrates: True [Hashicorp-Consul] telemetery : http://127.0.0.1:8500/v1/agent/metrics detailed : True getrates : True","title":"Configure"},{"location":"agent/hashicorp/#restart_1","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/hashicorp/#provides_1","text":"Name Description Type Unit consul_memberlist_tcp_connect This metric counts the number of times an agent has initiated a push/pull sync with an other agent. counter integer consul_memberlist_tcp_sent This metric measures the total number of bytes sent by an agent through the TCP protocol. counter bytes consul_memberlist_udp_received This metric measures the total number of bytes received by an agent through the UDP protocol. counter bytes consul_memberlist_udp_sent This metric measures the total number of bytes sent by an agent through the UDP protocol. counter bytes consul_rpc_accept_conn This metric counts the number of RPC prorocol accepted connections counter integer consul_rpc_request This metric counts the number of RPC prorocol requests counter integer consul_runtime_alloc_bytes This metric measures runtime bytes allocated by Agent counter bytes consul_runtime_free_count This metric measures runtime bytes freed by Agent counter bytes consul_runtime_heap_objects This metric measures amount of objects in Agent's heap counter bytes consul_runtime_sys_bytes This metric measures runtime system bytes freed by Agent counter bytes consul_runtime_total_gc_pause_ns This metric measures Agent's GC pauses. counter nanosecond consul_runtime_total_gc_runs This metric measures Agent's GC runs. counter integer consul_session_ttl_active This metric measures active TTL sessions. counter integer Detailed Name Description Type Unit consul_fsm.coordinate.batch.update This measures the time it takes to apply the given batch coordinate update to the FSM. gauge millisecond consul_http_get_v1_agent_checks This metric gives the number Agen'ts check HTTP GET requests rate\\counter integer consul_http_get_v1_agent_metrics This metric gives the number Agen'ts metric HTTP GET requests rate\\counter integer consul_http_get_v1_agent_self This metric gives the number Agen'ts self HTTP GET requests rate\\counter integer consul_http_get_v1_agent_services This metric gives the number Agen'ts service HTTP GET requests rate\\counter integer consul_memberlist_gossip This metric gives the number of gossips (messages) broadcasted to a set of randomly selected nodes. rate\\counter integer consul_memberlist_probenode This metric measures the time taken to perform a single round of failure detection on a select agent. rate\\counter integer consul_raft_fsm_apply This metric gives the number of logs committed since the last interval. rate\\counter integer consul_raft_rpc_appendentries This metric measures the time taken to process an append entries RPC call from an agent. rate\\counter millisecond consul_raft_rpc_appendentries_processlogs This metric measures the time taken to add any outstanding logs for an agent, since the last appendEntries was invoked rate\\counter millisecond consul_raft_rpc_appendentries_storelogs This metric measures the time taken to process the outstanding log entries of an agent. rate\\counter millisecond consul_raft_rpc_processheartbeat This metric measures the time taken to process a heartbeat request. rate\\counter millisecond consul_runtime_gc_pause_ns This metric measures the Golang GC runtime pauses. rate\\counter millisecond consul_serf_coordinate_adjustment_ms This metric measures the coordinate adjustments in milliseconds. rate\\counter millisecond consul_serf_queue_event This metric measures events in sef queue. rate\\counter integer consul_serf_queue_intent This metric measures intents in sef queue. rate\\counter integer consul_serf_queue_query This metric measures queries in sef queue. rate\\counter integer","title":"Provides"},{"location":"agent/hashicorp/#vault","text":"Vault exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_hashicorp_consul_py to checks_enabled and restart Agent.","title":"Vault"},{"location":"agent/hashicorp/#install_2","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hashicorp_vault_py ./","title":"Install"},{"location":"agent/hashicorp/#configure_2","text":"At most of cases there is no need to change telemetry link, but if you have non default installation of Vault, or if you need to monitor remote Vault, edit conf/hashicorp.ini and make your changes at Hashicorp-Vault section. Also it is very important to set correct token in config file, or Vault will deny requests from PuyPuy Agent Vault also exposes detailed metrics, with rates and counters, so if youwant to see these metrics set detailed: True for getting rated stats set getrates: True [Hashicorp-Vault] telemetery : http://127.0.0.1:8200/v1/sys/metrics token : s.HqQb7CFNBT1wHWLHD0DrOx6P detailed : True getrates : False","title":"Configure"},{"location":"agent/hashicorp/#restart_2","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/hashicorp/#provides_2","text":"Name Description Type Unit vault_expire_num_leases This metric gives the number of expired leases. gauge integer vault_runtime_alloc_bytes This metric shows amount of memory allocated by Vault process. gauge Bytes vault_runtime_free_count This metric shows Number of freed objects gauge integer vault_runtime_heap_objects This metric gives the number of objects in Vaulr process's heap. gauge integer vault_runtime_malloc_count This metric shows cumulative count of allocated heap objects gauge integer vault_runtime_num_goroutines Number of goroutines and general load pressure indicator gauge None vault_runtime_sys_bytes This includes what is being used by Vault's heap and what has been reclaimed but not given back to the operating system. gauge Bytes vault_runtime_total_gc_pause_ns This metric measures the Golang GC runtime pauses. counter millisecond vault_runtime_total_gc_runs This metric measures Agent's GC runs. counter integer Detailed Name Description Type Unit vault_audit_log_request Duration of time taken by all audit log requests across all audit log devices counter\\rate milliseconds vault_audit_log_response Duration of time taken by audit log responses across all audit log devices counter\\rate milliseconds vault_barrier_get Duration of time taken by GET operations at the barrier counter\\rate milliseconds vault_barrier_put Duration of time taken by PUT operations at the barrier counter\\rate milliseconds vault_barrier_delete Duration of time taken by DELETE operations at the barrier counter\\rate milliseconds vault_barrier_list Duration of time taken by LIST operations at the barrier counter\\rate milliseconds vault_core_check_token Duration of time taken by token checks handled by Vault core counter\\rate milliseconds vault_core_fetch_acl_and_token Duration of time taken by ACL and corresponding token entry fetches handled by Vault core counter\\rate milliseconds vault_core_handle_request Duration of time taken by requests handled by Vault core counter\\rate milliseconds vault_policy_get_policy Time taken to GET a policy counter\\rate milliseconds vault_policy_list_policy Time taken to LIST a policy counter\\rate milliseconds vault_policy_set_policy Time taken to SET a policy counter\\rate milliseconds vault_policy_delete_policy Time taken to DELETE a policy counter\\rate milliseconds vault_token_lookup The time taken to look up a token counter\\rate milliseconds vault_rollback_attempt_auth_token_ Time taken to perform a rollback operation for the token auth method counter\\rate milliseconds vault_rollback_attempt_auth_ldap_ Time taken to perform a rollback operation for the LDAP auth method counter\\rate milliseconds vault_rollback_attempt_cubbyhole_ Time taken to perform a rollback operation for the Cubbyhole secret backend counter\\rate milliseconds vault_rollback_attempt_identity_ Time taken to perform a rollback operation for the Identity backend counter\\rate milliseconds vault_rollback_attempt_secret_ Time taken to perform a rollback operation for the K/V secret backend counter\\rate milliseconds vault_rollback_attempt_sys_ Time taken to perform a rollback operation for the system backend counter\\rate milliseconds vault_route_read_sys_ Time taken to perform a route rollback operation for the system backend counter\\rate milliseconds vault_route_rollback_auth_token_ Time taken to perform a route rollback operation for the token auth method counter\\rate milliseconds vault_route_rollback_cubbyhole_ Time taken to perform a route rollback operation for the Cubbyhole secret backend counter\\rate milliseconds vault_route_rollback_identity_ Time taken to perform a route rollback operation for the Identity counter\\rate milliseconds vault_route_rollback_secret_ Time taken to perform a route rollback operation for the K/V secret backend counter\\rate milliseconds vault_route_rollback_sys_ Time taken to perform a route rollback operation for the system backend counter\\rate milliseconds vault_route_rollback_ldap_ Time taken to perform a route rollback operation for the LDAP auth method counter\\rate milliseconds","title":"Provides"},{"location":"agent/hbase/","text":"HBase is an open-source non-relational distributed database modeled after Google's Bigtable and written in Java. It is developed as part of Apache Software Foundation's Apache Hadoop project and runs on top of HDFS (Hadoop Distributed File System), providing Bigtable-like capabilities for Hadoop. PuyPuy Agent uses HBase built in Json interface, to get statistics from HBase Master and RegionServers Configuration file for HBase plugin is hadoop.ini . HBase Master Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hbase_master.py ./ Configure Usually HBase Master binds on 0.0.0.0:60010, so no extra configuration is needed. If you have specific case, please make sure to change 127.0.0.1 to IP address matching you HBase Master's bind address. [HBase-Master] jmx : http://127.0.0.1:60010/jmx Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit hmaster_exceptions General Exceptions counter None hmaster_exceptions_failedsanitycheck Failed Sanity Check Exception counter None hmaster_exceptions_multiresponsetoolarge Multi Response Too Large Exception counter None hmaster_exceptions_outoforderscannernext Out Of Order Scanner Next Exception counter None hmaster_exceptions_regionmoved Region Moved Exception counter None hmaster_exceptions_regiontoobusy Region Too Busy Exception counter None hmaster_exceptions_unknownscanner Unknown Scanner Exception counter None hmaster_heap_committed Hbase Master JVM heap committed gauge Byte hmaster_heap_init Hbase Master JVM heap init gauge Byte hmaster_heap_max Hbase Master JVM heap max gauge Byte hmaster_heap_used Hbase Master JVM heap used gauge Byte hmaster_heap_{parnew/g1_young}_lastgcinfo G1 Youg or ParNew last Garbage collections time gauge Milliseconds hmaster_heap_{cms/g1_old}_lastgcInfo G1 Old or CMS last last Garbage collection time gauge Milliseconds hmaster_node_averageload HBase cluster's load average gauge None hmaster_node_clusterrequests Hbase cluster wide requests per second rate OPS hmaster_node_gccount Hbase Master garbace collections count counter None hmaster_node_gctimemillis Hbase Master garbage collections pause time gauge Milliseconds hmaster_node_numdeadregionservers Number of dead Region Servers gauge None hmaster_node_numregionservers Number of Region Servers gauge None hmaster_node_ritcount The number of regions in transition gauge None hmaster_node_ritcountoverthreshold The number of regions that have been in transition longer than a threshold time gauge None hmaster_node_ritoldestage The age of the longest region in transition in milliseconds gauge hregion_node_memstoresize Size in bytes of Memstore gauge bytes hregion_node_regioncount Amount of regions running on monitored RegionServer gauge None hregion_node_storefilesize Size in bytes of StoreFile gauge bytes hregion_node_storefilecount Amount of Store Files on monitored RegionServer gauge None hregion_node_hlogfilecount Amount of HLog Files on monitored RegionServer gauge None hregion_node_hlogfilesize Size in bytes of HLog Files gauge bytes hregion_node_percentfileslocal HDFS data locality percentage gauge Percent hregion_node_blockcounthitpercent Percents of Block Cache hits gauge Percent HBase RegionServer Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hbase_regionserver.py ./ Configure Usually HBase RegionServer binds on 0.0.0.0:60030, so no extra configuration is needed. If you have specific case, please make sure to change 127.0.0.1 to IP address matching you HBase Master's bind address. [HBase-Region] jmx : http://127.0.0.1:60030/jmx Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit hregion_heap_cms_lastgcinfo Duration of previous CMS garbage collection gauge Milliseconds hregion_heap_g1_old_lastgcinfo Duration of previous G1 old generation garbage collection gauge Milliseconds hregion_heap_parnew_lastgcinfo Duration of previous ParNew garbage collection gauge Milliseconds hregion_heap_g1_young_lastgcinfo Duration of previous G1 young generation garbage collection gauge Milliseconds hregion_heap_committed HBase RegionServer JVM heap committed gauge Bytes hregion_heap_init HBase RegionServer JVM heap init gauge Bytes hregion_heap_max HBase RegionServer JVM heap max gauge Bytes hregion_heap_used HBase RegionServer JVM heap used gauge Bytes hregion_node_blockcachecount Block cache items count gauge None hregion_node_blockcacheevictioncount Block cache evictions count gauge None hregion_node_blockcacheexpresshitpercent Block cache express hits count rate OPS hregion_node_blockcachefreesize Block cache free size in bytes gauge Bytes hregion_node_blockcachehitcount Block cache hits count per second rate OPS hregion_node_blockcachemisscount Block cache misses count per second rate OPS hregion_node_blockcachesize Block cache size in bytes gauge Bytes hregion_node_blockcounthitpercent Block cache hits percent gauge Percent hregion_node_compactedcellscount Minor compacted cells count per second rate OPS hregion_node_compactedcellssize Minor compacted bytes rate Bytes hregion_node_majorcompactedcellscount Major compacted cells count per second rate Bytes hregion_node_majorcompactedcellssize Major compacted bytes rate Bytes hregion_node_gctimemillis rated affect of last Garbage collection for performed checks interval rate Milliseconds hregion_node_gccount Completed garbage collections counter integer hregion_node_openfiledescriptorcount Linux open files descriptors count by RegionServer\u2019s daemon gauge integer hregion_node_delete_num_ops Number of delete operations performed by current RegionServer per second rate OPS hregion_node_flushtime_num_ops Number of flush operations performed by current RegionServer per second rate OPS hregion_node_mutate_num_ops Number of mutate operations performed by current RegionServer per second rate OPS hregion_node_readrequestcount Number of read operations performed by current RegionServer per second rate OPS hregion_node_slowappendcount Number of slow append operations performed by current RegionServer per second rate OPS hregion_node_slowdeletecount Number of slow delete operations performed by current RegionServer per second rate OPS hregion_node_slowgetcount Number of slow get operations performed by current RegionServer per second rate OPS hregion_node_slowincrementcount Number of slow increment operations performed by current RegionServer per second rate OPS hregion_node_slowputcount Number of slow put operations performed by current RegionServer per second rate OPS hregion_node_totalrequestcount Total requests per second executed on current RegionServer rate OPS hregion_node_writerequestcount Writes per second executed on current RegionServer rate OPS Hedged Reads (If enabled) Name Description Type Unit hregion_node_hedgedreads Number of started Hedged Read operation counter None hregion_node_hedgedreadwins Number of Hedged Read operation which returned values faster that normal reads counter None HBase Thrift & REST Install cd { AGENT_HOME } /checks_enabled/ ln -s ../checks_available/check_hbase_rest.py ./ cd { AGENT_HOME } /checks_enabled/ ln -s ../checks_available/check_hbase_thrift.py ./ Configure Here is sample config which should be fine for most of HBase installations: Default config parameters are suitable for most of installtions. But if your services are running on different IP address or port, just change parameters below to match your installtion . [HBase-Thrift] jmx : http://127.0.0.1:9095/jmx [HBase-Rest] jmx : http://127.0.0.1:9095/jmx HBase REST Provides Name Description Type Unit hrest_daemonthreadcount Running Daemon threads count gauge None hrest_faileddelete Failed Deletes per second rate OPS hrest_failedget Failed Gets per second rate OPS hrest_failedput Failed Puts per second rate OPS hrest_failedscancount Failed Scans per second rate OPS hrest_heap_committed Hbase REST server\u2019s JVM heap committed gauge Bytes hrest_heap_max Hbase REST server\u2019s JVM heap max gauge Bytes hrest_heap_used Hbase REST server\u2019s JVM heap used gauge Bytes hrest_nonheap_committed Hbase REST server\u2019s JVM non heap committed gauge Bytes hrest_nonheap_max Hbase REST server\u2019s JVM npn heap max gauge Bytes hrest_nonheap_used Hbase REST server\u2019s JVM non heap used gauge Bytes hrest_pausetimewithgc_90th_percentile Garbage collectors pause time 90th percentile gauge Milliseconds hrest_pausetimewithgc_99th_percentile Garbage collectors pause time 99th percentile gauge Milliseconds hrest_pausetimewithoutgc_90th_percentile Garbage collectors without pause time 90th percentile gauge Milliseconds hrest_pausetimewithoutgc_99th_percentile Garbage collectors without pause time 99th percentile gauge Milliseconds hrest_peakthreadcount Peak running Daemon threads count gauge None hrest_requests Total requests count executed on this REST gateway counter None hrest_successfuldelete Successful delete requests per second executed on this REST gateway counter None hrest_successfulget Successful get requests count executed on this REST gateway counter None hrest_successfulput Successful Put requests count executed on this REST gateway counter None hrest_successfulscancount Successful Scan requests count executed on this REST gateway counter None hrest_threadcount REST gateway\u2019s running threads count gauge None hrest_totalstartedthreadcount REST gateway\u2019s total threads count counter None HBase Thrift Provides Name Description Type Unit hthrift_batchget Batch gets per second rate OPS hthrift_batchmutate Batch mutates per second rate OPS hthrift_callqueuelen Length of Thrift queue gauge Integer hthrift_(cms,g1_old)_lastgcinfo Duration of last CMS, G1 Old gen garbage collection current Milliseconds hthrift_daemonthreadcount Running Daemon threads count gauge Integer hthrift_heap_committed JVM heap committed gauge Bytes hthrift_heap_init JVM heap Init gauge Bytes hthrift_heap_max JVM heap Max gauge Bytes hthrift_heap_used JVM heap Used gauge Bytes hthrift_parnew_lastgcinfo Duration of last ParNew, G1 Young gen garbage collection current Milliseconds hthrift_pausetimewithgc_90th_percentile 90th percentile of GC pause time with GC current Milliseconds hthrift_pausetimewithgc_99th_percentile 99th percentile of GC pause time with GC current Milliseconds hthrift_pausetimewithoutgc_90th_percentile 90th percentile of GC pause time without GC current Milliseconds hthrift_pausetimewithoutgc_99th_percentile 99th percentile of GC pause time without GC current Milliseconds hthrift_peakthreadcount Thrift gateway\u2019s peak running threads count gauge Integer hthrift_slowthriftcall Slow calls rate OPS hthrift_threadcount Thrift gateway\u2019s running threads count gauge Integer hthrift_thriftcall Amount of thrift calls rate OPS hthrift_timeinqueue_num_ops Amount of time object were in Thrift queue rate OPS hthrift_totalstartedthreadcount Thrift gateway\u2019s total threads count gauge Integer","title":"HBase"},{"location":"agent/hbase/#hbase-master","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hbase_master.py ./ Configure Usually HBase Master binds on 0.0.0.0:60010, so no extra configuration is needed. If you have specific case, please make sure to change 127.0.0.1 to IP address matching you HBase Master's bind address. [HBase-Master] jmx : http://127.0.0.1:60010/jmx Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit hmaster_exceptions General Exceptions counter None hmaster_exceptions_failedsanitycheck Failed Sanity Check Exception counter None hmaster_exceptions_multiresponsetoolarge Multi Response Too Large Exception counter None hmaster_exceptions_outoforderscannernext Out Of Order Scanner Next Exception counter None hmaster_exceptions_regionmoved Region Moved Exception counter None hmaster_exceptions_regiontoobusy Region Too Busy Exception counter None hmaster_exceptions_unknownscanner Unknown Scanner Exception counter None hmaster_heap_committed Hbase Master JVM heap committed gauge Byte hmaster_heap_init Hbase Master JVM heap init gauge Byte hmaster_heap_max Hbase Master JVM heap max gauge Byte hmaster_heap_used Hbase Master JVM heap used gauge Byte hmaster_heap_{parnew/g1_young}_lastgcinfo G1 Youg or ParNew last Garbage collections time gauge Milliseconds hmaster_heap_{cms/g1_old}_lastgcInfo G1 Old or CMS last last Garbage collection time gauge Milliseconds hmaster_node_averageload HBase cluster's load average gauge None hmaster_node_clusterrequests Hbase cluster wide requests per second rate OPS hmaster_node_gccount Hbase Master garbace collections count counter None hmaster_node_gctimemillis Hbase Master garbage collections pause time gauge Milliseconds hmaster_node_numdeadregionservers Number of dead Region Servers gauge None hmaster_node_numregionservers Number of Region Servers gauge None hmaster_node_ritcount The number of regions in transition gauge None hmaster_node_ritcountoverthreshold The number of regions that have been in transition longer than a threshold time gauge None hmaster_node_ritoldestage The age of the longest region in transition in milliseconds gauge hregion_node_memstoresize Size in bytes of Memstore gauge bytes hregion_node_regioncount Amount of regions running on monitored RegionServer gauge None hregion_node_storefilesize Size in bytes of StoreFile gauge bytes hregion_node_storefilecount Amount of Store Files on monitored RegionServer gauge None hregion_node_hlogfilecount Amount of HLog Files on monitored RegionServer gauge None hregion_node_hlogfilesize Size in bytes of HLog Files gauge bytes hregion_node_percentfileslocal HDFS data locality percentage gauge Percent hregion_node_blockcounthitpercent Percents of Block Cache hits gauge Percent","title":"HBase Master"},{"location":"agent/hbase/#hbase-regionserver","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_hbase_regionserver.py ./ Configure Usually HBase RegionServer binds on 0.0.0.0:60030, so no extra configuration is needed. If you have specific case, please make sure to change 127.0.0.1 to IP address matching you HBase Master's bind address. [HBase-Region] jmx : http://127.0.0.1:60030/jmx Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit hregion_heap_cms_lastgcinfo Duration of previous CMS garbage collection gauge Milliseconds hregion_heap_g1_old_lastgcinfo Duration of previous G1 old generation garbage collection gauge Milliseconds hregion_heap_parnew_lastgcinfo Duration of previous ParNew garbage collection gauge Milliseconds hregion_heap_g1_young_lastgcinfo Duration of previous G1 young generation garbage collection gauge Milliseconds hregion_heap_committed HBase RegionServer JVM heap committed gauge Bytes hregion_heap_init HBase RegionServer JVM heap init gauge Bytes hregion_heap_max HBase RegionServer JVM heap max gauge Bytes hregion_heap_used HBase RegionServer JVM heap used gauge Bytes hregion_node_blockcachecount Block cache items count gauge None hregion_node_blockcacheevictioncount Block cache evictions count gauge None hregion_node_blockcacheexpresshitpercent Block cache express hits count rate OPS hregion_node_blockcachefreesize Block cache free size in bytes gauge Bytes hregion_node_blockcachehitcount Block cache hits count per second rate OPS hregion_node_blockcachemisscount Block cache misses count per second rate OPS hregion_node_blockcachesize Block cache size in bytes gauge Bytes hregion_node_blockcounthitpercent Block cache hits percent gauge Percent hregion_node_compactedcellscount Minor compacted cells count per second rate OPS hregion_node_compactedcellssize Minor compacted bytes rate Bytes hregion_node_majorcompactedcellscount Major compacted cells count per second rate Bytes hregion_node_majorcompactedcellssize Major compacted bytes rate Bytes hregion_node_gctimemillis rated affect of last Garbage collection for performed checks interval rate Milliseconds hregion_node_gccount Completed garbage collections counter integer hregion_node_openfiledescriptorcount Linux open files descriptors count by RegionServer\u2019s daemon gauge integer hregion_node_delete_num_ops Number of delete operations performed by current RegionServer per second rate OPS hregion_node_flushtime_num_ops Number of flush operations performed by current RegionServer per second rate OPS hregion_node_mutate_num_ops Number of mutate operations performed by current RegionServer per second rate OPS hregion_node_readrequestcount Number of read operations performed by current RegionServer per second rate OPS hregion_node_slowappendcount Number of slow append operations performed by current RegionServer per second rate OPS hregion_node_slowdeletecount Number of slow delete operations performed by current RegionServer per second rate OPS hregion_node_slowgetcount Number of slow get operations performed by current RegionServer per second rate OPS hregion_node_slowincrementcount Number of slow increment operations performed by current RegionServer per second rate OPS hregion_node_slowputcount Number of slow put operations performed by current RegionServer per second rate OPS hregion_node_totalrequestcount Total requests per second executed on current RegionServer rate OPS hregion_node_writerequestcount Writes per second executed on current RegionServer rate OPS Hedged Reads (If enabled) Name Description Type Unit hregion_node_hedgedreads Number of started Hedged Read operation counter None hregion_node_hedgedreadwins Number of Hedged Read operation which returned values faster that normal reads counter None","title":"HBase RegionServer"},{"location":"agent/hbase/#hbase-thrift-rest","text":"Install cd { AGENT_HOME } /checks_enabled/ ln -s ../checks_available/check_hbase_rest.py ./ cd { AGENT_HOME } /checks_enabled/ ln -s ../checks_available/check_hbase_thrift.py ./ Configure Here is sample config which should be fine for most of HBase installations: Default config parameters are suitable for most of installtions. But if your services are running on different IP address or port, just change parameters below to match your installtion . [HBase-Thrift] jmx : http://127.0.0.1:9095/jmx [HBase-Rest] jmx : http://127.0.0.1:9095/jmx HBase REST Provides Name Description Type Unit hrest_daemonthreadcount Running Daemon threads count gauge None hrest_faileddelete Failed Deletes per second rate OPS hrest_failedget Failed Gets per second rate OPS hrest_failedput Failed Puts per second rate OPS hrest_failedscancount Failed Scans per second rate OPS hrest_heap_committed Hbase REST server\u2019s JVM heap committed gauge Bytes hrest_heap_max Hbase REST server\u2019s JVM heap max gauge Bytes hrest_heap_used Hbase REST server\u2019s JVM heap used gauge Bytes hrest_nonheap_committed Hbase REST server\u2019s JVM non heap committed gauge Bytes hrest_nonheap_max Hbase REST server\u2019s JVM npn heap max gauge Bytes hrest_nonheap_used Hbase REST server\u2019s JVM non heap used gauge Bytes hrest_pausetimewithgc_90th_percentile Garbage collectors pause time 90th percentile gauge Milliseconds hrest_pausetimewithgc_99th_percentile Garbage collectors pause time 99th percentile gauge Milliseconds hrest_pausetimewithoutgc_90th_percentile Garbage collectors without pause time 90th percentile gauge Milliseconds hrest_pausetimewithoutgc_99th_percentile Garbage collectors without pause time 99th percentile gauge Milliseconds hrest_peakthreadcount Peak running Daemon threads count gauge None hrest_requests Total requests count executed on this REST gateway counter None hrest_successfuldelete Successful delete requests per second executed on this REST gateway counter None hrest_successfulget Successful get requests count executed on this REST gateway counter None hrest_successfulput Successful Put requests count executed on this REST gateway counter None hrest_successfulscancount Successful Scan requests count executed on this REST gateway counter None hrest_threadcount REST gateway\u2019s running threads count gauge None hrest_totalstartedthreadcount REST gateway\u2019s total threads count counter None HBase Thrift Provides Name Description Type Unit hthrift_batchget Batch gets per second rate OPS hthrift_batchmutate Batch mutates per second rate OPS hthrift_callqueuelen Length of Thrift queue gauge Integer hthrift_(cms,g1_old)_lastgcinfo Duration of last CMS, G1 Old gen garbage collection current Milliseconds hthrift_daemonthreadcount Running Daemon threads count gauge Integer hthrift_heap_committed JVM heap committed gauge Bytes hthrift_heap_init JVM heap Init gauge Bytes hthrift_heap_max JVM heap Max gauge Bytes hthrift_heap_used JVM heap Used gauge Bytes hthrift_parnew_lastgcinfo Duration of last ParNew, G1 Young gen garbage collection current Milliseconds hthrift_pausetimewithgc_90th_percentile 90th percentile of GC pause time with GC current Milliseconds hthrift_pausetimewithgc_99th_percentile 99th percentile of GC pause time with GC current Milliseconds hthrift_pausetimewithoutgc_90th_percentile 90th percentile of GC pause time without GC current Milliseconds hthrift_pausetimewithoutgc_99th_percentile 99th percentile of GC pause time without GC current Milliseconds hthrift_peakthreadcount Thrift gateway\u2019s peak running threads count gauge Integer hthrift_slowthriftcall Slow calls rate OPS hthrift_threadcount Thrift gateway\u2019s running threads count gauge Integer hthrift_thriftcall Amount of thrift calls rate OPS hthrift_timeinqueue_num_ops Amount of time object were in Thrift queue rate OPS hthrift_totalstartedthreadcount Thrift gateway\u2019s total threads count gauge Integer","title":"HBase Thrift &amp; REST"},{"location":"agent/jmx/","text":"JMX All Java applications can expose metrics via JMX interface, some of them do it by default and for others it is obligatory to be configured specially for that. While JMX is great way to get statistics from Java servers, it requires Java to read it. This means, that we run Java program for each attempt to get stats or keep small Java program up and running all the time to read JMX, to convert to more common api and allow non java collector to get these stats. It is not effective and quite expensive to start and stop JVM each time, when we need to get statistics. Better way is to keep JVM running all the time, but in any case its another running JVM, which seems more expensive that we want to. To solve this problem we have decided to use Jolokia JVM agent, which can be attached to the running JVM as an agent and expose metrics via Json. {AGENT_HOME}/lib contains of Jolokia JVM agent.jar version, which works perfectly for us, but if you need fresher or just another version of it, feel free to download JVM agent jar from https://jolokia.org/download.html and replace with it the existing agent.jar file. After downloading your prefered version of Jolokia JVM agent, make sure that you have renamed it to agent.jar Jolokia agent uses Java Attach API to attach agent.jar to running JVM and get statistics via HTTP/Json. The trick is, that newest JVM's will not allow other users to attach agent to JVM. So if you are running for example Tomcat on behalf of system user tomcat (Hope you are not running Java as root !), agent.jar should be attached via tomcat user as well. To make this happen Agent must be able to execute java as user tomcat without password. Code below is an example of how /etc/sudoers will be configured : puypuy ALL = (tomcat) NOPASSWD: /opt/java/bin/java Change puypuy , tomcat and /opt/java/bin/java to actual values for your system. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jmx.py ./ Configure To attach agent to running JVM, Agent needs to know the main class name, which is used to run your java application server. If you already do not know main class name, you can get it via command below. cd { AGENT_HOME } java -jar lib/agent.jar list Output of it should be : {PID} {MAIN_CLASS} {Something_else} 15425 org.apache.catalina.startup.Bootstrap start 28240 org.apache.hadoop.hbase.rest.RESTServer start 14759 org.apache.hadoop.hbase.thrift.ThriftServer start Above are examples of main classes for Tomcat, HBase Thrift and HBase Rest. Typically main class name should be in second column of output. Edit conf/java.ini and put correct fields in section [JMX] [JMX] jmx : http://127.0.0.1:7777/puypuy/read user : tomcat class : org.apache.catalina.startup.Bootstrap java : /opt/java/bin/java Restart ${ PUYPUY_HOME } /puypuy.sh restart If configuration is correct, after restarting Agent daemon, you would see that your existing Java program magically started to listen TCP:7777 and exposes JMX via HTTP/Json. You can change port to whatever you prefer, but do not change context path ot IP address. Provides Name Description Type Unit jmx_daemonthreadcount Amount of running java daemon threads gauge None jmx_gc_collectioncount Java garbage collections count counter None jmx_gc_collectiontime Time spend on GC during last iteration rate Milliseconds jmx_heap_committed Committed Java Heap Memory gauge Bytes jmx_heap_max Max Java Heap Memory gauge Bytes jmx_heap_used Used Java Heap Memory gauge Bytes jmx_lastgcinfo Last GC duration gauge Milliseconds jmx_nonheap_committed Committed Java Non Heap Memory gauge Bytes jmx_nonheap_max Max Java Non Heap Memory gauge Bytes jmx_nonheap_used Used Java Non Heap Memory gauge Bytes jmx_peakthreadcount Peak amount of running Java Threads gauge None jmx_threadcount Total amount of started threads counter None","title":"Java JMX"},{"location":"agent/jmx/#jmx","text":"All Java applications can expose metrics via JMX interface, some of them do it by default and for others it is obligatory to be configured specially for that. While JMX is great way to get statistics from Java servers, it requires Java to read it. This means, that we run Java program for each attempt to get stats or keep small Java program up and running all the time to read JMX, to convert to more common api and allow non java collector to get these stats. It is not effective and quite expensive to start and stop JVM each time, when we need to get statistics. Better way is to keep JVM running all the time, but in any case its another running JVM, which seems more expensive that we want to. To solve this problem we have decided to use Jolokia JVM agent, which can be attached to the running JVM as an agent and expose metrics via Json. {AGENT_HOME}/lib contains of Jolokia JVM agent.jar version, which works perfectly for us, but if you need fresher or just another version of it, feel free to download JVM agent jar from https://jolokia.org/download.html and replace with it the existing agent.jar file. After downloading your prefered version of Jolokia JVM agent, make sure that you have renamed it to agent.jar Jolokia agent uses Java Attach API to attach agent.jar to running JVM and get statistics via HTTP/Json. The trick is, that newest JVM's will not allow other users to attach agent to JVM. So if you are running for example Tomcat on behalf of system user tomcat (Hope you are not running Java as root !), agent.jar should be attached via tomcat user as well. To make this happen Agent must be able to execute java as user tomcat without password. Code below is an example of how /etc/sudoers will be configured : puypuy ALL = (tomcat) NOPASSWD: /opt/java/bin/java Change puypuy , tomcat and /opt/java/bin/java to actual values for your system.","title":"JMX"},{"location":"agent/jmx/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jmx.py ./","title":"Install"},{"location":"agent/jmx/#configure","text":"To attach agent to running JVM, Agent needs to know the main class name, which is used to run your java application server. If you already do not know main class name, you can get it via command below. cd { AGENT_HOME } java -jar lib/agent.jar list Output of it should be : {PID} {MAIN_CLASS} {Something_else} 15425 org.apache.catalina.startup.Bootstrap start 28240 org.apache.hadoop.hbase.rest.RESTServer start 14759 org.apache.hadoop.hbase.thrift.ThriftServer start Above are examples of main classes for Tomcat, HBase Thrift and HBase Rest. Typically main class name should be in second column of output. Edit conf/java.ini and put correct fields in section [JMX] [JMX] jmx : http://127.0.0.1:7777/puypuy/read user : tomcat class : org.apache.catalina.startup.Bootstrap java : /opt/java/bin/java","title":"Configure"},{"location":"agent/jmx/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart If configuration is correct, after restarting Agent daemon, you would see that your existing Java program magically started to listen TCP:7777 and exposes JMX via HTTP/Json. You can change port to whatever you prefer, but do not change context path ot IP address.","title":"Restart"},{"location":"agent/jmx/#provides","text":"Name Description Type Unit jmx_daemonthreadcount Amount of running java daemon threads gauge None jmx_gc_collectioncount Java garbage collections count counter None jmx_gc_collectiontime Time spend on GC during last iteration rate Milliseconds jmx_heap_committed Committed Java Heap Memory gauge Bytes jmx_heap_max Max Java Heap Memory gauge Bytes jmx_heap_used Used Java Heap Memory gauge Bytes jmx_lastgcinfo Last GC duration gauge Milliseconds jmx_nonheap_committed Committed Java Non Heap Memory gauge Bytes jmx_nonheap_max Max Java Non Heap Memory gauge Bytes jmx_nonheap_used Used Java Non Heap Memory gauge Bytes jmx_peakthreadcount Peak amount of running Java Threads gauge None jmx_threadcount Total amount of started threads counter None","title":"Provides"},{"location":"agent/jolokia/","text":"Jolokia Nowadays world's the most popular programming language is Java. There are mumereos servers running Java, and all they need to be monitored. While Agent have integraton with Java JMX, in some cases JMX cannot be enabled on Servlet Container, because of political or any other reason. Because of all these cases we have developed Servlet Containers monitoring module, based on Jolokia WAR agent. Jolokia WAR agent can be deployed on any Java Servlet Container like Tomcat, Jetty, Jboss etc ... It will transform JMX mbeans to friendly Json format and expose it via standard HTTP interface. Jolkia developers describe Jolokia as: JMX-HTTP bridge giving an alternative to JSR-160 connectors. It is an agent based approach with support for many platforms. In addition to basic JMX operations it enhances JMX remoting with unique features like bulk requests and fine grained security policies. So in general, Jolokia is a small Open Source application, which makes DevOps lives easy for monitoring any kind of Java based servers. Its can be dynamically attached to running Java process via Java Attache API as well, as statically included to CLASSPATH or installed as stand alone web application. We use Jolokia in number of our checks check_jmx (Java Attach API) check _hbase_rest (Java Attach API) check_hbase_thrift (Java Attach API) chech_cassandra (By including to CLASSPATH) chech_elasticsearch (By including to CLASSPATH) chech_kafka (By including to CLASSPATH) check_jolokia (As stand alone web app) Curent manual is about installing Jolokia WAR-Agent, which runs as stand alone web application at your Servlet Engine. Installation of Jolokia and check_jolokia is very easy : In order to deploy Jolokia WAR-Agent, you should download it from https://jolokia.org/download.html and place to webapps folder. Depending on your Servlet container, it will be auto deployed, or you shall deploy it manually in accordance to Container deployment rules. After the deployment of Jolokia to you Server, you can enable check_jolokia module. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jolokia ./ Configure Depending on your setup and jolokia-version, the metrics will be exposed trough http://HOST:PORT/jolokia-war-X.X.X/read Edit conf/java.ini with conducting changes in section Jolokia [Jolokia] jolokia : http://127.0.0.1:8888/jolokia-war-1.3.5/read Provides As jolokia check is very generic, it will take only metrics provided by java.lang mbean. Name Description Type Unit jolokia_daemonthreadcount Amount of running java daemon threads gauge None jolokia_gc_collectioncount Java garbage collections count counter None jolokia_gc_collectiontime Time spend on GC during last iteration rate Milliseconds jolokia_heap_committed Committed Java Heap Memory gauge Bytes jolokia_heap_max Max Java Heap Memory gauge Bytes jolokia_heap_used Used Java Heap Memory gauge Bytes jolokia_lastgcinfo Last GC duration gauge Milliseconds jolokia_nonheap_committed Committed Java Non Heap Memory gauge Bytes jolokia_nonheap_max Max Java Non Heap Memory gauge Bytes jolokia_nonheap_used Used Java Non Heap Memory gauge Bytes jolokia_peakthreadcount Peak amount of running Java Threads gauge None jolokia_threadcount Total amount of started threads counter None All metrics will be prefixed with jolokia_ so you can easily find them in your dashboard application.","title":"Jolokia"},{"location":"agent/jolokia/#jolokia","text":"Nowadays world's the most popular programming language is Java. There are mumereos servers running Java, and all they need to be monitored. While Agent have integraton with Java JMX, in some cases JMX cannot be enabled on Servlet Container, because of political or any other reason. Because of all these cases we have developed Servlet Containers monitoring module, based on Jolokia WAR agent. Jolokia WAR agent can be deployed on any Java Servlet Container like Tomcat, Jetty, Jboss etc ... It will transform JMX mbeans to friendly Json format and expose it via standard HTTP interface. Jolkia developers describe Jolokia as: JMX-HTTP bridge giving an alternative to JSR-160 connectors. It is an agent based approach with support for many platforms. In addition to basic JMX operations it enhances JMX remoting with unique features like bulk requests and fine grained security policies. So in general, Jolokia is a small Open Source application, which makes DevOps lives easy for monitoring any kind of Java based servers. Its can be dynamically attached to running Java process via Java Attache API as well, as statically included to CLASSPATH or installed as stand alone web application. We use Jolokia in number of our checks check_jmx (Java Attach API) check _hbase_rest (Java Attach API) check_hbase_thrift (Java Attach API) chech_cassandra (By including to CLASSPATH) chech_elasticsearch (By including to CLASSPATH) chech_kafka (By including to CLASSPATH) check_jolokia (As stand alone web app) Curent manual is about installing Jolokia WAR-Agent, which runs as stand alone web application at your Servlet Engine. Installation of Jolokia and check_jolokia is very easy : In order to deploy Jolokia WAR-Agent, you should download it from https://jolokia.org/download.html and place to webapps folder. Depending on your Servlet container, it will be auto deployed, or you shall deploy it manually in accordance to Container deployment rules. After the deployment of Jolokia to you Server, you can enable check_jolokia module.","title":"Jolokia"},{"location":"agent/jolokia/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jolokia ./","title":"Install"},{"location":"agent/jolokia/#configure","text":"Depending on your setup and jolokia-version, the metrics will be exposed trough http://HOST:PORT/jolokia-war-X.X.X/read Edit conf/java.ini with conducting changes in section Jolokia [Jolokia] jolokia : http://127.0.0.1:8888/jolokia-war-1.3.5/read","title":"Configure"},{"location":"agent/jolokia/#provides","text":"As jolokia check is very generic, it will take only metrics provided by java.lang mbean. Name Description Type Unit jolokia_daemonthreadcount Amount of running java daemon threads gauge None jolokia_gc_collectioncount Java garbage collections count counter None jolokia_gc_collectiontime Time spend on GC during last iteration rate Milliseconds jolokia_heap_committed Committed Java Heap Memory gauge Bytes jolokia_heap_max Max Java Heap Memory gauge Bytes jolokia_heap_used Used Java Heap Memory gauge Bytes jolokia_lastgcinfo Last GC duration gauge Milliseconds jolokia_nonheap_committed Committed Java Non Heap Memory gauge Bytes jolokia_nonheap_max Max Java Non Heap Memory gauge Bytes jolokia_nonheap_used Used Java Non Heap Memory gauge Bytes jolokia_peakthreadcount Peak amount of running Java Threads gauge None jolokia_threadcount Total amount of started threads counter None All metrics will be prefixed with jolokia_ so you can easily find them in your dashboard application.","title":"Provides"},{"location":"agent/k8s/","text":"PuyPuy Kubernetes plugin requires up and running Kube State Metrics server Install Installation of Kube State Metrics server is easy and can be done by executing a single command : go get k8s.io/kube-state-metrics This will Install Kube State Metrics server to your $GOPATH using go get: You can find more information about More info about Kube State Metrics server here : https://github.com/kubernetes/kube-state-metrics You can run Kube State Metrics in foreground by executing : $GOPATH /bin/kube-state-metrics --port = 6868 --telemetry-port = 8081 --kubeconfig = /etc/kubernetes/admin.conf It's recommended to create systemd service and run Kube State Metrics on startup; cat > /etc/systemd/system/kube-state-metrics.service <<-EOF [Unit] Description=Kube State Metrics Documentation=https://github.com/kubernetes/kube-state-metrics Wants=network-online.target After=network-online.target [Service] ExecReload=/bin/kill -HUP $MAINPID ExecStart=/usr/local/bin/kube-state-metrics --port=6868 --telemetry-port=8081 --kubeconfig=/etc/kubernetes/admin.conf KillMode=process KillSignal=SIGINT Restart=always RestartSec=2 StartLimitBurst=3 StartLimitIntervalSec=10 TasksMax=infinity [Install] WantedBy=multi-user.target EOF Reload systemd and enable service . systemctl daemon-reload systemctl enable kube-state-metrics.service systemctl start kube-state-metrics.service Now Kube State Metrics server is controlled by systemd and will start in background during OS boot. Enable PuyPuy agent check : cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_kube_state_metrics.py ./ Configure If you are using default installation, no additional configuration is needed. If you need to monitor remote server or you Kube State Metrics server is running on different IP:PORT, edit conf/k8s.ini section kube-state-metrics and set metrics parameter with value matching your needs. You can enable/disable per pod statistics collection by setting podinfo : False/True (Default is True) [kube-state-metrics] metrics : http://127.0.0.1:6868/metrics podinfo : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type kube_deployment_status_replicas The number of replicas per deployment. gauge kube_deployment_status_replicas_available The number of available replicas per deployment. gauge kube_deployment_status_replicas_unavailable The number of unavailable replicas per deployment. gauge kube_deployment_status_replicas_updated The number of updated replicas per deployment. gauge kube_endpoint_address_available Number of addresses available in endpoint. gauge kube_pod_container_resource_limits_cpu_cores The limit on cpu cores to be used by a container. gauge kube_pod_container_resource_limits_memory_bytes The limit on memory to be used by a container in bytes. gauge kube_pod_container_status_waiting Describes whether the container is currently in waiting state. gauge","title":"Kubernetes"},{"location":"agent/k8s/#install","text":"Installation of Kube State Metrics server is easy and can be done by executing a single command : go get k8s.io/kube-state-metrics This will Install Kube State Metrics server to your $GOPATH using go get: You can find more information about More info about Kube State Metrics server here : https://github.com/kubernetes/kube-state-metrics You can run Kube State Metrics in foreground by executing : $GOPATH /bin/kube-state-metrics --port = 6868 --telemetry-port = 8081 --kubeconfig = /etc/kubernetes/admin.conf It's recommended to create systemd service and run Kube State Metrics on startup; cat > /etc/systemd/system/kube-state-metrics.service <<-EOF [Unit] Description=Kube State Metrics Documentation=https://github.com/kubernetes/kube-state-metrics Wants=network-online.target After=network-online.target [Service] ExecReload=/bin/kill -HUP $MAINPID ExecStart=/usr/local/bin/kube-state-metrics --port=6868 --telemetry-port=8081 --kubeconfig=/etc/kubernetes/admin.conf KillMode=process KillSignal=SIGINT Restart=always RestartSec=2 StartLimitBurst=3 StartLimitIntervalSec=10 TasksMax=infinity [Install] WantedBy=multi-user.target EOF Reload systemd and enable service . systemctl daemon-reload systemctl enable kube-state-metrics.service systemctl start kube-state-metrics.service Now Kube State Metrics server is controlled by systemd and will start in background during OS boot. Enable PuyPuy agent check : cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_kube_state_metrics.py ./","title":"Install"},{"location":"agent/k8s/#configure","text":"If you are using default installation, no additional configuration is needed. If you need to monitor remote server or you Kube State Metrics server is running on different IP:PORT, edit conf/k8s.ini section kube-state-metrics and set metrics parameter with value matching your needs. You can enable/disable per pod statistics collection by setting podinfo : False/True (Default is True) [kube-state-metrics] metrics : http://127.0.0.1:6868/metrics podinfo : True","title":"Configure"},{"location":"agent/k8s/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/k8s/#provides","text":"Name Description Type kube_deployment_status_replicas The number of replicas per deployment. gauge kube_deployment_status_replicas_available The number of available replicas per deployment. gauge kube_deployment_status_replicas_unavailable The number of unavailable replicas per deployment. gauge kube_deployment_status_replicas_updated The number of updated replicas per deployment. gauge kube_endpoint_address_available Number of addresses available in endpoint. gauge kube_pod_container_resource_limits_cpu_cores The limit on cpu cores to be used by a container. gauge kube_pod_container_resource_limits_memory_bytes The limit on memory to be used by a container in bytes. gauge kube_pod_container_status_waiting Describes whether the container is currently in waiting state. gauge","title":"Provides"},{"location":"agent/kafka/","text":"Apache Kafka is distributed stream processing engine, written in Java/Scala, initially developed by Linked in. Indeed it's a top level Apache foundation product. Enablling Kafka checks has two parts: Configure Kafka to expose metrics via Jolokia Kafka checks and configure Agent with Jolokia access parameters. Install At first download Jolokia jolokia-jvm-VERSION-agent.jar from https://jolokia.org/download.html and copy it to All nodes of Kafka cluster. cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar Now we need to edit kafka-server-start.sh and add javaagent JVM option: lets assume that you have installed Kafka at /opt/kafka directory. export KAFKA_OPTS = \" $KAFKA_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/opt/kafka/config/jolokia/jolokia.properties\" Jolokia Now we need to configure Jolokia: For packaged Kafka installations copy-paste of code below will do the trick. If you have tarball Kafka installation, just replace paths with actual location of your config files . mkdir /opt/kafka/config/jolokia cat > /opt/kafka/config/jolokia/jolokia.policy <<-EOF <?xml version=\"1.0\" encoding=\"utf-8\"?> <restrict> <http> <method>get</method> <method>post</method> </http> <commands> <command>read</command> <command>list</command> <command>search</command> </commands> </restrict> EOF cat > /opt/kafka/config/jolokia/jolokia.properties <<-EOF host=0.0.0.0 port=7777 agentContext=/jolokia backlog=100 policyLocation=file:///opt/kafka/config/jolokia/jolokia.policy historyMaxEntries=10 debug=false debugMaxEntries=100 maxDepth=15 maxCollectionSize=1000 maxObjects=0 EOF Restart Kafka node. Agent cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_kafka.py ./ Kafka check is enabled as any other check: so copy or symlink check_kafka.py check from checks_available to checks_enabled . Configure Edit conf/mq.ini , it already contains reasonable defaults to work out of the box, but if your Kafka and Jolokia are configured in other than described below way, just replace default parameters with desired ones. [Kafka] jolokia : http://127.0.0.1:7777/jolokia/read Restart { AGENT_HOME } /puypuy.sh restart Provides After several seconds you can start building your Kafka dashboards. Metrics will be prefixed with kafka_ . Name Description Type Unit kafka_bytesinpersec Amount of incoming bytes to Kafka node rate Bytes kafka_bytesoutpersec Amount of outgoing bytes to Kafka node rate Bytes kafka_bytesrejectedpersec Amount of rejected bytes to Kafka node rate Bytes kafka_failedfetchrequestspersec Amount of failed fetch requests to node rate OPS kafka_failedproducerequestspersec Amount of failed produce requests to node rate OPS kafka_fetch Fetches on current node rate OPS kafka_fetchconsumer Fetch consumers on current node rate OPS kafka_fetchfollower Fetch followers on current node rate OPS kafka_gc_old_collectioncount CMS or G1 Old gen garbage collections count counter None kafka_gc_old_collectiontime CMS or G1 Old gen garbage collections time rate Milliseconds kafka_gc_old_lastgcinfo CMS or G1 Old gen last garbage collections duration gauge Milliseconds kafka_gc_young_collectioncount ParNew or G1 Young gen garbage collections count rate Milliseconds kafka_gc_young_collectiontime ParNew or G1 Young gen garbage collections time rate Milliseconds kafka_gc_young_lastgcinfo ParNew or G1 Young gen last garbage collections duration gauge Milliseconds kafka_groupcoordinator Kafka group coordinators gauge None kafka_heap_committed Java Heap memory committed gauge Bytes kafka_heap_used Java Heap memory used gauge Bytes kafka_joingroup Kafka join groups rate OPS kafka_leaderandisr LeaderAndIsr requests performed ont his node rate OPS kafka_messagesinpersec Incomming messages rae to current node rate OPS kafka_nonheap_committed Java Non Heap memory committed gauge Bytes kafka_nonheap_used Java Non Heap memory used gauge Bytes kafka_offsetcommit Offset commits on current node rate OPS kafka_offsetfetch Offset fetched on current node rate OPS kafka_offsets Kafka Offsets gauge None kafka_produce Prodeucers per second on current node rate OPS kafka_totalproducerequestspersec Kafka total produced requess per second rate OPS \ud83d\udcc8 Example Grafana Dashboard","title":"Kafka"},{"location":"agent/kafka/#install","text":"At first download Jolokia jolokia-jvm-VERSION-agent.jar from https://jolokia.org/download.html and copy it to All nodes of Kafka cluster. cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar Now we need to edit kafka-server-start.sh and add javaagent JVM option: lets assume that you have installed Kafka at /opt/kafka directory. export KAFKA_OPTS = \" $KAFKA_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/opt/kafka/config/jolokia/jolokia.properties\" Jolokia Now we need to configure Jolokia: For packaged Kafka installations copy-paste of code below will do the trick. If you have tarball Kafka installation, just replace paths with actual location of your config files . mkdir /opt/kafka/config/jolokia cat > /opt/kafka/config/jolokia/jolokia.policy <<-EOF <?xml version=\"1.0\" encoding=\"utf-8\"?> <restrict> <http> <method>get</method> <method>post</method> </http> <commands> <command>read</command> <command>list</command> <command>search</command> </commands> </restrict> EOF cat > /opt/kafka/config/jolokia/jolokia.properties <<-EOF host=0.0.0.0 port=7777 agentContext=/jolokia backlog=100 policyLocation=file:///opt/kafka/config/jolokia/jolokia.policy historyMaxEntries=10 debug=false debugMaxEntries=100 maxDepth=15 maxCollectionSize=1000 maxObjects=0 EOF Restart Kafka node. Agent cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_kafka.py ./ Kafka check is enabled as any other check: so copy or symlink check_kafka.py check from checks_available to checks_enabled .","title":"Install"},{"location":"agent/kafka/#configure","text":"Edit conf/mq.ini , it already contains reasonable defaults to work out of the box, but if your Kafka and Jolokia are configured in other than described below way, just replace default parameters with desired ones. [Kafka] jolokia : http://127.0.0.1:7777/jolokia/read","title":"Configure"},{"location":"agent/kafka/#restart","text":"{ AGENT_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/kafka/#provides","text":"After several seconds you can start building your Kafka dashboards. Metrics will be prefixed with kafka_ . Name Description Type Unit kafka_bytesinpersec Amount of incoming bytes to Kafka node rate Bytes kafka_bytesoutpersec Amount of outgoing bytes to Kafka node rate Bytes kafka_bytesrejectedpersec Amount of rejected bytes to Kafka node rate Bytes kafka_failedfetchrequestspersec Amount of failed fetch requests to node rate OPS kafka_failedproducerequestspersec Amount of failed produce requests to node rate OPS kafka_fetch Fetches on current node rate OPS kafka_fetchconsumer Fetch consumers on current node rate OPS kafka_fetchfollower Fetch followers on current node rate OPS kafka_gc_old_collectioncount CMS or G1 Old gen garbage collections count counter None kafka_gc_old_collectiontime CMS or G1 Old gen garbage collections time rate Milliseconds kafka_gc_old_lastgcinfo CMS or G1 Old gen last garbage collections duration gauge Milliseconds kafka_gc_young_collectioncount ParNew or G1 Young gen garbage collections count rate Milliseconds kafka_gc_young_collectiontime ParNew or G1 Young gen garbage collections time rate Milliseconds kafka_gc_young_lastgcinfo ParNew or G1 Young gen last garbage collections duration gauge Milliseconds kafka_groupcoordinator Kafka group coordinators gauge None kafka_heap_committed Java Heap memory committed gauge Bytes kafka_heap_used Java Heap memory used gauge Bytes kafka_joingroup Kafka join groups rate OPS kafka_leaderandisr LeaderAndIsr requests performed ont his node rate OPS kafka_messagesinpersec Incomming messages rae to current node rate OPS kafka_nonheap_committed Java Non Heap memory committed gauge Bytes kafka_nonheap_used Java Non Heap memory used gauge Bytes kafka_offsetcommit Offset commits on current node rate OPS kafka_offsetfetch Offset fetched on current node rate OPS kafka_offsets Kafka Offsets gauge None kafka_produce Prodeucers per second on current node rate OPS kafka_totalproducerequestspersec Kafka total produced requess per second rate OPS \ud83d\udcc8 Example Grafana Dashboard","title":"Provides"},{"location":"agent/lizardfs/","text":"LizardFS is a high performance distributed storage system for storing massive amount of data on commodity hardware. PuyPuy Agent uses LizardFS's built in tools to expose statistics and send to PuyPuy servers. You just need to set hostname of target server and chose detalization of metrics. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_lizardfs.py ./ Configure Configuration parameters of LizardFS check are in ${PUYPUY_HOME}/bonf/bigdata.ini file [LizardFS] host : 127.0.0.1 port : 9421 chunkstats : True diskstats : True Host and port parameters points to master node. It's always a good idea to run PuyPuy Agent on target hosts, so for most of installtions these parameters can stay defaults. Other parameters enables and disabled detailed statistics of chunk servers, and disks|mountpoits Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Basic Stats Name Description Type Unit lizardfs_memory_uage Memory used by LizardFS gauge Bytes lizardfs_total_space Total space for LizardFS gauge Bytes lizardfs_available_space Available space of LizardFS gauge Bytes lizardfs_trash_space Space used by trashed files gauge Bytes lizardfs_trash_files Amount of trashed files gauge None lizardfs_reserved_space LizardFS reserved disk space gauge Bytes lizardfs_reserved_files Amount of files reserved for LizardFS gauge None lizardfs_fs_objects Amount of file system objects reserved for LizardFS gauge None lizardfs_directories Amount of directories in LizardFS gauge None lizardfs_files Amount of files in LizardFS gauge None lizardfs_chunks Amount of LizardFS chunks gauge None lizardfs_chunk_copies Amount of copies of LizardFS chunks gauge None Chunserver Stats Name Description Type Unit lizardfs_chunksrv_total_space Total space of particular chunk server gauge Bytes lizardfs_chunksrv_used_space Used space on particular chunk server gauge Bytes lizardfs_chunksrv_chunks_mfr Chunks marked for deletion on chunk server gauge Bytes lizardfs_chunksrv_space_mfr Space marked for deletion on chunk server gauge Bytes lizardfs_chunksrv_errors Errors on chunk server gauge None Disks and mountpoints Name Description Type Unit lizardfs_disk_total_space Total disk space of LizardFS by chunk server and mount point gauge Bytes lizardfs_disk_used_space Used disk space of LizardFS by chunk server and mount point gauge Bytes lizardfs_disk_chunks Amount of disk chunks by chunk server and mount point gauge Integer lizardfs_read_bytes Reads per minute by chunk server and mount point rate Bytes lizardfs_write_bytes Writes per minute by chunk server and mount point rate Bytes lizardfs_max_read_time Max read time by chunk server and mount point curent Microsecond lizardfs_max_write_time Max write time by chunk server and mount point curent Microsecond lizardfs_max_fsync_time Max file system sync time by chunk server and mount point curent Microsecond lizardfs_read_ops Read operations per minute by chunk server and mount point rate None lizardfs_write_ops Write operations pre minute by chunk server and mount point rate None lizardfs_fsync_ops File system sync operation by chunk server and mount point rate None There isn no necessity to run check_lizardfs.py on all nodes of LizardFS of cluster, statistics from all nodes can be collected from single location.","title":"LizardFS"},{"location":"agent/lizardfs/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_lizardfs.py ./","title":"Install"},{"location":"agent/lizardfs/#configure","text":"Configuration parameters of LizardFS check are in ${PUYPUY_HOME}/bonf/bigdata.ini file [LizardFS] host : 127.0.0.1 port : 9421 chunkstats : True diskstats : True Host and port parameters points to master node. It's always a good idea to run PuyPuy Agent on target hosts, so for most of installtions these parameters can stay defaults. Other parameters enables and disabled detailed statistics of chunk servers, and disks|mountpoits","title":"Configure"},{"location":"agent/lizardfs/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/lizardfs/#provides","text":"Basic Stats Name Description Type Unit lizardfs_memory_uage Memory used by LizardFS gauge Bytes lizardfs_total_space Total space for LizardFS gauge Bytes lizardfs_available_space Available space of LizardFS gauge Bytes lizardfs_trash_space Space used by trashed files gauge Bytes lizardfs_trash_files Amount of trashed files gauge None lizardfs_reserved_space LizardFS reserved disk space gauge Bytes lizardfs_reserved_files Amount of files reserved for LizardFS gauge None lizardfs_fs_objects Amount of file system objects reserved for LizardFS gauge None lizardfs_directories Amount of directories in LizardFS gauge None lizardfs_files Amount of files in LizardFS gauge None lizardfs_chunks Amount of LizardFS chunks gauge None lizardfs_chunk_copies Amount of copies of LizardFS chunks gauge None Chunserver Stats Name Description Type Unit lizardfs_chunksrv_total_space Total space of particular chunk server gauge Bytes lizardfs_chunksrv_used_space Used space on particular chunk server gauge Bytes lizardfs_chunksrv_chunks_mfr Chunks marked for deletion on chunk server gauge Bytes lizardfs_chunksrv_space_mfr Space marked for deletion on chunk server gauge Bytes lizardfs_chunksrv_errors Errors on chunk server gauge None Disks and mountpoints Name Description Type Unit lizardfs_disk_total_space Total disk space of LizardFS by chunk server and mount point gauge Bytes lizardfs_disk_used_space Used disk space of LizardFS by chunk server and mount point gauge Bytes lizardfs_disk_chunks Amount of disk chunks by chunk server and mount point gauge Integer lizardfs_read_bytes Reads per minute by chunk server and mount point rate Bytes lizardfs_write_bytes Writes per minute by chunk server and mount point rate Bytes lizardfs_max_read_time Max read time by chunk server and mount point curent Microsecond lizardfs_max_write_time Max write time by chunk server and mount point curent Microsecond lizardfs_max_fsync_time Max file system sync time by chunk server and mount point curent Microsecond lizardfs_read_ops Read operations per minute by chunk server and mount point rate None lizardfs_write_ops Write operations pre minute by chunk server and mount point rate None lizardfs_fsync_ops File system sync operation by chunk server and mount point rate None There isn no necessity to run check_lizardfs.py on all nodes of LizardFS of cluster, statistics from all nodes can be collected from single location.","title":"Provides"},{"location":"agent/loadbalancrs/","text":"HAProxy Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_haproxy.py ./ Configure Statistics for HAProxy can be enabled by adding following to haproxy.conf : listen stats bind : 8888 mode http stats enable stats hide-version stats realm Haproxy\\ Statistics stats uri /haproxy?stats stats auth User : Pass Then you need to configure Agent to start gathering statistics from Haproxy server. [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True upstream : MyApp1 Config parameter upstream is name of upstream server configured in Haproxy. listen MyApp1 192.168.0.1 : 80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10 : 8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20 : 8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor = len 32 rspidel ^Set-cookie : \\ IP= From above mentioned example it is obvious, that upstream name is MyApp1, so this name should be placed as upstream parameter in HAProxy section of webservers.ini If you have more sophisticated HAProxy configuration with multiple upstreams and need to monitor several upstreams, you should write comma and separate names in upstream configuration of Agent: So if your HAProxy configuration looks like this : listen MyApp1 192.168.0.1:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= listen MyApp2 192.168.0.2:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.11:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.22:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= Agent should be configured as follows: [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type haproxy_connrate Connections per second rate nhaproxy_sessions Current active sessions gauge Envoy Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_envoy.py ./ Configure Start Envoy with following parameters admin : access_log_path : \"/dev/null\" address : socket_address : address : 127.0.0.1 port_value : 8001 Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [Envoy] metrics : http://127.0.0.1:8001/stats/prometheus Restart PuyPuy agent and Envoy. Provides Name Type Description downstream_cx_total counter Total connections downstream_cx_ssl_total counter Total TLS connections downstream_cx_http1_total counter Total HTTP/1.1 connections downstream_cx_websocket_total counter Total WebSocket connections downstream_cx_http2_total counter Total HTTP/2 connections downstream_cx_destroy counter Total connections destroyed downstream_cx_destroy_remote counter Total connections destroyed due to remote close downstream_cx_destroy_local counter Total connections destroyed due to local close downstream_cx_destroy_active_rq counter Total connections destroyed with 1+ active request downstream_cx_destroy_local_active_rq counter Total connections destroyed locally with 1+ active request downstream_cx_destroy_remote_active_rq counter Total connections destroyed remotely with 1+ active request downstream_cx_active gauge Total active connections downstream_cx_ssl_active gauge Total active TLS connections downstream_cx_http1_active gauge Total active HTTP/1.1 connections downstream_cx_websocket_active gauge Total active WebSocket connections downstream_cx_http2_active gauge Total active HTTP/2 connections downstream_cx_protocol_error counter Total protocol errors downstream_cx_length_ms histogram Connection length milliseconds downstream_cx_rx_bytes_total counter Total bytes received downstream_cx_rx_bytes_buffered gauge Total received bytes currently buffered downstream_cx_tx_bytes_total counter Total bytes sent downstream_cx_tx_bytes_buffered gauge Total sent bytes currently buffered downstream_cx_drain_close counter Total connections closed due to draining downstream_cx_idle_timeout counter Total connections closed due to idle timeout downstream_flow_control_paused_reading_total counter Total number of times reads were disabled due to flow control downstream_flow_control_resumed_reading_total counter Total number of times reads were enabled on the connection due to flow control downstream_rq_total counter Total requests downstream_rq_http1_total counter Total HTTP/1.1 requests downstream_rq_http2_total counter Total HTTP/2 requests downstream_rq_active gauge Total active requests downstream_rq_response_before_rq_complete counter Total responses sent before the request was complete downstream_rq_rx_reset counter Total request resets received downstream_rq_tx_reset counter Total request resets sent downstream_rq_non_relative_path counter Total requests with a non-relative HTTP path downstream_rq_too_large counter Total requests resulting in a 413 due to buffering an overly large body downstream_rq_1xx counter Total 1xx responses downstream_rq_2xx counter Total 2xx responses downstream_rq_3xx counter Total 3xx responses downstream_rq_4xx counter Total 4xx responses downstream_rq_5xx counter Total 5xx responses downstream_rq_ws_on_non_ws_route counter Total WebSocket upgrade requests rejected by non WebSocket routes downstream_rq_time histogram Request time milliseconds rs_too_large counter Total response errors due to buffering an overly large body Traefik Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_traefik.py ./ Configure Start Traefik with following parameters [entryPoints.metrics] address = \":8081\" [metrics] [metrics.prometheus] entryPoint = \"metrics\" Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [traefik] metrics : http://127.0.0.1:8081/metrics Restart PuyPuy agent and Envoy. Provides Name Type Description traefik_entrypoint_http_duration_seconds_count counter How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_entrypoint_http_duration_seconds_sum gauge How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_go_gc_duration_seconds_count counter A summary of the GC invocation durations. traefik_go_gc_duration_seconds_sum gauge A summary of the GC invocation durations. traefik_process_cpu_seconds_total counter Total user and system CPU time spent in seconds. traefik_process_max_fds gauge Maximum number of open file descriptors. traefik_process_open_fds gauge Number of open file descriptors. traefik_process_resident_memory_bytes gauge Resident memory size in bytes. traefik_process_start_time_seconds gauge Start time of the process since unix epoch in seconds. traefik_process_virtual_memory_bytes gauge Virtual memory size in bytes. traefik_process_virtual_memory_max_bytes gauge Maximum amount of virtual memory available in bytes.","title":"Loadbalancrs"},{"location":"agent/loadbalancrs/#haproxy","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_haproxy.py ./ Configure Statistics for HAProxy can be enabled by adding following to haproxy.conf : listen stats bind : 8888 mode http stats enable stats hide-version stats realm Haproxy\\ Statistics stats uri /haproxy?stats stats auth User : Pass Then you need to configure Agent to start gathering statistics from Haproxy server. [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True upstream : MyApp1 Config parameter upstream is name of upstream server configured in Haproxy. listen MyApp1 192.168.0.1 : 80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10 : 8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20 : 8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor = len 32 rspidel ^Set-cookie : \\ IP= From above mentioned example it is obvious, that upstream name is MyApp1, so this name should be placed as upstream parameter in HAProxy section of webservers.ini If you have more sophisticated HAProxy configuration with multiple upstreams and need to monitor several upstreams, you should write comma and separate names in upstream configuration of Agent: So if your HAProxy configuration looks like this : listen MyApp1 192.168.0.1:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= listen MyApp2 192.168.0.2:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.11:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.22:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= Agent should be configured as follows: [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type haproxy_connrate Connections per second rate nhaproxy_sessions Current active sessions gauge","title":"HAProxy"},{"location":"agent/loadbalancrs/#envoy","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_envoy.py ./ Configure Start Envoy with following parameters admin : access_log_path : \"/dev/null\" address : socket_address : address : 127.0.0.1 port_value : 8001 Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [Envoy] metrics : http://127.0.0.1:8001/stats/prometheus Restart PuyPuy agent and Envoy. Provides Name Type Description downstream_cx_total counter Total connections downstream_cx_ssl_total counter Total TLS connections downstream_cx_http1_total counter Total HTTP/1.1 connections downstream_cx_websocket_total counter Total WebSocket connections downstream_cx_http2_total counter Total HTTP/2 connections downstream_cx_destroy counter Total connections destroyed downstream_cx_destroy_remote counter Total connections destroyed due to remote close downstream_cx_destroy_local counter Total connections destroyed due to local close downstream_cx_destroy_active_rq counter Total connections destroyed with 1+ active request downstream_cx_destroy_local_active_rq counter Total connections destroyed locally with 1+ active request downstream_cx_destroy_remote_active_rq counter Total connections destroyed remotely with 1+ active request downstream_cx_active gauge Total active connections downstream_cx_ssl_active gauge Total active TLS connections downstream_cx_http1_active gauge Total active HTTP/1.1 connections downstream_cx_websocket_active gauge Total active WebSocket connections downstream_cx_http2_active gauge Total active HTTP/2 connections downstream_cx_protocol_error counter Total protocol errors downstream_cx_length_ms histogram Connection length milliseconds downstream_cx_rx_bytes_total counter Total bytes received downstream_cx_rx_bytes_buffered gauge Total received bytes currently buffered downstream_cx_tx_bytes_total counter Total bytes sent downstream_cx_tx_bytes_buffered gauge Total sent bytes currently buffered downstream_cx_drain_close counter Total connections closed due to draining downstream_cx_idle_timeout counter Total connections closed due to idle timeout downstream_flow_control_paused_reading_total counter Total number of times reads were disabled due to flow control downstream_flow_control_resumed_reading_total counter Total number of times reads were enabled on the connection due to flow control downstream_rq_total counter Total requests downstream_rq_http1_total counter Total HTTP/1.1 requests downstream_rq_http2_total counter Total HTTP/2 requests downstream_rq_active gauge Total active requests downstream_rq_response_before_rq_complete counter Total responses sent before the request was complete downstream_rq_rx_reset counter Total request resets received downstream_rq_tx_reset counter Total request resets sent downstream_rq_non_relative_path counter Total requests with a non-relative HTTP path downstream_rq_too_large counter Total requests resulting in a 413 due to buffering an overly large body downstream_rq_1xx counter Total 1xx responses downstream_rq_2xx counter Total 2xx responses downstream_rq_3xx counter Total 3xx responses downstream_rq_4xx counter Total 4xx responses downstream_rq_5xx counter Total 5xx responses downstream_rq_ws_on_non_ws_route counter Total WebSocket upgrade requests rejected by non WebSocket routes downstream_rq_time histogram Request time milliseconds rs_too_large counter Total response errors due to buffering an overly large body","title":"Envoy"},{"location":"agent/loadbalancrs/#traefik","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_traefik.py ./ Configure Start Traefik with following parameters [entryPoints.metrics] address = \":8081\" [metrics] [metrics.prometheus] entryPoint = \"metrics\" Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [traefik] metrics : http://127.0.0.1:8081/metrics Restart PuyPuy agent and Envoy. Provides Name Type Description traefik_entrypoint_http_duration_seconds_count counter How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_entrypoint_http_duration_seconds_sum gauge How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_go_gc_duration_seconds_count counter A summary of the GC invocation durations. traefik_go_gc_duration_seconds_sum gauge A summary of the GC invocation durations. traefik_process_cpu_seconds_total counter Total user and system CPU time spent in seconds. traefik_process_max_fds gauge Maximum number of open file descriptors. traefik_process_open_fds gauge Number of open file descriptors. traefik_process_resident_memory_bytes gauge Resident memory size in bytes. traefik_process_start_time_seconds gauge Start time of the process since unix epoch in seconds. traefik_process_virtual_memory_bytes gauge Virtual memory size in bytes. traefik_process_virtual_memory_max_bytes gauge Maximum amount of virtual memory available in bytes.","title":"Traefik"},{"location":"agent/marathon/","text":"Marathon Marathon master exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_marathon.py to checks_enabled and restart Agent. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_marathon.py ./ Configure Configuration of Marathon check is Marathon section of conf/bigdata.ini You need to set full URL of statistics interface of marathon which is : http://{HOST}:{PORT}/metrics [Marathon] stats : http://127.0.0.1:8888/metrics Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit marathon_apps_active Amount of currently active applications gauge None marathon_deployments_active Amount of currently active deployments gauge None marathon_gc_collections Garbage collations performed bt Marathon daemon counter None marathon_gc_duration Time spend on GC my Marathon daemon since it's start counter None marathon_groups_active Amount of currently active groups gauge None marathon_heap_committed Marathon JVM heap committed gauge Bytes marathon_heap_used Marathon JVM heap used gauge Bytes marathon_http_event_streams_active Amount of currently active HTTP event streams gauge None marathon_http_requests_active Amount of currently active requests gauge None marathon_instances_launch_overdue Overdue of launch instances gauge None marathon_instances_running Currently running instances gauge None marathon_instances_staged Currently staged instances gauge None marathon_nonheap_committed Marathon non JVM heap committed gauge Bytes marathon_nonheap_used Marathon non JVM heap used gauge Bytes marathon_pods_active Currently active pods gauge None","title":"Marathon"},{"location":"agent/marathon/#marathon","text":"Marathon master exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_marathon.py to checks_enabled and restart Agent.","title":"Marathon"},{"location":"agent/marathon/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_marathon.py ./","title":"Install"},{"location":"agent/marathon/#configure","text":"Configuration of Marathon check is Marathon section of conf/bigdata.ini You need to set full URL of statistics interface of marathon which is : http://{HOST}:{PORT}/metrics [Marathon] stats : http://127.0.0.1:8888/metrics","title":"Configure"},{"location":"agent/marathon/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/marathon/#provides","text":"Name Description Type Unit marathon_apps_active Amount of currently active applications gauge None marathon_deployments_active Amount of currently active deployments gauge None marathon_gc_collections Garbage collations performed bt Marathon daemon counter None marathon_gc_duration Time spend on GC my Marathon daemon since it's start counter None marathon_groups_active Amount of currently active groups gauge None marathon_heap_committed Marathon JVM heap committed gauge Bytes marathon_heap_used Marathon JVM heap used gauge Bytes marathon_http_event_streams_active Amount of currently active HTTP event streams gauge None marathon_http_requests_active Amount of currently active requests gauge None marathon_instances_launch_overdue Overdue of launch instances gauge None marathon_instances_running Currently running instances gauge None marathon_instances_staged Currently staged instances gauge None marathon_nonheap_committed Marathon non JVM heap committed gauge Bytes marathon_nonheap_used Marathon non JVM heap used gauge Bytes marathon_pods_active Currently active pods gauge None","title":"Provides"},{"location":"agent/mesos/","text":"Mesos Master Mesos master exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_mesos_master.py to checks_enabled and restart Agent. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_mesos_master.py ./ Configure At most of cases there is no need to configure Agent , but if you have non default installation of Mesos, or if you need to monitor Mesos Master, which is not running locally for Agent node, edit conf/bigdata.ini and make your changes at Mesos-Master section. [Mesos-Master] stats : http://127.0.0.1:5050/metrics/snapshot Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit mesos_allocator_mesos_allocation_run_ms Duration of running mesos allocations gauge Milliseconds mesos_allocator_mesos_allocation_run_ms_p99 99 Percentile Duration of running mesos allocations gauge Milliseconds mesos_master_cpus_percent Percent of in Use mesos master CPUs gauge Percent mesos_master_cpus_revocable_percent Mesos Master's CPUs revocable percentage gauge Percent mesos_master_cpus_used Amount used Mesos master CPUs gauge None mesos_master_disk_percent Mesos Master's dids usage in percent gauge Percent mesos_master_disk_revocable_percent Mesos Master disks revocable in percent gauge Percent mesos_master_disk_used Meso Master disks usage in bytes gauge Bytes mesos_master_event_queue_dispatches Master's dispatched event queue gauge None mesos_master_event_queue_http_requests Master's HTTP requests to event queue gauge None mesos_master_event_queue_messages Message in Masters even queue gauge None mesos_master_frameworks_active Amount of current active frameworks gauge None mesos_master_gpus_percent Percent of in Use mesos master GPUs gauge Percent mesos_master_gpus_used Amount used Mesos master GPUs gauge None mesos_master_mem_percent Masters memory usage in percent gauge Percent mesos_master_mem_used Masters memory usage in bytes gauge Bytes mesos_master_messages_kill_task Mater kill tasks gauge None mesos_master_messages_reregister_framework Master registering frameworks gauge None mesos_master_slaves_connected Amount of connected slaves gauge None mesos_master_tasks_dropped Amount of dropped tasks counter None mesos_master_tasks_error Amount of tasks with errors counter None mesos_master_tasks_failed Amount of failed tasks counter None mesos_master_tasks_finished Amount of finished tasks counter None mesos_master_tasks_gone Amount of gone tasks gauge None mesos_master_tasks_lost Amount of lost tasks gauge None mesos_master_tasks_running Amount of running tasks gauge None mesos_master_tasks_staging Amount of staging tasks gauge None mesos_master_tasks_starting Amount of starting tasks gauge None mesos_master_tasks_unreachable Amount of unreachable tasks gauge None mesos_registrar_state_fetch_ms Registrars state fetched in milliseconds gauge Milliseconds mesos_registrar_state_store_ms_p99 99 percentile of registrars state fetched in milliseconds gauge Milliseconds Mesos Slave Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_mesos_slave.py ./ Configure At most of cases there is no need to configure Agent , but if you have non default installation of Mesos, or if you need to monitor Mesos Master, which is not running locally for Agent node, edit conf/bigdata.ini and make your changes at Mesos-Master section. [Mesos-Slave] stats : http://127.0.0.1:5051/metrics/snapshot Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit mesos_slave_cpus_percent Slaves CPU usage in percent gauge Percent mesos_slave_cpus_revocable_used Slaves CPU revocable usage gauge None mesos_slave_cpus_used Slave CPUs used gauge None mesos_slave_disk_percent Slave disks usage percentage gauge Percent mesos_slave_disk_used Slave disks usage bytes gauge Bytes mesos_slave_executors_running Amount of running executors gauge None mesos_slave_executors_terminated Amount of terminated executors counter None mesos_slave_executors_terminating Amount of terminating executors gauge None mesos_slave_frameworks_active Active frameworks on current node gauge None mesos_slave_gpus_revocable_used Slaves GPU revocable usage gauge None mesos_slave_gpus_used Slaves GPU usage in percent gauge Percent mesos_slave_invalid_status_updates Invalid status update gauge None mesos_slave_mem_percent Slave used memory percentage gauge Percent mesos_slave_mem_revocable_percent Slave memory revocable percentage gauge Percent mesos_slave_mem_used Slave used memory in bytes gauge Bytes mesos_slave_recovery_errors Recover errors gauge None mesos_slave_tasks_failed Amount of failed tasks on current node gauge None mesos_slave_tasks_killing Amount of failed killing on current node gauge None mesos_slave_tasks_lost Amount of lost killed on current node gauge None mesos_slave_tasks_running Amount of running tasks on current node counter None","title":"Mesos"},{"location":"agent/mesos/#mesos-master","text":"Mesos master exposes metrics via HTTP/Json out of the box, so all you need is just to symlink checks_available/check_mesos_master.py to checks_enabled and restart Agent.","title":"Mesos Master"},{"location":"agent/mesos/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_mesos_master.py ./","title":"Install"},{"location":"agent/mesos/#configure","text":"At most of cases there is no need to configure Agent , but if you have non default installation of Mesos, or if you need to monitor Mesos Master, which is not running locally for Agent node, edit conf/bigdata.ini and make your changes at Mesos-Master section. [Mesos-Master] stats : http://127.0.0.1:5050/metrics/snapshot","title":"Configure"},{"location":"agent/mesos/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/mesos/#provides","text":"Name Description Type Unit mesos_allocator_mesos_allocation_run_ms Duration of running mesos allocations gauge Milliseconds mesos_allocator_mesos_allocation_run_ms_p99 99 Percentile Duration of running mesos allocations gauge Milliseconds mesos_master_cpus_percent Percent of in Use mesos master CPUs gauge Percent mesos_master_cpus_revocable_percent Mesos Master's CPUs revocable percentage gauge Percent mesos_master_cpus_used Amount used Mesos master CPUs gauge None mesos_master_disk_percent Mesos Master's dids usage in percent gauge Percent mesos_master_disk_revocable_percent Mesos Master disks revocable in percent gauge Percent mesos_master_disk_used Meso Master disks usage in bytes gauge Bytes mesos_master_event_queue_dispatches Master's dispatched event queue gauge None mesos_master_event_queue_http_requests Master's HTTP requests to event queue gauge None mesos_master_event_queue_messages Message in Masters even queue gauge None mesos_master_frameworks_active Amount of current active frameworks gauge None mesos_master_gpus_percent Percent of in Use mesos master GPUs gauge Percent mesos_master_gpus_used Amount used Mesos master GPUs gauge None mesos_master_mem_percent Masters memory usage in percent gauge Percent mesos_master_mem_used Masters memory usage in bytes gauge Bytes mesos_master_messages_kill_task Mater kill tasks gauge None mesos_master_messages_reregister_framework Master registering frameworks gauge None mesos_master_slaves_connected Amount of connected slaves gauge None mesos_master_tasks_dropped Amount of dropped tasks counter None mesos_master_tasks_error Amount of tasks with errors counter None mesos_master_tasks_failed Amount of failed tasks counter None mesos_master_tasks_finished Amount of finished tasks counter None mesos_master_tasks_gone Amount of gone tasks gauge None mesos_master_tasks_lost Amount of lost tasks gauge None mesos_master_tasks_running Amount of running tasks gauge None mesos_master_tasks_staging Amount of staging tasks gauge None mesos_master_tasks_starting Amount of starting tasks gauge None mesos_master_tasks_unreachable Amount of unreachable tasks gauge None mesos_registrar_state_fetch_ms Registrars state fetched in milliseconds gauge Milliseconds mesos_registrar_state_store_ms_p99 99 percentile of registrars state fetched in milliseconds gauge Milliseconds","title":"Provides"},{"location":"agent/mesos/#mesos-slave","text":"","title":"Mesos Slave"},{"location":"agent/mesos/#install_1","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_mesos_slave.py ./","title":"Install"},{"location":"agent/mesos/#configure_1","text":"At most of cases there is no need to configure Agent , but if you have non default installation of Mesos, or if you need to monitor Mesos Master, which is not running locally for Agent node, edit conf/bigdata.ini and make your changes at Mesos-Master section. [Mesos-Slave] stats : http://127.0.0.1:5051/metrics/snapshot","title":"Configure"},{"location":"agent/mesos/#restart_1","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/mesos/#provides_1","text":"Name Description Type Unit mesos_slave_cpus_percent Slaves CPU usage in percent gauge Percent mesos_slave_cpus_revocable_used Slaves CPU revocable usage gauge None mesos_slave_cpus_used Slave CPUs used gauge None mesos_slave_disk_percent Slave disks usage percentage gauge Percent mesos_slave_disk_used Slave disks usage bytes gauge Bytes mesos_slave_executors_running Amount of running executors gauge None mesos_slave_executors_terminated Amount of terminated executors counter None mesos_slave_executors_terminating Amount of terminating executors gauge None mesos_slave_frameworks_active Active frameworks on current node gauge None mesos_slave_gpus_revocable_used Slaves GPU revocable usage gauge None mesos_slave_gpus_used Slaves GPU usage in percent gauge Percent mesos_slave_invalid_status_updates Invalid status update gauge None mesos_slave_mem_percent Slave used memory percentage gauge Percent mesos_slave_mem_revocable_percent Slave memory revocable percentage gauge Percent mesos_slave_mem_used Slave used memory in bytes gauge Bytes mesos_slave_recovery_errors Recover errors gauge None mesos_slave_tasks_failed Amount of failed tasks on current node gauge None mesos_slave_tasks_killing Amount of failed killing on current node gauge None mesos_slave_tasks_lost Amount of lost killed on current node gauge None mesos_slave_tasks_running Amount of running tasks on current node counter None","title":"Provides"},{"location":"agent/mysql/","text":"To monitor MySQL server you need : Install MySQLdb or pymysql module. Create MySQL user with privileges to run SHOW GLOBAL STATUS . Configure Agent with User/Pass/Host, for connecting to Mysql server. Install MySQL Driver If you are running Debian or Ubuntu, use apt-get to install MySQLdb module apt-get install python-mysqldb or apt-get install python3-mysqldb If you have enabled backports repositories for Debian, you can use it to install pymysql apt-get install python-mysqldb or apt-get install python3-mysqldb For CentOS you can Use YUM. yum install MySQL-python MySQL drivers can be installed via PIP as well. pip install MySQL-python or pip install pymysql The reason of adding pymysql support, is that on some Linux distributions (Debian 9), MySQLdb is not working properly. Create MySQL User Login to your MySQL server as root and execute following statement : GRANT USAGE ON * . * TO puypuy @ '127.0.0.1' IDENTIFIED BY 'Very-Long-Pa$$w0rd' ; FLUSH PRIVILEGES ; Configure Agent Copy or symlink checks_available/check_mysql.py to checks_enabled cd ${ AGENT_HOME /checks_enabled } ln -s ../checks_available/check_mysql.py ./ Edit conf conf/sql_cache.ini and put right parameters at MySQL section: [MySQL] host : 127.0.0.1 user : puypuy pass : Very-Long-Pa$$w0rd Provides Name Description Type Unit mysql_bytes_received MySQL Received bytes rate Bytes mysql_bytes_sent MySQL Sent bytes rate Bytes mysql_com_delete Executed MySQL DELETE commands per second rate OPS mysql_com_delete_multi Executed MySQL Multi DELETE commands per second rate OPS mysql_com_insert Executed MySQL INSERT commands per second rate OPS mysql_com_select Executed MySQL SELECT commands per second rate OPS mysql_com_update Executed MySQL UPDATE commands per second rate OPS mysql_connections Amount of current connections current None mysql_innodb_buffer_pool_read_requests InnoDB buffer pool read requests rate OPS mysql_innodb_buffer_pool_write_requests InnoDB buffer pool write requests rate OPS mysql_innodb_data_fsyncs InnoDB data fsyncs rate OPS mysql_innodb_data_read InnoDB data reads rate OPS mysql_innodb_data_writes InnoDB data writes rate OPS mysql_innodb_rows_deleted InnoDB data deletes rate OPS mysql_innodb_rows_inserted InnoDB inserted rows rate OPS mysql_innodb_rows_read InnoDB read rows rate OPS mysql_innodb_rows_updated InnoDB updated rows rate OPS mysql_max_used_connections Maximum used connection size mysql restart current None mysql_open_files Amount of open file descriptors current None mysql_qcache_hits MySQL query cache hits rate OPS mysql_queries Total number of executed MySQl queries per second rate OPS mysql_questions Total number of executed MySQl questions per second rate OPS mysql_slow_queries Amount of running slow queries current None mysql_threads_connected Amount of currently connected threads current None","title":"MySQL"},{"location":"agent/mysql/#install-mysql-driver","text":"If you are running Debian or Ubuntu, use apt-get to install MySQLdb module apt-get install python-mysqldb or apt-get install python3-mysqldb If you have enabled backports repositories for Debian, you can use it to install pymysql apt-get install python-mysqldb or apt-get install python3-mysqldb For CentOS you can Use YUM. yum install MySQL-python MySQL drivers can be installed via PIP as well. pip install MySQL-python or pip install pymysql The reason of adding pymysql support, is that on some Linux distributions (Debian 9), MySQLdb is not working properly.","title":"Install MySQL Driver"},{"location":"agent/mysql/#create-mysql-user","text":"Login to your MySQL server as root and execute following statement : GRANT USAGE ON * . * TO puypuy @ '127.0.0.1' IDENTIFIED BY 'Very-Long-Pa$$w0rd' ; FLUSH PRIVILEGES ;","title":"Create MySQL User"},{"location":"agent/mysql/#configure-agent","text":"Copy or symlink checks_available/check_mysql.py to checks_enabled cd ${ AGENT_HOME /checks_enabled } ln -s ../checks_available/check_mysql.py ./ Edit conf conf/sql_cache.ini and put right parameters at MySQL section: [MySQL] host : 127.0.0.1 user : puypuy pass : Very-Long-Pa$$w0rd","title":"Configure Agent"},{"location":"agent/mysql/#provides","text":"Name Description Type Unit mysql_bytes_received MySQL Received bytes rate Bytes mysql_bytes_sent MySQL Sent bytes rate Bytes mysql_com_delete Executed MySQL DELETE commands per second rate OPS mysql_com_delete_multi Executed MySQL Multi DELETE commands per second rate OPS mysql_com_insert Executed MySQL INSERT commands per second rate OPS mysql_com_select Executed MySQL SELECT commands per second rate OPS mysql_com_update Executed MySQL UPDATE commands per second rate OPS mysql_connections Amount of current connections current None mysql_innodb_buffer_pool_read_requests InnoDB buffer pool read requests rate OPS mysql_innodb_buffer_pool_write_requests InnoDB buffer pool write requests rate OPS mysql_innodb_data_fsyncs InnoDB data fsyncs rate OPS mysql_innodb_data_read InnoDB data reads rate OPS mysql_innodb_data_writes InnoDB data writes rate OPS mysql_innodb_rows_deleted InnoDB data deletes rate OPS mysql_innodb_rows_inserted InnoDB inserted rows rate OPS mysql_innodb_rows_read InnoDB read rows rate OPS mysql_innodb_rows_updated InnoDB updated rows rate OPS mysql_max_used_connections Maximum used connection size mysql restart current None mysql_open_files Amount of open file descriptors current None mysql_qcache_hits MySQL query cache hits rate OPS mysql_queries Total number of executed MySQl queries per second rate OPS mysql_questions Total number of executed MySQl questions per second rate OPS mysql_slow_queries Amount of running slow queries current None mysql_threads_connected Amount of currently connected threads current None","title":"Provides"},{"location":"agent/nagios/","text":"Nagios/Icinga Nagios and Icinga are popular and powerful open source monitoring applications. There are tons of plugins for these systems. Recently we have created native integration of Nagios plugins with PuyPuy All what's needed is to enable Nagios module cd ${OE-AGENT-HOME}/checks_enabled && ln -s ../checks_available/nagios.py ./ . And configure OE-Agent with Plugins which you want to use. In [Nagios] section of conf/nagios.ini file just write check_name: command key value pairs. You can write, space separated, parameters for you plugin exactly as you will do when you configure Nagios/Icinga or nagios-nrpe-server. [Nagios] loadaverage : /usr/lib/nagios/plugins/check_load -w 15,10,5 -c 30,25,20 diskusage : /usr/lib/nagios/plugins/check_disk -l -w 20% -c 10% -p /dev/sda1 processes : /usr/lib/nagios/plugins/check_procs -w 250 -c 400 After restarting oe-agent you can see alert at you Dashboard, where name of alert is given key at nagios.ini nd value is actual value of actual check command. Nagios/Icinga client OE-Agent can work with Nagion Or Icinga directly acting as remote agent for executing commands. for that we need to enable built in webserver and set api key in config.ini and restart the agent service. [WebServer] webserver : yes webaddress : 0.0.0.0:9898 apikey : xxx-xxx-xxx-xxx-xxx-xxx-xxx-xxx Configuration of checks is in conf/nagios.ini file, and it looks like this: [Nagios] loadaverage : /usr/lib/nagios/plugins/check_load -w 15,10,5 -c 30,25,20 diskusage : /usr/lib/nagios/plugins/check_disk -l -w 20% -c 10% -p /dev/sda1 processes : /usr/lib/nagios/plugins/check_procs -w 250 -c 400 After agent is configured to run a webserver and serve nagios plugins, we should configure our Nagios or Icinga server to connect to agent and run checks. The configuration of Icinga is easy, we need to copy tools/icingacommands.conf file to Icinga config directory, usually etc/icinga2/conf.d , tools/naclient.conf to plugins directory ( /usr/lib/nagios/plugins/ ) and restart the Icinga service. Next we need to donfigure Icinga ckecks as examples below : object Service \"memory\" { host_name = \"HOSTNAME\" display_name = \"Memory Usage\" check_command = \"puypuyclient\" vars . puypuyclient_address = \"ip or hostname of remote agent\" vars . puypuyclient_port = \"port of agent\" vars . puypuyclient_key = \"api key to connect to agent\" vars . puypuyclient_command = \"loadaverage -w 15,10,5 -c 30,25,20\" } The important note for line vars.puypuyclient_command = \"memory -w 20 -c 10 -n Command name should be the name defined in nagios.ini file. Parameters can be empty, in this agent will use parameneters which are locally configured in nagios.ini . If you set parameters in icinga config file it will have higher prority and these parameters will be used to execute the nagios plugin .","title":"Nagios/Icinga"},{"location":"agent/nagios/#nagiosicinga","text":"Nagios and Icinga are popular and powerful open source monitoring applications. There are tons of plugins for these systems. Recently we have created native integration of Nagios plugins with PuyPuy All what's needed is to enable Nagios module cd ${OE-AGENT-HOME}/checks_enabled && ln -s ../checks_available/nagios.py ./ . And configure OE-Agent with Plugins which you want to use. In [Nagios] section of conf/nagios.ini file just write check_name: command key value pairs. You can write, space separated, parameters for you plugin exactly as you will do when you configure Nagios/Icinga or nagios-nrpe-server. [Nagios] loadaverage : /usr/lib/nagios/plugins/check_load -w 15,10,5 -c 30,25,20 diskusage : /usr/lib/nagios/plugins/check_disk -l -w 20% -c 10% -p /dev/sda1 processes : /usr/lib/nagios/plugins/check_procs -w 250 -c 400 After restarting oe-agent you can see alert at you Dashboard, where name of alert is given key at nagios.ini nd value is actual value of actual check command.","title":"Nagios/Icinga"},{"location":"agent/nagios/#nagiosicinga-client","text":"OE-Agent can work with Nagion Or Icinga directly acting as remote agent for executing commands. for that we need to enable built in webserver and set api key in config.ini and restart the agent service. [WebServer] webserver : yes webaddress : 0.0.0.0:9898 apikey : xxx-xxx-xxx-xxx-xxx-xxx-xxx-xxx Configuration of checks is in conf/nagios.ini file, and it looks like this: [Nagios] loadaverage : /usr/lib/nagios/plugins/check_load -w 15,10,5 -c 30,25,20 diskusage : /usr/lib/nagios/plugins/check_disk -l -w 20% -c 10% -p /dev/sda1 processes : /usr/lib/nagios/plugins/check_procs -w 250 -c 400 After agent is configured to run a webserver and serve nagios plugins, we should configure our Nagios or Icinga server to connect to agent and run checks. The configuration of Icinga is easy, we need to copy tools/icingacommands.conf file to Icinga config directory, usually etc/icinga2/conf.d , tools/naclient.conf to plugins directory ( /usr/lib/nagios/plugins/ ) and restart the Icinga service. Next we need to donfigure Icinga ckecks as examples below : object Service \"memory\" { host_name = \"HOSTNAME\" display_name = \"Memory Usage\" check_command = \"puypuyclient\" vars . puypuyclient_address = \"ip or hostname of remote agent\" vars . puypuyclient_port = \"port of agent\" vars . puypuyclient_key = \"api key to connect to agent\" vars . puypuyclient_command = \"loadaverage -w 15,10,5 -c 30,25,20\" } The important note for line vars.puypuyclient_command = \"memory -w 20 -c 10 -n Command name should be the name defined in nagios.ini file. Parameters can be empty, in this agent will use parameneters which are locally configured in nagios.ini . If you set parameters in icinga config file it will have higher prority and these parameters will be used to execute the nagios plugin .","title":"Nagios/Icinga client"},{"location":"agent/nvidia/","text":"Nvidia GPU Detailed monitoring of Nvidia GPU with PuyPuy . Nvidia CUDA check depends on nvidia-ml python module, so in order to use this check nvidia-ml should be installed. Install You can install nvidia-ml with pip or pip3 based on your python version . Python2: pip install nvidia-ml-py Python3: pip3 install nvidia-ml-py3 Configure Nvidia CUDA check does not requires any configuration , just enable check_nvidia_gpu module and restart oe-agent cd ${ PUYPUY_HOME } /checks_enabled/ ln -s ../checks_available/check_nvidia_gpu.py Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit nvidia_b1_memory_free Retrieves the amount of BAR1 free memory available on the device gauge Bytes nvidia_b1_memory_total Retrieves the amount of BAR1 total memory available on the device gauge Bytes nvidia_b1_memory_used Retrieves the amount of BAR1 used memory available on the device gauge Bytes nvidia_memory_free Retrieves the amount of free memory available on the device gauge Bytes nvidia_memory_total Retrieves the amount of total memory available on the device gauge Bytes nvidia_memory_used Retrieves the amount of used memory available on the device gauge Bytes nvidia_cuda_processes Metrics only about compute running processes (e.g. CUDA application which have active context). gauge None nvidia_graphic_processes Metrics only about graphics based processes (eg. applications using OpenGL, DirectX)\" gauge None nvidia_memory_utilizaton Current utilization rates for the device's memory subsystems. gauge Percent nvidia_gpu_utilizaton Current utilization rates for the device's gpu subsystems. gauge Percent nvidia_fan_speed The fan speed is expressed as a percent of the maximum, i.e. full speed is 100%.\" gauge Percent nvidia_gpu_clock_info Current clock speeds for the device. gauge None nvidia_gpu_temperature Current temperature readings for the device, in degrees C.\" gauge Celsius nvidia_power_usage power usage for this GPU in milliwatts gauge Milliwatts","title":"Nvidia GPU"},{"location":"agent/nvidia/#nvidia-gpu","text":"Detailed monitoring of Nvidia GPU with PuyPuy . Nvidia CUDA check depends on nvidia-ml python module, so in order to use this check nvidia-ml should be installed.","title":"Nvidia GPU"},{"location":"agent/nvidia/#install","text":"You can install nvidia-ml with pip or pip3 based on your python version . Python2: pip install nvidia-ml-py Python3: pip3 install nvidia-ml-py3","title":"Install"},{"location":"agent/nvidia/#configure","text":"Nvidia CUDA check does not requires any configuration , just enable check_nvidia_gpu module and restart oe-agent cd ${ PUYPUY_HOME } /checks_enabled/ ln -s ../checks_available/check_nvidia_gpu.py","title":"Configure"},{"location":"agent/nvidia/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/nvidia/#provides","text":"Name Description Type Unit nvidia_b1_memory_free Retrieves the amount of BAR1 free memory available on the device gauge Bytes nvidia_b1_memory_total Retrieves the amount of BAR1 total memory available on the device gauge Bytes nvidia_b1_memory_used Retrieves the amount of BAR1 used memory available on the device gauge Bytes nvidia_memory_free Retrieves the amount of free memory available on the device gauge Bytes nvidia_memory_total Retrieves the amount of total memory available on the device gauge Bytes nvidia_memory_used Retrieves the amount of used memory available on the device gauge Bytes nvidia_cuda_processes Metrics only about compute running processes (e.g. CUDA application which have active context). gauge None nvidia_graphic_processes Metrics only about graphics based processes (eg. applications using OpenGL, DirectX)\" gauge None nvidia_memory_utilizaton Current utilization rates for the device's memory subsystems. gauge Percent nvidia_gpu_utilizaton Current utilization rates for the device's gpu subsystems. gauge Percent nvidia_fan_speed The fan speed is expressed as a percent of the maximum, i.e. full speed is 100%.\" gauge Percent nvidia_gpu_clock_info Current clock speeds for the device. gauge None nvidia_gpu_temperature Current temperature readings for the device, in degrees C.\" gauge Celsius nvidia_power_usage power usage for this GPU in milliwatts gauge Milliwatts","title":"Provides"},{"location":"agent/rabbitmq/","text":"Agent Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_rabbitmq.py ./ Or if you are using recent versions of RabbitMQ : cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_rabbitmq_368.py ./ Agent Configure Edit conf/mq.ini and change user/pass parameters if needed, defaults are below: Agent have two modes of monitoring RabbitMQ . Basic Mode (Provides server level metrics, queue, item access rates etc ..) Detailed Mode (Provides per queue metrics) For RabbitMQ servers older than v3.68: [RabbitMQ] stats : http://127.0.0.1:15672 queue_details : True user : admin pass : admin Parameter queue_details enables per queue statistics, depending on amount of queues in you RabbitMQ server in may significantly increase amount of sending metrics. For RabbitMQ servers newer than v3.68: [RabbitMQ 3.6] stats : http://127.0.0.1:15672 queue_details : True desired_queues : beer-queue, deer-queue, bear-queue user : admin pass : admin Parameter queue_details enables per queue statistics, desired_queues parameter containf comma seprated list og queues on which you want to have per queue monitoring . RabbitMQ Configuration RabbitMQ has very detailed monitoring interface, but before using, it must be enabled and configured. To start Monitoring of RabbitMQ first we need to create user, and enable management plugin. If you already have done that, pass to Agent Configuration rabbitmqctl add_user admin admin rabbitmqctl set_user_tags admin administrator rabbitmqctl set_permissions -p / admin \".*\" \".*\" \".*\" Enable RabbitMQ management plugin: rabbitmq-plugins enable rabbitmq_management Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit rabbitmq_deliver_rate rate of delivering messages rate OPS rabbitmq_message_bytes_persistent Amount of disk bytes used for persisting messages current Bytes rabbitmq_message_bytes_ram Amount of memory used for persisting messages current Bytes rabbitmq_messages Message currently in queue current None rabbitmq_messages_details How much the count has changed per second in the most recent sampling interval rate OPS rabbitmq_messages_persistent Message currently in disk queue current None rabbitmq_messages_ram Message currently in memory queue current None rabbitmq_messages_ready Message ready for delivery current None rabbitmq_messages_ready_details How much the messages ready count has changed per second in the most recent sampling interval rate OPS rabbitmq_messages_unacknowledged Amount of unacknowledged messages current None rabbitmq_messages_unacknowledged_details How much the messages unacknowledged count has changed per second in the most recent sampling interval rate OPS","title":"RabbitMQ"},{"location":"agent/rabbitmq/#agent-install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_rabbitmq.py ./ Or if you are using recent versions of RabbitMQ : cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_rabbitmq_368.py ./","title":"Agent Install"},{"location":"agent/rabbitmq/#agent-configure","text":"Edit conf/mq.ini and change user/pass parameters if needed, defaults are below: Agent have two modes of monitoring RabbitMQ . Basic Mode (Provides server level metrics, queue, item access rates etc ..) Detailed Mode (Provides per queue metrics) For RabbitMQ servers older than v3.68: [RabbitMQ] stats : http://127.0.0.1:15672 queue_details : True user : admin pass : admin Parameter queue_details enables per queue statistics, depending on amount of queues in you RabbitMQ server in may significantly increase amount of sending metrics. For RabbitMQ servers newer than v3.68: [RabbitMQ 3.6] stats : http://127.0.0.1:15672 queue_details : True desired_queues : beer-queue, deer-queue, bear-queue user : admin pass : admin Parameter queue_details enables per queue statistics, desired_queues parameter containf comma seprated list og queues on which you want to have per queue monitoring .","title":"Agent Configure"},{"location":"agent/rabbitmq/#rabbitmq-configuration","text":"RabbitMQ has very detailed monitoring interface, but before using, it must be enabled and configured. To start Monitoring of RabbitMQ first we need to create user, and enable management plugin. If you already have done that, pass to Agent Configuration rabbitmqctl add_user admin admin rabbitmqctl set_user_tags admin administrator rabbitmqctl set_permissions -p / admin \".*\" \".*\" \".*\" Enable RabbitMQ management plugin: rabbitmq-plugins enable rabbitmq_management","title":"RabbitMQ Configuration"},{"location":"agent/rabbitmq/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/rabbitmq/#provides","text":"Name Description Type Unit rabbitmq_deliver_rate rate of delivering messages rate OPS rabbitmq_message_bytes_persistent Amount of disk bytes used for persisting messages current Bytes rabbitmq_message_bytes_ram Amount of memory used for persisting messages current Bytes rabbitmq_messages Message currently in queue current None rabbitmq_messages_details How much the count has changed per second in the most recent sampling interval rate OPS rabbitmq_messages_persistent Message currently in disk queue current None rabbitmq_messages_ram Message currently in memory queue current None rabbitmq_messages_ready Message ready for delivery current None rabbitmq_messages_ready_details How much the messages ready count has changed per second in the most recent sampling interval rate OPS rabbitmq_messages_unacknowledged Amount of unacknowledged messages current None rabbitmq_messages_unacknowledged_details How much the messages unacknowledged count has changed per second in the most recent sampling interval rate OPS","title":"Provides"},{"location":"agent/riak/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_riak.py ./ Configure Configuration of Riak check is located at bigdata.ini . By default it will look fo Riak installation localhost . Please make sure to set correct IP address of Riak instance which you want to monitor. Restart Agent. ./puypuy.sh restart check_riak module should run without making changes in configuration, but according to your specific needs, you can edit conf/bindata.ini and make changes in section Riak [Riak] stats : http://127.0.0.1:8098/stats Provides Name Description Type Unit riak_mem_allocated Amount of memory alloted for Riak instance current Bytes riak_memory_processes Amount of memory allocated for Erlang processe current Bytes riak_memory_processes_used Amount of memory used by Erlang processe current Bytes riak_node_gets rate of GET commands executed on current node rate OPS riak_node_puts rate of PUT commands executed on current node rate OPS riak_read_repairs rate of READ commands executed on current node rate OPS riak_sys_process_count Riak system prcesses count current None riak_vnode_gets rate of GET commands executed on current v node rate OPS riak_vnode_puts rate of PUT commands executed on current v node rate OPS riak_vnode_set_update rate of UPDATES commands executed on current node rate OPS","title":"Riak"},{"location":"agent/riak/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_riak.py ./","title":"Install"},{"location":"agent/riak/#configure","text":"Configuration of Riak check is located at bigdata.ini . By default it will look fo Riak installation localhost . Please make sure to set correct IP address of Riak instance which you want to monitor. Restart Agent. ./puypuy.sh restart check_riak module should run without making changes in configuration, but according to your specific needs, you can edit conf/bindata.ini and make changes in section Riak [Riak] stats : http://127.0.0.1:8098/stats","title":"Configure"},{"location":"agent/riak/#provides","text":"Name Description Type Unit riak_mem_allocated Amount of memory alloted for Riak instance current Bytes riak_memory_processes Amount of memory allocated for Erlang processe current Bytes riak_memory_processes_used Amount of memory used by Erlang processe current Bytes riak_node_gets rate of GET commands executed on current node rate OPS riak_node_puts rate of PUT commands executed on current node rate OPS riak_read_repairs rate of READ commands executed on current node rate OPS riak_sys_process_count Riak system prcesses count current None riak_vnode_gets rate of GET commands executed on current v node rate OPS riak_vnode_puts rate of PUT commands executed on current v node rate OPS riak_vnode_set_update rate of UPDATES commands executed on current node rate OPS","title":"Provides"},{"location":"agent/rrs/","text":"Redis Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_redis.py ./ Configure check_redis module have pre configured defaults, that should work for most of stups, but if you need, you can edit conf/sql_cache.ini and make changes in section Redis [Redis] host : 127.0.0.1 port : 6379 Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit redis_connected_clients Amount of connected clients counter None redis_evicted_keys Amount of evicted keys per second rate OPS redis_expired_keys Amount of evicted keys per second rate OPS redis_keyspace_hits Amount of keyspace hits per second rate OPS redis_keyspace_misses Amount of keyspace misses per second rate OPS redis_mem_fragmentation_ratio Memory fragmentation ratio gauge None redis_rdb_bgsave_in_progress In progress of RDB background save processes counter None redis_rdb_changes_since_last_save Changes made in RDB since last save counter None redis_rdb_current_bgsave_time_sec Amount of seconds spend for current background save counter Seconds redis_rdb_last_bgsave_time_sec Amount of seconds spend for last background save counter Seconds redis_total_commands_processed Amount of commands executed on Redi per second rate OPS redis_total_net_input_bytes Input bytes per second rate Bytes redis_total_net_output_bytes Output bytes per second rate Bytes redis_uptime_in_seconds Redis uptime in seconds gauge Seconds redis_used_memory Redis used memory gauge Bytes redis_used_memory_peak Redis Memory peak usage gauge Bytes redis_used_memory_rss Redis RSS used memory gauge Bytes \ud83d\udcc8 Example Grafana Dashboard Memcached Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_memcached.py ./ Configure check_memcached module have pre configured defaults, that should work for most of stups, but if you need, you can edit conf/sql_cache.ini and make changes in section Memcached [Memcached] host : 127.0.0.1 port : 11211 Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit memcached_bytes Memcached memory usage in bytes gauge Bytes memcached_bytes_read Read bytes per second rate Bytes memcached_bytes_written Write bytes per second rate Bytes memcached_cmd_get GET command per second rate OPS memcached_cmd_set SET commands per second rate OPS memcached_curr_connections Amount of currently active connections gauge None memcached_curr_items Amount of current items counter None memcached_delete_hits DELETE hits per second rate OPS memcached_delete_misses DELETE misses per second rate OPS memcached_evictions Evictions per second rate OPS memcached_get_hits GET hits per second rate OPS memcached_get_misses GET misses per second rate OPS memcached_incr_misses INCR misses per second rate OPS memcached_limit_maxbytes Memcached maximum bytes limit gauge Bytes memcached_rusage_system System memory usage gauge Bytes memcached_rusage_user User Memory usage gauge Bytes","title":"Redis, Memcached"},{"location":"agent/rrs/#redis","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_redis.py ./ Configure check_redis module have pre configured defaults, that should work for most of stups, but if you need, you can edit conf/sql_cache.ini and make changes in section Redis [Redis] host : 127.0.0.1 port : 6379 Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit redis_connected_clients Amount of connected clients counter None redis_evicted_keys Amount of evicted keys per second rate OPS redis_expired_keys Amount of evicted keys per second rate OPS redis_keyspace_hits Amount of keyspace hits per second rate OPS redis_keyspace_misses Amount of keyspace misses per second rate OPS redis_mem_fragmentation_ratio Memory fragmentation ratio gauge None redis_rdb_bgsave_in_progress In progress of RDB background save processes counter None redis_rdb_changes_since_last_save Changes made in RDB since last save counter None redis_rdb_current_bgsave_time_sec Amount of seconds spend for current background save counter Seconds redis_rdb_last_bgsave_time_sec Amount of seconds spend for last background save counter Seconds redis_total_commands_processed Amount of commands executed on Redi per second rate OPS redis_total_net_input_bytes Input bytes per second rate Bytes redis_total_net_output_bytes Output bytes per second rate Bytes redis_uptime_in_seconds Redis uptime in seconds gauge Seconds redis_used_memory Redis used memory gauge Bytes redis_used_memory_peak Redis Memory peak usage gauge Bytes redis_used_memory_rss Redis RSS used memory gauge Bytes \ud83d\udcc8 Example Grafana Dashboard","title":"Redis"},{"location":"agent/rrs/#memcached","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_memcached.py ./ Configure check_memcached module have pre configured defaults, that should work for most of stups, but if you need, you can edit conf/sql_cache.ini and make changes in section Memcached [Memcached] host : 127.0.0.1 port : 11211 Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit memcached_bytes Memcached memory usage in bytes gauge Bytes memcached_bytes_read Read bytes per second rate Bytes memcached_bytes_written Write bytes per second rate Bytes memcached_cmd_get GET command per second rate OPS memcached_cmd_set SET commands per second rate OPS memcached_curr_connections Amount of currently active connections gauge None memcached_curr_items Amount of current items counter None memcached_delete_hits DELETE hits per second rate OPS memcached_delete_misses DELETE misses per second rate OPS memcached_evictions Evictions per second rate OPS memcached_get_hits GET hits per second rate OPS memcached_get_misses GET misses per second rate OPS memcached_incr_misses INCR misses per second rate OPS memcached_limit_maxbytes Memcached maximum bytes limit gauge Bytes memcached_rusage_system System memory usage gauge Bytes memcached_rusage_user User Memory usage gauge Bytes","title":"Memcached"},{"location":"agent/scylla/","text":"Scylla is a massively scalable Open-Source NoSQL database. It's an implementation of Apache Cassandra using C++ instead of Java. Developers of Scylla describe it as : Scylla is a drop-in replacement for Apache Cassandra and DynamoDB. Yet it also provides significant advantages over these other databases. Flip the cards to see similarities and differences. Scylla ships with native metrics exported, which runs by default 9180 port. So there is no need for special configuration of Scylla. Scylla config of PuyPuy agent is in conf/bigdata.ini file. If you run recommended Scylla installation, no need for making spacial configs for PuyPuy agent as well. Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_scylla.py ./ Configure Default config should be suitable for the most of the installations. If you are running Scylla's node_exporter other than default way, change the stats parameter to match your setup. [Scilla] stats : http://127.0.0.1:9180/metrics Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit scylla_node_operation_mode The operation mode of the current node. gauge None scylla_reactor_utilization CPU utilization gauge None scylla_transport_requests_served Counts a number of served requests counter None scylla_storage_proxy_coordinator_write_latency_count The general write latency histogram histogram None scylla_storage_proxy_coordinator_write_latency_sum The general write latency histogram histogram None scylla_storage_proxy_coordinator_write_timeouts Number of write request failed due to a timeout counter None scylla_storage_proxy_coordinator_read_latency_count The general read latency histogram histogram None scylla_storage_proxy_coordinator_read_latency_sum The general read latency histogram histogram None scylla_storage_proxy_coordinator_read_timeouts Number of read request failed due to a timeout counter None scylla_cache_row_hits Total number of rows needed by reads and found in cache counter None scylla_cache_row_misses Total number of rows needed by reads and missing in cache counter None scylla_cache_bytes_total Total size of memory for the cache gauge None scylla_cache_bytes_used urrent bytes used by the cache out of the total size of memory gauge Bytes scylla_cache_concurrent_misses_same_key Total number of operation with misses same key counter None scylla_sstables_row_reads Number of rows read counter None scylla_sstables_range_partition_reads Number of range tombstones written counter None scylla_sstables_range_tombstone_writes Cassandra Peak threads count gauge None scylla_sstables_row_writes Number of clustering rows written counter None scylla_sstables_single_partition_reads Number of single partition flat mutation reads counter None scylla_sstables_sstable_partition_reads Number of whole sstable flat mutation reads counter None scylla_sstables_static_row_writes Number of static rows written counter None scylla_sstables_tombstone_writes Number of tombstones written counter None scylla_cql_inserts The Number of CQL INSERT requests gauge None scylla_cql_reads The Number of CQL SELECT requests. gauge None scylla_cql_deletes The Number of CQL DELETE requests. gauge None scylla_cql_updates The Number of CQL UPDATE requests gauge None scylla_cql_batches The Number of CQL BATCH requests gauge None scylla_cache_row_hits Total number of rows needed by reads and found in cache gauge None scylla_cache_row_misses Total number of rows needed by reads and missing in cache gauge None scylla_transport_requests_served Counts a number of served requests. gauge None","title":"Scylla"},{"location":"agent/scylla/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_scylla.py ./","title":"Install"},{"location":"agent/scylla/#configure","text":"Default config should be suitable for the most of the installations. If you are running Scylla's node_exporter other than default way, change the stats parameter to match your setup. [Scilla] stats : http://127.0.0.1:9180/metrics","title":"Configure"},{"location":"agent/scylla/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/scylla/#provides","text":"Name Description Type Unit scylla_node_operation_mode The operation mode of the current node. gauge None scylla_reactor_utilization CPU utilization gauge None scylla_transport_requests_served Counts a number of served requests counter None scylla_storage_proxy_coordinator_write_latency_count The general write latency histogram histogram None scylla_storage_proxy_coordinator_write_latency_sum The general write latency histogram histogram None scylla_storage_proxy_coordinator_write_timeouts Number of write request failed due to a timeout counter None scylla_storage_proxy_coordinator_read_latency_count The general read latency histogram histogram None scylla_storage_proxy_coordinator_read_latency_sum The general read latency histogram histogram None scylla_storage_proxy_coordinator_read_timeouts Number of read request failed due to a timeout counter None scylla_cache_row_hits Total number of rows needed by reads and found in cache counter None scylla_cache_row_misses Total number of rows needed by reads and missing in cache counter None scylla_cache_bytes_total Total size of memory for the cache gauge None scylla_cache_bytes_used urrent bytes used by the cache out of the total size of memory gauge Bytes scylla_cache_concurrent_misses_same_key Total number of operation with misses same key counter None scylla_sstables_row_reads Number of rows read counter None scylla_sstables_range_partition_reads Number of range tombstones written counter None scylla_sstables_range_tombstone_writes Cassandra Peak threads count gauge None scylla_sstables_row_writes Number of clustering rows written counter None scylla_sstables_single_partition_reads Number of single partition flat mutation reads counter None scylla_sstables_sstable_partition_reads Number of whole sstable flat mutation reads counter None scylla_sstables_static_row_writes Number of static rows written counter None scylla_sstables_tombstone_writes Number of tombstones written counter None scylla_cql_inserts The Number of CQL INSERT requests gauge None scylla_cql_reads The Number of CQL SELECT requests. gauge None scylla_cql_deletes The Number of CQL DELETE requests. gauge None scylla_cql_updates The Number of CQL UPDATE requests gauge None scylla_cql_batches The Number of CQL BATCH requests gauge None scylla_cache_row_hits Total number of rows needed by reads and found in cache gauge None scylla_cache_row_misses Total number of rows needed by reads and missing in cache gauge None scylla_transport_requests_served Counts a number of served requests. gauge None","title":"Provides"},{"location":"agent/snmp/","text":"Module install In order to make SNMP negotiation check_snmp requires pysnmp python module. It can be installed via pip . Module is tested and properly working with pysnmp==4.3.9 , older versions may not work properly, so please make sure to install pysnmp==4.3.9 or newer. To avoid future confusions, we recommend to install exact tested version of PySNMP . pip install pysnmp == 4 .3.9 or pip3 install pysnmp == 4 .3.9 check_snmp supports v2 Public and v3 authPriv protocols. Configuration is done in conf/snmp.ini file. At this moment Agent supports only SNMP over UDP . Followings are supported authentication and private protocols. authProtocol: MD5 authProtocol: SHA privProtocol: DES privProtocol: 3DES privProtocol: AES128 privProtocol: AES192 privProtocol: AES256 conf/snmp.ini file already contains commented protocol and auth names, so you need to uncomment ones which matches your SNMP servers requirements. check_snmp module runs similarly to snmpget Net-SNMP command. So if you run check without authentication, result will be equivalent to : snmpget -v2c -cpublic 192 .168.10.11 .1.3.6.1.4.1.2021.11.9.0 For v3 authPriv : snmpget -v3 -lauthPriv -u SecurityName -A AuthPassphrase -X PrivPassphrase -a MD5 -x AES 192 .168.10.11 1 .3.6.1.2.1.25.2.3.1.5.65536 Configuration fo SNMP plugin is little different that other traditional checks. Config parameters are set in conf/snmp.ini file, but unlike others naming is little different. Names of config sections represents friendly names for you devices. Also you should write names and OIDS of needed checks, so Agent can do SNMP get with OID and use friendly names to send information to backend servers. [mikrotik.router.net] auth : True port : 161 server : 192.168.10.2 authProtocol : MD5 privProtocol : AES128 SecurityName : demo AuthPassphrase : Bb123456 PrivPassphrase : Bb123456 total_memory : .1.3.6.1.2.1.25.2.3.1.5.65536 used_memory : .1.3.6.1.2.1.25.2.3.1.6.65536 cpu_frequency : .1.3.6.1.4.1.14988.1.1.3.14.0 tx_rate : .1.3.6.1.4.1.14988.1.1.1.3.1.2.6 rx_rate : .1.3.6.1.4.1.14988.1.1.1.3.1.3.6 client_count : .1.3.6.1.4.1.14988.1.1.1.3.1.6.6 frequency : .1.3.6.1.4.1.14988.1.1.1.3.1.7.6 noise_floor : .1.3.6.1.4.1.14988.1.1.1.3.1.9.6 overall_ccq : .1.3.6.1.4.1.14988.1.1.1.3.1.10.6 For better manageability metrics names at endpoint are prefixed with snmp_ so if_eth0_out_errors will be shown as snmp_if_eth0_out_errors in Dashboard. Please make sure to create correct mappings before running check_snmp SNMP v2 Public auth: Boolean parameter in conf/snmp.ini controls switching protocol an community versions. auth : False Will set to legacy v2 protocol with Public community. As result you will have SNMP querly similar to : snmpget -v2c -cpublic 192 .168.10.11 .1.3.6.1.4.1.2021.11.9.0 auth: True enables v3 AuthPriv . SNMP v3 AuthPriv V3 is enhanced Protocol of SNMP, which supports encryption and authentication. Our agent supports following protocols. authProtocols, MD5, SHA privProtocols, DES, 3DES, AES128, AES192, AES256 Please setup authProtocol and privProtocol values to ones which matches your SNMP servers requirements. Eventual config file will look something like this : [linux.router.net] auth : True port : 161 server : 192.168.10.11 authProtocol : SHA privProtocol : DES SecurityName : demo AuthPassphrase : Bb1234567 PrivPassphrase : Bb1234567 mem_available : .1.3.6.1.4.1.2021.4.6.0 As result you will have SNMP querly similar to : snmpget -v3 -lauthPriv -u user -A AuthpaSS -X ProtopaSS -a SHA -x DES 192 .168.10.11 .1.3.6.1.4.1.2021.4.6.0 After configuration and mapping is finished, you can enable check_snmp as any other PuyPuy check and restart Agent: cd checks_enabled ln -s ../checks_available/check_snmp.py ./ ../puypuy.sh restart","title":"SNMP"},{"location":"agent/snmp/#module-install","text":"In order to make SNMP negotiation check_snmp requires pysnmp python module. It can be installed via pip . Module is tested and properly working with pysnmp==4.3.9 , older versions may not work properly, so please make sure to install pysnmp==4.3.9 or newer. To avoid future confusions, we recommend to install exact tested version of PySNMP . pip install pysnmp == 4 .3.9 or pip3 install pysnmp == 4 .3.9 check_snmp supports v2 Public and v3 authPriv protocols. Configuration is done in conf/snmp.ini file. At this moment Agent supports only SNMP over UDP . Followings are supported authentication and private protocols. authProtocol: MD5 authProtocol: SHA privProtocol: DES privProtocol: 3DES privProtocol: AES128 privProtocol: AES192 privProtocol: AES256 conf/snmp.ini file already contains commented protocol and auth names, so you need to uncomment ones which matches your SNMP servers requirements. check_snmp module runs similarly to snmpget Net-SNMP command. So if you run check without authentication, result will be equivalent to : snmpget -v2c -cpublic 192 .168.10.11 .1.3.6.1.4.1.2021.11.9.0 For v3 authPriv : snmpget -v3 -lauthPriv -u SecurityName -A AuthPassphrase -X PrivPassphrase -a MD5 -x AES 192 .168.10.11 1 .3.6.1.2.1.25.2.3.1.5.65536 Configuration fo SNMP plugin is little different that other traditional checks. Config parameters are set in conf/snmp.ini file, but unlike others naming is little different. Names of config sections represents friendly names for you devices. Also you should write names and OIDS of needed checks, so Agent can do SNMP get with OID and use friendly names to send information to backend servers. [mikrotik.router.net] auth : True port : 161 server : 192.168.10.2 authProtocol : MD5 privProtocol : AES128 SecurityName : demo AuthPassphrase : Bb123456 PrivPassphrase : Bb123456 total_memory : .1.3.6.1.2.1.25.2.3.1.5.65536 used_memory : .1.3.6.1.2.1.25.2.3.1.6.65536 cpu_frequency : .1.3.6.1.4.1.14988.1.1.3.14.0 tx_rate : .1.3.6.1.4.1.14988.1.1.1.3.1.2.6 rx_rate : .1.3.6.1.4.1.14988.1.1.1.3.1.3.6 client_count : .1.3.6.1.4.1.14988.1.1.1.3.1.6.6 frequency : .1.3.6.1.4.1.14988.1.1.1.3.1.7.6 noise_floor : .1.3.6.1.4.1.14988.1.1.1.3.1.9.6 overall_ccq : .1.3.6.1.4.1.14988.1.1.1.3.1.10.6 For better manageability metrics names at endpoint are prefixed with snmp_ so if_eth0_out_errors will be shown as snmp_if_eth0_out_errors in Dashboard. Please make sure to create correct mappings before running check_snmp","title":"Module install"},{"location":"agent/snmp/#snmp-v2-public","text":"auth: Boolean parameter in conf/snmp.ini controls switching protocol an community versions. auth : False Will set to legacy v2 protocol with Public community. As result you will have SNMP querly similar to : snmpget -v2c -cpublic 192 .168.10.11 .1.3.6.1.4.1.2021.11.9.0 auth: True enables v3 AuthPriv .","title":"SNMP v2 Public"},{"location":"agent/snmp/#snmp-v3-authpriv","text":"V3 is enhanced Protocol of SNMP, which supports encryption and authentication. Our agent supports following protocols. authProtocols, MD5, SHA privProtocols, DES, 3DES, AES128, AES192, AES256 Please setup authProtocol and privProtocol values to ones which matches your SNMP servers requirements. Eventual config file will look something like this : [linux.router.net] auth : True port : 161 server : 192.168.10.11 authProtocol : SHA privProtocol : DES SecurityName : demo AuthPassphrase : Bb1234567 PrivPassphrase : Bb1234567 mem_available : .1.3.6.1.4.1.2021.4.6.0 As result you will have SNMP querly similar to : snmpget -v3 -lauthPriv -u user -A AuthpaSS -X ProtopaSS -a SHA -x DES 192 .168.10.11 .1.3.6.1.4.1.2021.4.6.0 After configuration and mapping is finished, you can enable check_snmp as any other PuyPuy check and restart Agent: cd checks_enabled ln -s ../checks_available/check_snmp.py ./ ../puypuy.sh restart","title":"SNMP v3 AuthPriv"},{"location":"agent/solr/","text":"Solr check is tested with Vanilla ( Apache version) of Solr based on Jetty . Out of the box installtion of PuyPuy Agent may not work properly with other ditrinution of Solr (Cloudera, Tomcat, etc ...) Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_solr.py ./ Configure Configuration of Solr check is located at bigdata.ini . By default it will look fo Solr installation localhost . Please make sure to set correct IP address of Solr instance which you want to monitor. [Solr] stats : http://127.0.0.1:8983/solr/admin/metrics?group=all&wt=json Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit solr_1xx_responses HTTP 1xx responses per second rate OPS solr_2xx_responses HTTP 2xx responses per second rate OPS solr_3xx_responses HTTP 3xx responses per second rate OPS solr_4xx_responses HTTP 4xx responses per second rate OPS solr_5xx_responses HTTP 5xx responses per second rate OPS solr_delete_requests HTTP DELETE requests rate OPS solr_gc_{cms/g1_old}_count CMS or G1 Old gen Garbage Collections count counter None solr_gc_{cms/g1_old}_time CMS or G! Old gen Garbage Collections time rate Milliseconds solr_gc_{parnew/g1_young}_count CMS or G1 Young gen Garbage Collections count counter None solr_gc_{parnew/g1_young}_time CMS or G1 Young gen Garbage Collections count rate Milliseconds solr_heap_committed Java Heap committed counter Bytes solr_heap_init Java Heap init counter Bytes solr_heap_max Java Heap max counter Bytes solr_heap_used Java Heap used counter Bytes solr_non_heap_committed Java Non Heap committed counter Bytes solr_non_heap_init Java Non Heap init counter Bytes solr_non_heap_max Java Non Heap max counter Bytes solr_non_heap_used Java Non Heap used counter Bytes solr_move_requests MOVE requests executed on node rate OPS solr_options_requests OPTIONS requests executed on node rate OPS solr_get_requests GET requests executed on node rate OPS solr_put_requests PUT requests executed on node rate OPS solr_head_requests HEAD requests executed on node rate OPS solr_other_requests Other requests executed on node rate OPS solr_trace_requests Trace requests executed on node rate OPS solr_requests_all Requests executed on node rate OPS solr_threads Currently running Java threads gauge None solr_threads_daemon Currently running Java daemon threads gauge None","title":"Solr"},{"location":"agent/solr/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_solr.py ./","title":"Install"},{"location":"agent/solr/#configure","text":"Configuration of Solr check is located at bigdata.ini . By default it will look fo Solr installation localhost . Please make sure to set correct IP address of Solr instance which you want to monitor. [Solr] stats : http://127.0.0.1:8983/solr/admin/metrics?group=all&wt=json","title":"Configure"},{"location":"agent/solr/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/solr/#provides","text":"Name Description Type Unit solr_1xx_responses HTTP 1xx responses per second rate OPS solr_2xx_responses HTTP 2xx responses per second rate OPS solr_3xx_responses HTTP 3xx responses per second rate OPS solr_4xx_responses HTTP 4xx responses per second rate OPS solr_5xx_responses HTTP 5xx responses per second rate OPS solr_delete_requests HTTP DELETE requests rate OPS solr_gc_{cms/g1_old}_count CMS or G1 Old gen Garbage Collections count counter None solr_gc_{cms/g1_old}_time CMS or G! Old gen Garbage Collections time rate Milliseconds solr_gc_{parnew/g1_young}_count CMS or G1 Young gen Garbage Collections count counter None solr_gc_{parnew/g1_young}_time CMS or G1 Young gen Garbage Collections count rate Milliseconds solr_heap_committed Java Heap committed counter Bytes solr_heap_init Java Heap init counter Bytes solr_heap_max Java Heap max counter Bytes solr_heap_used Java Heap used counter Bytes solr_non_heap_committed Java Non Heap committed counter Bytes solr_non_heap_init Java Non Heap init counter Bytes solr_non_heap_max Java Non Heap max counter Bytes solr_non_heap_used Java Non Heap used counter Bytes solr_move_requests MOVE requests executed on node rate OPS solr_options_requests OPTIONS requests executed on node rate OPS solr_get_requests GET requests executed on node rate OPS solr_put_requests PUT requests executed on node rate OPS solr_head_requests HEAD requests executed on node rate OPS solr_other_requests Other requests executed on node rate OPS solr_trace_requests Trace requests executed on node rate OPS solr_requests_all Requests executed on node rate OPS solr_threads Currently running Java threads gauge None solr_threads_daemon Currently running Java daemon threads gauge None","title":"Provides"},{"location":"agent/spark/","text":"Apache Spark Apache Spark is a fast and general engine for large-scale data processing. In order to gather Spark workers statistics, we need to download and enable Jolokia JVM Agent Jolokia cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar Spark Master As far, as Jolokia JVM Agent is downloaded, we should configure Apache Spark , to use it as JavaAgent for workers and expose metrics via HTTP/Json. Edit spark-env.sh . It should be in /usr/local/spark/conf and add following parameters : export SPARK_MASTER_OPTS = \"$SPARK_MASTER_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/usr/local/spark/conf/jolokia-master.properties\" Now create /usr/local/spark/conf/jolokia-master.properties file with following content (Assuming that spark install folder is /usr/local/spark , if not change the pathe to one on which Spark is installed ): host = 0.0.0.0 port = 7777 agentContext = /jolokia backlog = 100 policyLocation = file:///usr/local/spark/conf/jolokia.policy historyMaxEntries = 10 debug = false debugMaxEntries = 100 maxDepth = 15 maxCollectionSize = 1000 maxObjects = 0 Now we need to create /usr/local/spark/conf/jolokia.policy with following content : <?xml version=\"1.0\" encoding=\"utf-8\"?> <restrict> <http> <method> get </method> <method> post </method> </http> <commands> <command> read </command> <command> list </command> <command> search </command> </commands> </restrict> Configure Agent with following in conf/bigdata.ini file : [Spark-Master] stats : http://127.0.0.1:7777/jolokia/read Restart Spark master. Spark worker Edit spark-env.sh . It should be in /usr/local/spark/conf and add following parameters : export SPARK_WORKER_OPTS = \" $SPARK_WORKER_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/usr/local/spark/conf/jolokia-worker.properties\" Now create /usr/local/spark/conf/jolokia-worker.properties file with following content (Assuming that spark install folder is /usr/local/spark , if not, change the path to one on which Spark is installed ): host = 0.0.0.0 port = 7778 agentContext = /jolokia backlog = 100 policyLocation = file:///usr/local/spark/conf/jolokia.policy historyMaxEntries = 10 debug = false debugMaxEntries = 100 maxDepth = 15 maxCollectionSize = 1000 maxObjects = 0 Create /usr/local/spark/conf/jolokia.policy with following content : <?xml version=\"1.0\" encoding=\"utf-8\"?> <restrict> <http> <method> get </method> <method> post </method> </http> <commands> <command> read </command> <command> list </command> <command> search </command> </commands> </restrict> Configure Agent with following in conf/bigdata.ini file : [Spark-Worker] stats : http://127.0.0.1:7778/jolokia/read Restart Spark worker.","title":"Apache Spark"},{"location":"agent/spark/#apache-spark","text":"Apache Spark is a fast and general engine for large-scale data processing. In order to gather Spark workers statistics, we need to download and enable Jolokia JVM Agent","title":"Apache Spark"},{"location":"agent/spark/#jolokia","text":"cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar","title":"Jolokia"},{"location":"agent/spark/#spark-master","text":"As far, as Jolokia JVM Agent is downloaded, we should configure Apache Spark , to use it as JavaAgent for workers and expose metrics via HTTP/Json. Edit spark-env.sh . It should be in /usr/local/spark/conf and add following parameters : export SPARK_MASTER_OPTS = \"$SPARK_MASTER_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/usr/local/spark/conf/jolokia-master.properties\" Now create /usr/local/spark/conf/jolokia-master.properties file with following content (Assuming that spark install folder is /usr/local/spark , if not change the pathe to one on which Spark is installed ): host = 0.0.0.0 port = 7777 agentContext = /jolokia backlog = 100 policyLocation = file:///usr/local/spark/conf/jolokia.policy historyMaxEntries = 10 debug = false debugMaxEntries = 100 maxDepth = 15 maxCollectionSize = 1000 maxObjects = 0 Now we need to create /usr/local/spark/conf/jolokia.policy with following content : <?xml version=\"1.0\" encoding=\"utf-8\"?> <restrict> <http> <method> get </method> <method> post </method> </http> <commands> <command> read </command> <command> list </command> <command> search </command> </commands> </restrict> Configure Agent with following in conf/bigdata.ini file : [Spark-Master] stats : http://127.0.0.1:7777/jolokia/read Restart Spark master.","title":"Spark Master"},{"location":"agent/spark/#spark-worker","text":"Edit spark-env.sh . It should be in /usr/local/spark/conf and add following parameters : export SPARK_WORKER_OPTS = \" $SPARK_WORKER_OPTS -javaagent:/usr/share/java/jolokia-agent.jar=config=/usr/local/spark/conf/jolokia-worker.properties\" Now create /usr/local/spark/conf/jolokia-worker.properties file with following content (Assuming that spark install folder is /usr/local/spark , if not, change the path to one on which Spark is installed ): host = 0.0.0.0 port = 7778 agentContext = /jolokia backlog = 100 policyLocation = file:///usr/local/spark/conf/jolokia.policy historyMaxEntries = 10 debug = false debugMaxEntries = 100 maxDepth = 15 maxCollectionSize = 1000 maxObjects = 0 Create /usr/local/spark/conf/jolokia.policy with following content : <?xml version=\"1.0\" encoding=\"utf-8\"?> <restrict> <http> <method> get </method> <method> post </method> </http> <commands> <command> read </command> <command> list </command> <command> search </command> </commands> </restrict> Configure Agent with following in conf/bigdata.ini file : [Spark-Worker] stats : http://127.0.0.1:7778/jolokia/read Restart Spark worker.","title":"Spark worker"},{"location":"agent/storm/","text":"Apache Storm is an Open Source distributed real time processing system. PuyPuy Have two modules for monitoring Apache Storm check_storm (Monitors Storm worker processes and exposes Java Lang metrics) check_storm_api (Collect's Topology specific metrics from Storm UI-) Storm API Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_ceph.py ./ Configure Storm API configuration parameters are in bigdata.ini file. Check supports Topology general aswell as per Spout/Bolt monitoring. By default per spout/bolt monitoring is turned on, if you do not need thesedetail, please set perspout or perbolt to False . [Storm-API] host : 127.0.0.1 port : 8080 perspout : True perbolt : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit storm_acked Storm acked requests per second counter integer storm_capacity \"Shown runtime capacity should be around 1.0 \" gauge storm_complete_latency Latency for completing tasks gauge Milliseconds storm_emitted Emitted messages per second counter integer storm_execute_latency Message execution latency gauge Milliseconds storm_executed Storm executions counter integer storm_failed Failed requests counter integer storm_process_latency Storm process latency gauge Milliseconds storm_requested_cpu Requested CPU resources per topology member gauge integer storm_requested_mem_off_heap Requested heap memory per topology member gauge Bytes storm_requested_mem_on_heap Requested non heap memory per topology member gauge Bytes storm_transferred Storm transfers counter integer Storm Workers In order to gather Storm workers statistics, we need to download and enable Jolokia JVM Agent Jolokia cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar Configure Storm As far, as Jolokia JVM Agent is downloaded, we should configure Apache Storm , to use it as JavaAgent for workers and expose metrics via HTTP/Json. To do this, edit storm.yaml . It should be in STORM_HOME/conf folder and add or append worker.childopts parameters with following: -javaagent:/usr/share/java/jolokia-jvm-agent.jar = port = 4 %WORKER-PORT%,host = 0 .0.0.0 Based on configured supervisor.slots.ports Java agent will bind 4%WORKER-PORT% if you don't like 4 , please feel free to change it to any suitable number. By default, storm children binds on 670 ports, so after making changes in storm.yaml and restarting Storm Topology *, you should see something like this, when you run netstat -nlptu | grep java tcp 0 0 0 .0.0.0:46700 0 .0.0.0:* LISTEN 6357 /java tcp 0 0 0 .0.0.0:46701 0 .0.0.0:* LISTEN 11281 /java tcp 0 0 0 .0.0.0:4670x 0 .0.0.0:* LISTEN 11281 /java If you see these ports open, you can configure Agent , otherwise, something is wrong with configuration. Configure Agent To configure Agent , change working directory to AGENT_HOME and : cd checks_enabled ln -s ../checks_available/check_storm_workers.py ./ Edit conf/bigdata.init and set correct parameters for Storm : [Storm] host : node1 port : 46700,46701,4670x path : /jolokia/read You can set all ports, used by Jolokia or only those, that are interesting for you, separate them by comma and restart Agent . cd ../ && ./puypuy.sh restart Provides Collected metrics will contain extra tag workerport , which will match port s configured in config file Name Description Type Unit storm_{g1_old/cms}_collectioncount G1 Old gen or CMS garbage collections count counter None storm_{g1_old/cms}_collectiontime G1 Old gen or CMS garbage collection time rate Milliseconds storm_{g1_young/parnew}_collectioncount G1 Young gen or ParNew garbage collections count counter None storm_{g1_young/parnew}_collectiontime G1 Young gen or ParNew garbage collection time rate Milliseconds storm_{g1_young/parnew}_lastgcinfo G1 Young gen or ParNew garbage collections last GC duration gauge MIlliseconds storm_heap_committed Java Heap memory committed gauge Bytes storm_heap_max Java Heap memory max gauge Bytes storm_heap_used Java Heap memory used gauge Bytes storm_nonheap_committed Java Non Heap memory committed gauge Bytes storm_nonheap_max Java Non Heap memory max gauge Bytes storm_nonheap_used Java Non Heap memory used gauge Bytes","title":"Apache Storm"},{"location":"agent/storm/#storm-api","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_ceph.py ./ Configure Storm API configuration parameters are in bigdata.ini file. Check supports Topology general aswell as per Spout/Bolt monitoring. By default per spout/bolt monitoring is turned on, if you do not need thesedetail, please set perspout or perbolt to False . [Storm-API] host : 127.0.0.1 port : 8080 perspout : True perbolt : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit storm_acked Storm acked requests per second counter integer storm_capacity \"Shown runtime capacity should be around 1.0 \" gauge storm_complete_latency Latency for completing tasks gauge Milliseconds storm_emitted Emitted messages per second counter integer storm_execute_latency Message execution latency gauge Milliseconds storm_executed Storm executions counter integer storm_failed Failed requests counter integer storm_process_latency Storm process latency gauge Milliseconds storm_requested_cpu Requested CPU resources per topology member gauge integer storm_requested_mem_off_heap Requested heap memory per topology member gauge Bytes storm_requested_mem_on_heap Requested non heap memory per topology member gauge Bytes storm_transferred Storm transfers counter integer","title":"Storm API"},{"location":"agent/storm/#storm-workers","text":"In order to gather Storm workers statistics, we need to download and enable Jolokia JVM Agent","title":"Storm Workers"},{"location":"agent/storm/#jolokia","text":"cd /usr/share/java/ wget -O jolokia-agent.jar http://search.maven.org/remotecontent?filepath = org/jolokia/jolokia-jvm/1.3.6/jolokia-jvm-1.3.6-agent.jar","title":"Jolokia"},{"location":"agent/storm/#configure-storm","text":"As far, as Jolokia JVM Agent is downloaded, we should configure Apache Storm , to use it as JavaAgent for workers and expose metrics via HTTP/Json. To do this, edit storm.yaml . It should be in STORM_HOME/conf folder and add or append worker.childopts parameters with following: -javaagent:/usr/share/java/jolokia-jvm-agent.jar = port = 4 %WORKER-PORT%,host = 0 .0.0.0 Based on configured supervisor.slots.ports Java agent will bind 4%WORKER-PORT% if you don't like 4 , please feel free to change it to any suitable number. By default, storm children binds on 670 ports, so after making changes in storm.yaml and restarting Storm Topology *, you should see something like this, when you run netstat -nlptu | grep java tcp 0 0 0 .0.0.0:46700 0 .0.0.0:* LISTEN 6357 /java tcp 0 0 0 .0.0.0:46701 0 .0.0.0:* LISTEN 11281 /java tcp 0 0 0 .0.0.0:4670x 0 .0.0.0:* LISTEN 11281 /java If you see these ports open, you can configure Agent , otherwise, something is wrong with configuration.","title":"Configure Storm"},{"location":"agent/storm/#configure-agent","text":"To configure Agent , change working directory to AGENT_HOME and : cd checks_enabled ln -s ../checks_available/check_storm_workers.py ./ Edit conf/bigdata.init and set correct parameters for Storm : [Storm] host : node1 port : 46700,46701,4670x path : /jolokia/read You can set all ports, used by Jolokia or only those, that are interesting for you, separate them by comma and restart Agent . cd ../ && ./puypuy.sh restart","title":"Configure Agent"},{"location":"agent/storm/#provides","text":"Collected metrics will contain extra tag workerport , which will match port s configured in config file Name Description Type Unit storm_{g1_old/cms}_collectioncount G1 Old gen or CMS garbage collections count counter None storm_{g1_old/cms}_collectiontime G1 Old gen or CMS garbage collection time rate Milliseconds storm_{g1_young/parnew}_collectioncount G1 Young gen or ParNew garbage collections count counter None storm_{g1_young/parnew}_collectiontime G1 Young gen or ParNew garbage collection time rate Milliseconds storm_{g1_young/parnew}_lastgcinfo G1 Young gen or ParNew garbage collections last GC duration gauge MIlliseconds storm_heap_committed Java Heap memory committed gauge Bytes storm_heap_max Java Heap memory max gauge Bytes storm_heap_used Java Heap memory used gauge Bytes storm_nonheap_committed Java Non Heap memory committed gauge Bytes storm_nonheap_max Java Non Heap memory max gauge Bytes storm_nonheap_used Java Non Heap memory used gauge Bytes","title":"Provides"},{"location":"agent/system/","text":"Linux OS Monitoring Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/ { check_cpustats.py,check_disks.py,check_load_average.py,check_memory.py,check_network_bytes.py } ./ Configure For most of installations, our defaults works well, but you can edit conf/system.ini if you need fine tuning. For each of system check you van enable or disable static alerts and set appropriate thresholds. [Load Average] static_enabled : True high : 95 severe : 100 [Disk Stats] static_enabled : True high : 90 severe : 95 [Memory Stats] static_enabled : True high : 90 severe : 95 [CPU Stats] static_enabled : True percore_stats : False high : 90 severe : 95 [Network Stats] localhost = False rated = True Restart ${ PUYPUY_HOME } /puypuy.sh restart CPU System CPU statistics are collected via check_cpustats.py module: It reads /proc/stat file for CPU related information. The Check does not require any additional dependencies, and it should provide following metrics: Provides Name Description Type Unit cpu_idle percent of free CPU resources gauge Percent cpu_iowait CPU percent spent on waiting for I/O operation gauge Percent cpu_irq CPU percent spent on handling hardware interrupts gauge Percent cpu_load Total CPU/Core load percent gauge Percent cpu_nice CPU percent of processing user level processes with positive nice gauge Percent cpu_softirq CPU percent spent on handling soft interrupts gauge Percent cpu_system CPU percent of processing system level processes gauge Percent cpu_user CPU percent of processing user level processes gauge Percent Memory Collected via check_memory.py module, it takes memory related information from /proc/meminfo file, and provides following metrics: Provides Name Description Type Unit mem_active Memory that is being used by a particular process gauge Bytes mem_available Not active / free memory gauge Bytes mem_buffers The total amount of memory used for critical system buffers gauge Bytes mem_cached Amount of cached data. Free\u2019d if there is not enough free memory in the system. gauge Bytes mem_inactive Memory that was allocated to a process that is no longer running gauge Bytes mem_swapcached Amount of swapped memory gauge Bytes mem_total Total amount of memory gauge Bytes mem_used_percent Aggregated from metrics above, total memory usage percentage gauge Percent Disk Collected via check_disks.py module, this check uses several resources, to provide statistics about disk IO and Space usage. Read/write statistics are taken from /sys/block/{DISK_NAME}/stat files, also we use Linux df command, to get information about space usage. IO statistics are taken from /proc/diskstats. For each disk we take following metrics: Provides Name Description Type Unit drive_bytes_available Amounts of unused bytes gauge Bytes drive_bytes_used Amounts of used bytes gauge Bytes drive_io_percent_used Percent of used IO resources per second of disk drive gauge Percent drive_percent_used Percentage of disk space usage gauge Percent drive_reads Read operations per second performed on disk drive rate Bytes drive_writes Write operations per second performed on disk drive rate Bytes Network Collected via check_network_bytes.py module, It collects metrics about all installed interfaces by reading /sys/class/net/{NIC}/statistics/rx_bytes file. Provides Name Description Type Unit bytes_rx Amounts of received bytes rate Bytes bytes_tx Amounts of sent bytes rate Bytes IP Conntrack Enable this module only if you use connection tracking. This check makes sense, if you have router like system, or if by some reason nf_conntrack kernel module is loaded. It reads /proc/sys/net/ipv4/netfilter/ip_conntrack_max|ip_conntrack_count files and provides : Provides Name Description Type Unit conntrack_max Maximum configured Conntack value gauge None conntrack_cur Current IP Conntack value gauge None Load Average This is one of the most important metrics in Linux (Maybe even the most). System load average shows ammount of processes, waiting in queue for CPU. It is calculater by 1,5 and 15 minute averages.In most of live systems it must have a value, which is less than total amount of CPUs detected by system. For example of your Server is equiped with 2x Quad cores CPUs, with enabled hyper trading Linux will see 16 CPUs, so Load Average should be below 16. Our check provides: Provides Name Description Type Unit sys_load_1 System load average for last minute gauge None sys_load_5 System load average for last 5 minutes gauge None sys_load_15 System load average for last 15 minutes gauge None As regular checks and also triggers special WARNING, when value of sys_load_1 is more that 90% of amount of CPU cores and ERROR, when its equal or more that 100%. This behavior can be changed by editing check_load_average.py and changing : warn_level = 90 crit_level = 100 to desired values. However these values are quite reasonable so, use it without modifications, if you are not for 100% sure that you need to change it TCP Connections This check provides status of TCP connections to systems. It parses /proc/net/tcp and provides following metrics. Provides Name Description Type Unit tcp_close TCP connections with CLOSED state gauge None tcp_close_wait The remote side has been shut down and is now waiting for the socket to close gauge None tcp_closing TCP connections in closing state gauge None tcp_established The socket has a connection established gauge None tcp_fin_wait1 The socket is closed, and the connection is now shutting down. gauge None tcp_last_ack TCP connections in last ack state gauge None tcp_listen TCP listening sockets gauge None tcp_max_states TCP connections in max state gauge None tcp_new_syn_recv TCP connections in new syn recv state gauge None tcp_syn_recv TCP connections in syn recvstate gauge None tcp_syn_sent TCP connections in syn recv state gauge None tcp_time_wait TCP connections in time wait state gauge None On some very heavy loaded systems, this check may become expensive, please make sure its suits your system resources before enabling it on systems with 20k+ TCP ESTABLISHED connections. BTRFS check BTRFS check can be very useful in combinations with regular Drive IO checks on systems which uses BTRFS file system. Its monitors BTRFS volumes and checks for volume errors. It also contains special check which will send manually defined ERROR and WARNING messages if values of checked parameters are above Zero. Manual Error handling can be enabled or disable by setting up enable_special variable at the top of script. Its accepts True or False parameters, defaults is True . Provides btrfs_dev_{NAME}_corruption_errs btrfs_dev_{NAME}_flush_io_errs btrfs_dev_{NAME}_generation_errs btrfs_dev_{NAME}_read_io_errs btrfs_dev_{NAME}_write_io_errs","title":"System Checks"},{"location":"agent/system/#linux-os-monitoring","text":"","title":"Linux OS Monitoring"},{"location":"agent/system/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/ { check_cpustats.py,check_disks.py,check_load_average.py,check_memory.py,check_network_bytes.py } ./","title":"Install"},{"location":"agent/system/#configure","text":"For most of installations, our defaults works well, but you can edit conf/system.ini if you need fine tuning. For each of system check you van enable or disable static alerts and set appropriate thresholds. [Load Average] static_enabled : True high : 95 severe : 100 [Disk Stats] static_enabled : True high : 90 severe : 95 [Memory Stats] static_enabled : True high : 90 severe : 95 [CPU Stats] static_enabled : True percore_stats : False high : 90 severe : 95 [Network Stats] localhost = False rated = True","title":"Configure"},{"location":"agent/system/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/system/#cpu","text":"System CPU statistics are collected via check_cpustats.py module: It reads /proc/stat file for CPU related information. The Check does not require any additional dependencies, and it should provide following metrics: Provides Name Description Type Unit cpu_idle percent of free CPU resources gauge Percent cpu_iowait CPU percent spent on waiting for I/O operation gauge Percent cpu_irq CPU percent spent on handling hardware interrupts gauge Percent cpu_load Total CPU/Core load percent gauge Percent cpu_nice CPU percent of processing user level processes with positive nice gauge Percent cpu_softirq CPU percent spent on handling soft interrupts gauge Percent cpu_system CPU percent of processing system level processes gauge Percent cpu_user CPU percent of processing user level processes gauge Percent","title":"CPU"},{"location":"agent/system/#memory","text":"Collected via check_memory.py module, it takes memory related information from /proc/meminfo file, and provides following metrics: Provides Name Description Type Unit mem_active Memory that is being used by a particular process gauge Bytes mem_available Not active / free memory gauge Bytes mem_buffers The total amount of memory used for critical system buffers gauge Bytes mem_cached Amount of cached data. Free\u2019d if there is not enough free memory in the system. gauge Bytes mem_inactive Memory that was allocated to a process that is no longer running gauge Bytes mem_swapcached Amount of swapped memory gauge Bytes mem_total Total amount of memory gauge Bytes mem_used_percent Aggregated from metrics above, total memory usage percentage gauge Percent","title":"Memory"},{"location":"agent/system/#disk","text":"Collected via check_disks.py module, this check uses several resources, to provide statistics about disk IO and Space usage. Read/write statistics are taken from /sys/block/{DISK_NAME}/stat files, also we use Linux df command, to get information about space usage. IO statistics are taken from /proc/diskstats. For each disk we take following metrics: Provides Name Description Type Unit drive_bytes_available Amounts of unused bytes gauge Bytes drive_bytes_used Amounts of used bytes gauge Bytes drive_io_percent_used Percent of used IO resources per second of disk drive gauge Percent drive_percent_used Percentage of disk space usage gauge Percent drive_reads Read operations per second performed on disk drive rate Bytes drive_writes Write operations per second performed on disk drive rate Bytes","title":"Disk"},{"location":"agent/system/#network","text":"Collected via check_network_bytes.py module, It collects metrics about all installed interfaces by reading /sys/class/net/{NIC}/statistics/rx_bytes file. Provides Name Description Type Unit bytes_rx Amounts of received bytes rate Bytes bytes_tx Amounts of sent bytes rate Bytes","title":"Network"},{"location":"agent/system/#ip-conntrack","text":"Enable this module only if you use connection tracking. This check makes sense, if you have router like system, or if by some reason nf_conntrack kernel module is loaded. It reads /proc/sys/net/ipv4/netfilter/ip_conntrack_max|ip_conntrack_count files and provides : Provides Name Description Type Unit conntrack_max Maximum configured Conntack value gauge None conntrack_cur Current IP Conntack value gauge None","title":"IP Conntrack"},{"location":"agent/system/#load-average","text":"This is one of the most important metrics in Linux (Maybe even the most). System load average shows ammount of processes, waiting in queue for CPU. It is calculater by 1,5 and 15 minute averages.In most of live systems it must have a value, which is less than total amount of CPUs detected by system. For example of your Server is equiped with 2x Quad cores CPUs, with enabled hyper trading Linux will see 16 CPUs, so Load Average should be below 16. Our check provides: Provides Name Description Type Unit sys_load_1 System load average for last minute gauge None sys_load_5 System load average for last 5 minutes gauge None sys_load_15 System load average for last 15 minutes gauge None As regular checks and also triggers special WARNING, when value of sys_load_1 is more that 90% of amount of CPU cores and ERROR, when its equal or more that 100%. This behavior can be changed by editing check_load_average.py and changing : warn_level = 90 crit_level = 100 to desired values. However these values are quite reasonable so, use it without modifications, if you are not for 100% sure that you need to change it","title":"Load Average"},{"location":"agent/system/#tcp-connections","text":"This check provides status of TCP connections to systems. It parses /proc/net/tcp and provides following metrics. Provides Name Description Type Unit tcp_close TCP connections with CLOSED state gauge None tcp_close_wait The remote side has been shut down and is now waiting for the socket to close gauge None tcp_closing TCP connections in closing state gauge None tcp_established The socket has a connection established gauge None tcp_fin_wait1 The socket is closed, and the connection is now shutting down. gauge None tcp_last_ack TCP connections in last ack state gauge None tcp_listen TCP listening sockets gauge None tcp_max_states TCP connections in max state gauge None tcp_new_syn_recv TCP connections in new syn recv state gauge None tcp_syn_recv TCP connections in syn recvstate gauge None tcp_syn_sent TCP connections in syn recv state gauge None tcp_time_wait TCP connections in time wait state gauge None On some very heavy loaded systems, this check may become expensive, please make sure its suits your system resources before enabling it on systems with 20k+ TCP ESTABLISHED connections.","title":"TCP Connections"},{"location":"agent/system/#btrfs-check","text":"BTRFS check can be very useful in combinations with regular Drive IO checks on systems which uses BTRFS file system. Its monitors BTRFS volumes and checks for volume errors. It also contains special check which will send manually defined ERROR and WARNING messages if values of checked parameters are above Zero. Manual Error handling can be enabled or disable by setting up enable_special variable at the top of script. Its accepts True or False parameters, defaults is True . Provides btrfs_dev_{NAME}_corruption_errs btrfs_dev_{NAME}_flush_io_errs btrfs_dev_{NAME}_generation_errs btrfs_dev_{NAME}_read_io_errs btrfs_dev_{NAME}_write_io_errs","title":"BTRFS check"},{"location":"agent/varnish/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_varnish.py ./ Configure Configuration of Varnish check is located at webservers.ini . You only need to set right path for varnishstat binary, by default for packaged installation it is /usr/bin/varnishstat . If you have compilled Varnish from source or used oher mechanism to install it, just locate varnishstat change default path in config file. Restart Agent. ./puypuy.sh restart check_varnish module should run without making changes in configuration, but according to your specific needs, you can edit conf/bindata.ini and make changes in section Varnish [Varnish] varnishstat : /usr/bin/varnishstat varnishuser : varnish Usually varnishstat requires ether root or {VARNISH_USER} privilege, so user which runs PuyPuy Agent should be able to execute varnishstat on behalf of privileged user. In most of linux distributions adding following line to /etc/sudoers will do the trick. Lets assume that Varnish is running under user varnish puypuy ALL = ( varnish ) NOPASSWD: /usr/bin/varnishstat Now restart PuyPuy Agent ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit sess_conn Cumulative number of accepted client connections by Varnish Cache rate OPS client_req Cumulative number of received client requests. Increments after a request is received, but before Varnish responds rate OPS cache_hit Cumulative number of times a file was served from Varnish\u2019s cache rate OPS cache_miss Cumulative number of times a file was requested but was not in the cache, and was therefore requested from the backend rate OPS cache_hitpass Cumulative number of hits for a \u201cpass\u201d file rate OPS threads Number of threads in all pools current None threads_created Number of times a thread has been created current None threads_failed Number of times that Varnish unsuccessfully tried to create a thread current None threads_limited Number of times a thread needed to be created but couldn't because varnishd maxed out its configured capacity for new threads current None thread_queue_len Current queue length: number of requests waiting on worker thread to become available current None sess_queued Number of times Varnish has been out of threads and had to queue up a request current None backend_conn Cumulative number of successful TCP connections to the backend counter None backend_recycle Cumulative number of current backend connections which were put back to a pool of keep-alive connections and have not yet been used counter None backend_reuse Cumulative number of connections that were reused from the keep-alive pool counter None backend_toolate Cumulative number of backend connections that have been closed because they were idle for too long counter None backend_fail Cumulative number of failed connections to the backend counter None backend_unhealthy Cumulative number of backend connections which were not attempted because the backend has been marked as unhealthy counter None backend_busy Cumulative number of times the maximum amount of connections to the backend has been reached counter None backend_req Number of requests to the backend counter None n_expired Cumulative number of expired objects for example due to TTL gauge None n_lru_nuked Least Recently Used Nuked Objects: Cumulative number of cached objects that Varnish has evicted from the cache because of a lack of space current None sess_dropped Number of connections dropped due to a full queue current None","title":"Varnish"},{"location":"agent/varnish/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_varnish.py ./","title":"Install"},{"location":"agent/varnish/#configure","text":"Configuration of Varnish check is located at webservers.ini . You only need to set right path for varnishstat binary, by default for packaged installation it is /usr/bin/varnishstat . If you have compilled Varnish from source or used oher mechanism to install it, just locate varnishstat change default path in config file. Restart Agent. ./puypuy.sh restart check_varnish module should run without making changes in configuration, but according to your specific needs, you can edit conf/bindata.ini and make changes in section Varnish [Varnish] varnishstat : /usr/bin/varnishstat varnishuser : varnish Usually varnishstat requires ether root or {VARNISH_USER} privilege, so user which runs PuyPuy Agent should be able to execute varnishstat on behalf of privileged user. In most of linux distributions adding following line to /etc/sudoers will do the trick. Lets assume that Varnish is running under user varnish puypuy ALL = ( varnish ) NOPASSWD: /usr/bin/varnishstat Now restart PuyPuy Agent ${ PUYPUY_HOME } /puypuy.sh restart","title":"Configure"},{"location":"agent/varnish/#provides","text":"Name Description Type Unit sess_conn Cumulative number of accepted client connections by Varnish Cache rate OPS client_req Cumulative number of received client requests. Increments after a request is received, but before Varnish responds rate OPS cache_hit Cumulative number of times a file was served from Varnish\u2019s cache rate OPS cache_miss Cumulative number of times a file was requested but was not in the cache, and was therefore requested from the backend rate OPS cache_hitpass Cumulative number of hits for a \u201cpass\u201d file rate OPS threads Number of threads in all pools current None threads_created Number of times a thread has been created current None threads_failed Number of times that Varnish unsuccessfully tried to create a thread current None threads_limited Number of times a thread needed to be created but couldn't because varnishd maxed out its configured capacity for new threads current None thread_queue_len Current queue length: number of requests waiting on worker thread to become available current None sess_queued Number of times Varnish has been out of threads and had to queue up a request current None backend_conn Cumulative number of successful TCP connections to the backend counter None backend_recycle Cumulative number of current backend connections which were put back to a pool of keep-alive connections and have not yet been used counter None backend_reuse Cumulative number of connections that were reused from the keep-alive pool counter None backend_toolate Cumulative number of backend connections that have been closed because they were idle for too long counter None backend_fail Cumulative number of failed connections to the backend counter None backend_unhealthy Cumulative number of backend connections which were not attempted because the backend has been marked as unhealthy counter None backend_busy Cumulative number of times the maximum amount of connections to the backend has been reached counter None backend_req Number of requests to the backend counter None n_expired Cumulative number of expired objects for example due to TTL gauge None n_lru_nuked Least Recently Used Nuked Objects: Cumulative number of cached objects that Varnish has evicted from the cache because of a lack of space current None sess_dropped Number of connections dropped due to a full queue current None","title":"Provides"},{"location":"agent/webservers/","text":"Apache Install In order to get statiscics from Apache2 web server, you should enable status module and define status URL. On Debian like system, you can do it by a2enmod status or adding following to Apache main config file: LoadModule status_module /path/to/apache/mod_status.so After enabling status module you should configure status URL. <Location /server-status > SetHandler server-status </Location> Its STRONGLY recommended to limit access to this page ether by limiting by source IP, or enabling authentication on this page : <Location /server-status > SetHandler server-status Order deny,allow Deny from all Allow from 127.0.0.1 ::1 Allow from 192.0.1.0/24 </Location> This will allow access to status page only from Localhost and 192.168.1.0/24 subnet. <Location /server-status > SetHandler server-status AuthUserFile /etc/apache2/USERLIST AuthName \"restricted stuff\" AuthType Basic require valid-user </Location> This will require authentication for status page. In real life cluster installation HDFS NameNode doesn't use loopback interface, so make sure that you put right IP of NameNode in config file. Configure At Agent side you should make config changes in order to tell Agent how to get statistics from Apache server. Config file for Webservers is {AGENT_HOME}/conf/webservers.ini. and it should look like this [Apache] url : http://127.0.0.1:8080/server-status?auto user : user pass : password auth : True If you have not configured Apache to require login for status page just set auth: True and write something as username and password. Do not delete user/pass/auth sections, even if you do not use it. Symlink or copy checks_available/check_apache.py to checks_enabled/check_apache.py . Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit apache_busyworkers Worker processes that servers client requests gauge None apache_bytesperreq Served bytes per request gauge Bytes apache_bytespersec Served bytes per second rate Bytes apache_idleworkers Started workers which do not serve any request gauge None apache_reqpersec Requests per second served by HTTTPD server rate OPS apache_totalaccesses Accesses to server since last restart counter None apache_totalkbytes Bytes served since last restart counter kBytes NginX Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_nginx.py ./ Configure Status page os Nginx is disabled by default. You can enable it by adding following to NginX config file and restarting daemon. Code below will do the trick: location /nginx_status { stub_status on; allow 127.0.0.1; deny all; } We recommend to use separate Server directive status for dedicated port. server { listen 127 .0.0.1:8088 ; root /var/www ; index index.html ; server_name localhost ; location /nginx_status { stub_status on ; } } This way your NginX server will bind to port 8088 on loop back interface. Its very easy and secure way to provide status. After enabling NginX Status, You should add status page parameters to {AGENT_HOME}/conf/webservers.ini . [NginX] address : http://127.0.0.1:8888 stats : /nginx_status auth : False user : user pass : password Change auth enabled from False to True, if you have anabled authentication on NginX status URL. Please do not delete user/pass/auth, just put some placeholders, if authentication is disabled. Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit nginx_accept NginX Accepts per second rate OPS nginx_connections Current connections count gauge None nginx_handled Handled requests per second rate OPS nginx_reading Nginx reading requests gauge None nginx_requests Total requests handled by per second rate OPS nginx_waiting Nginx Waiting for client counter None nginx_writing Nginx writing requests counter None PHP-FPM Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_phpfpm.py ./ Configure PHP-FPM provides very usefull statistics about its internal processes. To enable stats for php-fpm edit php.ini file and add following pm.status_path = /fpm-status . FPM status page should be configured at webserver as well. Asuming you are using NginX. So cinfig will look like this: location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; allow 127.0.0.1; deny all; } In conjunction with NginX config above, full config file for NginX+FPM status will look like this : server { listen 127.0.0.1:8088; root /var/www; index index.html ; server_name localhost; location /nginx_status { stub_status on; } location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } This is easy way to keep stats related configs in the same place and keep tracking of configuration files. After PHP-FPM is configured you can copy or symlink checks_available/check_phpfpm.py to checks_enabled/check_phpfpm.py , configure Agent in conf/webservers.ini and restart Agent daemon. [PhpFPM] address : http://127.0.0.1:8888 stats : /fpm-status auth : False user : User pass : Pass Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit phpfpm_conns_per_sec FastCGI Connections per second rate OPS phpfpm_max_active Number of maximum active connections gauge None phpfpm_max_children Maximum allowed child processes gauge None phpfpm_proc_active Number of active processes gauge None phpfpm_proc_idle Number of idle processes gauge None phpfpm_proc_total Total number of processes gauge None phpfpm_slow_request Number of slow requests gauge OPS Tomcat Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_tomcat.py ./ Configure Apache Tomcat also ships with by default disabled status page. In order to get stats from tomcat, you should edit CATALINA_HOME/conf/tomcat-users.xml and enable role manager-jmx . To do this enter following to tomcat-users.xml and restart Tomcat . <role rolename= \"manager-jmx\" /> <user username= \"User\" password= \"Pass\" roles= \"manager-jmx\" /> If you see 403 Access Denied, try to edit CATALINA_HOME/webapps/manager/META-INF/context.xml and somment Valve : <Context antiResourceLocking= \"false\" privileged= \"true\" > <!-- <Valve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" /> --> </Context> Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit tomcat_daemonthreadcount Amount of running Java daemon threads gauge None tomcat_heap_commited Java Heap committed gauge Bytes tomcat_heap_init Java Heap init gauge Bytes tomcat_heap_max Java Heap max gauge Bytes tomcat_heap_used Java Heap used gauge Bytes tomcat_lastgc_0 Young generation GC time gauge Milliseconds tomcat_lastgc_1 Old generation GC time gauge Milliseconds tomcat_nonheap_commited Java non Heap committed gauge Bytes tomcat_nonheap_init Java non Heap init gauge Bytes tomcat_nonheap_max Java non Heap max gauge Bytes tomcat_nonheap_used Java non Heap used gauge Bytes tomcat_peakthreadcount Peak amount of Java threads gauge Bytes tomcat_threadcount Running threads of tomcat gauge None tomcat_totalstartedthreadcount Total amount of threads started by tomcat counter None Jetty Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jetty.py ./ Configure Jetty comes with pre built support of Jolokia, but module is disabled by default. All is needed is just to enable jolokia and restart Jetty. cd $JETTY_HOME bin/jetty.sh stop java -jar start.jar --add-to-start = jolokia bin/jetty.sh start After enabling Jetty-Jolokia copy or symlink checks_available/check_jetty.py to checks_enabled/check_jetty.py , Change IP:PORT of Jetty server at section [Jetty] of conf/webservers.ini to match IP:PORT of your server. Provides Name Description Type Unit jetty_asyncrequests Number of async requests to Jetty gauge None jetty_daemonthreadcount Number of running daemon threads gauge None jetty_dispatchedactive Number of dispatched threads gauge None jetty_{G1,CMS}_old_collectioncount Number of old gen GC collections counter None jetty_{G1,CMS}_old_collectiontime Time spend for old gen GC counter Milliseconds jetty_{G1,CMS}_old_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_{G1,CMS}_young_collectioncount Number of young gen GC collections counter None jetty_{G1,CMS}_young_collectiontime Time spend for young gen GC counter Milliseconds jetty_{G1,CMS}_young_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_heap_committed Java heap committed gauge Bytes jetty_heap_max Java heap max gauge Bytes jetty_heap_used Java heap used gauge Bytes jetty_nonheap_committed Java non heap committed gauge Bytes jetty_nonheap_max Java non heap max gauge Bytes jetty_nonheap_used Java non heap used gauge Bytes jetty_peakthreadcount Peak amount of running threads gauge None jetty_requests_rate Requests per seconds executed on server rate OPS jetty_requestsactive Current active requests gauge None jetty_requesttimemean Mean requests time gauge Milliseconds jetty_responses1xx Responses of type 1xx counter None jetty_responses2xx Responses of type 2xx counter None jetty_responses4xx Responses of type 4xx counter None jetty_responses5xx Responses of type 5xx counter None jetty_threadcount Jetty running threads gauge None Lighttpd Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_lighttpd.py ./ Configure Lighttpd is a lightweight HTTP servers build with performance and security in mind. In order to collect metrics from Lighttpd servers you need first to enable and configure stats module. Loading module: server.modules = ( ..., \"mod_status\" , ... ) Status page is disabled by default so you need to enable it status.status-url = \"/server-status\" You can restrict access to status url by allowing access only from certain subnet : $HTTP [ \"remoteip\" ] == \"192.168.0.0/24\" { status.status-url = \"/server-status\" } Or requesting authentication: auth.require = ( \"/server-status\" = > ( \"realm\" ... ) ) Please make sure that you configure URL and HOST in conf/webservers.ini file. Default configuration looks like this: [Lighttpd] address : http://127.0.0.1 stats : /server-status?auto auth : False user : netangels pass : bololo HTTP API check_http_api is basic check for measuring performance of HTTP API servers. Any HTTP backend can act as monitoring point for this check. It will do GET request to your api server and calculate its response time, which will be sent to PuyPuy. check_http_api supports HTTP basic authentication. Parameters for this check ate in HTTP section of webservers.ini file: [HTTP] upstream : http://your.api.com:8080, https://yoursecure.api.com:8443 user : netangels pass : bololo auth : True You can add as many upstreams as you wish to monitor. The only limit is that you must provide full URL of monitored endpoint. Final metrics names will look like this : http_your_api_com_8080 http_your_secure_api_com_8443 Where 8080 amd 8443 are ports of configured API server. If your api server binds on default HTTP/HTTPS ports, you can exclude port number from upstream of HTTP config: [HTTP] upstream : http://your.api.com, https://yoursecure.api.com user : netangels pass : bololo auth : True In this case check names at PuyPuy will look like this: http_your_api_com_80 http_your_secure_api_com_443 Please note that http_ prefix is not describing exact protocol, but just prefixing check name for easy check. Thus both HTTP and HTTPS checks will have http_ prefix.","title":"Webservers"},{"location":"agent/webservers/#apache","text":"Install In order to get statiscics from Apache2 web server, you should enable status module and define status URL. On Debian like system, you can do it by a2enmod status or adding following to Apache main config file: LoadModule status_module /path/to/apache/mod_status.so After enabling status module you should configure status URL. <Location /server-status > SetHandler server-status </Location> Its STRONGLY recommended to limit access to this page ether by limiting by source IP, or enabling authentication on this page : <Location /server-status > SetHandler server-status Order deny,allow Deny from all Allow from 127.0.0.1 ::1 Allow from 192.0.1.0/24 </Location> This will allow access to status page only from Localhost and 192.168.1.0/24 subnet. <Location /server-status > SetHandler server-status AuthUserFile /etc/apache2/USERLIST AuthName \"restricted stuff\" AuthType Basic require valid-user </Location> This will require authentication for status page. In real life cluster installation HDFS NameNode doesn't use loopback interface, so make sure that you put right IP of NameNode in config file. Configure At Agent side you should make config changes in order to tell Agent how to get statistics from Apache server. Config file for Webservers is {AGENT_HOME}/conf/webservers.ini. and it should look like this [Apache] url : http://127.0.0.1:8080/server-status?auto user : user pass : password auth : True If you have not configured Apache to require login for status page just set auth: True and write something as username and password. Do not delete user/pass/auth sections, even if you do not use it. Symlink or copy checks_available/check_apache.py to checks_enabled/check_apache.py . Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit apache_busyworkers Worker processes that servers client requests gauge None apache_bytesperreq Served bytes per request gauge Bytes apache_bytespersec Served bytes per second rate Bytes apache_idleworkers Started workers which do not serve any request gauge None apache_reqpersec Requests per second served by HTTTPD server rate OPS apache_totalaccesses Accesses to server since last restart counter None apache_totalkbytes Bytes served since last restart counter kBytes","title":"Apache"},{"location":"agent/webservers/#nginx","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_nginx.py ./ Configure Status page os Nginx is disabled by default. You can enable it by adding following to NginX config file and restarting daemon. Code below will do the trick: location /nginx_status { stub_status on; allow 127.0.0.1; deny all; } We recommend to use separate Server directive status for dedicated port. server { listen 127 .0.0.1:8088 ; root /var/www ; index index.html ; server_name localhost ; location /nginx_status { stub_status on ; } } This way your NginX server will bind to port 8088 on loop back interface. Its very easy and secure way to provide status. After enabling NginX Status, You should add status page parameters to {AGENT_HOME}/conf/webservers.ini . [NginX] address : http://127.0.0.1:8888 stats : /nginx_status auth : False user : user pass : password Change auth enabled from False to True, if you have anabled authentication on NginX status URL. Please do not delete user/pass/auth, just put some placeholders, if authentication is disabled. Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit nginx_accept NginX Accepts per second rate OPS nginx_connections Current connections count gauge None nginx_handled Handled requests per second rate OPS nginx_reading Nginx reading requests gauge None nginx_requests Total requests handled by per second rate OPS nginx_waiting Nginx Waiting for client counter None nginx_writing Nginx writing requests counter None","title":"NginX"},{"location":"agent/webservers/#php-fpm","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_phpfpm.py ./ Configure PHP-FPM provides very usefull statistics about its internal processes. To enable stats for php-fpm edit php.ini file and add following pm.status_path = /fpm-status . FPM status page should be configured at webserver as well. Asuming you are using NginX. So cinfig will look like this: location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; allow 127.0.0.1; deny all; } In conjunction with NginX config above, full config file for NginX+FPM status will look like this : server { listen 127.0.0.1:8088; root /var/www; index index.html ; server_name localhost; location /nginx_status { stub_status on; } location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } This is easy way to keep stats related configs in the same place and keep tracking of configuration files. After PHP-FPM is configured you can copy or symlink checks_available/check_phpfpm.py to checks_enabled/check_phpfpm.py , configure Agent in conf/webservers.ini and restart Agent daemon. [PhpFPM] address : http://127.0.0.1:8888 stats : /fpm-status auth : False user : User pass : Pass Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit phpfpm_conns_per_sec FastCGI Connections per second rate OPS phpfpm_max_active Number of maximum active connections gauge None phpfpm_max_children Maximum allowed child processes gauge None phpfpm_proc_active Number of active processes gauge None phpfpm_proc_idle Number of idle processes gauge None phpfpm_proc_total Total number of processes gauge None phpfpm_slow_request Number of slow requests gauge OPS","title":"PHP-FPM"},{"location":"agent/webservers/#tomcat","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_tomcat.py ./ Configure Apache Tomcat also ships with by default disabled status page. In order to get stats from tomcat, you should edit CATALINA_HOME/conf/tomcat-users.xml and enable role manager-jmx . To do this enter following to tomcat-users.xml and restart Tomcat . <role rolename= \"manager-jmx\" /> <user username= \"User\" password= \"Pass\" roles= \"manager-jmx\" /> If you see 403 Access Denied, try to edit CATALINA_HOME/webapps/manager/META-INF/context.xml and somment Valve : <Context antiResourceLocking= \"false\" privileged= \"true\" > <!-- <Valve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" /> --> </Context> Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit tomcat_daemonthreadcount Amount of running Java daemon threads gauge None tomcat_heap_commited Java Heap committed gauge Bytes tomcat_heap_init Java Heap init gauge Bytes tomcat_heap_max Java Heap max gauge Bytes tomcat_heap_used Java Heap used gauge Bytes tomcat_lastgc_0 Young generation GC time gauge Milliseconds tomcat_lastgc_1 Old generation GC time gauge Milliseconds tomcat_nonheap_commited Java non Heap committed gauge Bytes tomcat_nonheap_init Java non Heap init gauge Bytes tomcat_nonheap_max Java non Heap max gauge Bytes tomcat_nonheap_used Java non Heap used gauge Bytes tomcat_peakthreadcount Peak amount of Java threads gauge Bytes tomcat_threadcount Running threads of tomcat gauge None tomcat_totalstartedthreadcount Total amount of threads started by tomcat counter None","title":"Tomcat"},{"location":"agent/webservers/#jetty","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jetty.py ./ Configure Jetty comes with pre built support of Jolokia, but module is disabled by default. All is needed is just to enable jolokia and restart Jetty. cd $JETTY_HOME bin/jetty.sh stop java -jar start.jar --add-to-start = jolokia bin/jetty.sh start After enabling Jetty-Jolokia copy or symlink checks_available/check_jetty.py to checks_enabled/check_jetty.py , Change IP:PORT of Jetty server at section [Jetty] of conf/webservers.ini to match IP:PORT of your server. Provides Name Description Type Unit jetty_asyncrequests Number of async requests to Jetty gauge None jetty_daemonthreadcount Number of running daemon threads gauge None jetty_dispatchedactive Number of dispatched threads gauge None jetty_{G1,CMS}_old_collectioncount Number of old gen GC collections counter None jetty_{G1,CMS}_old_collectiontime Time spend for old gen GC counter Milliseconds jetty_{G1,CMS}_old_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_{G1,CMS}_young_collectioncount Number of young gen GC collections counter None jetty_{G1,CMS}_young_collectiontime Time spend for young gen GC counter Milliseconds jetty_{G1,CMS}_young_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_heap_committed Java heap committed gauge Bytes jetty_heap_max Java heap max gauge Bytes jetty_heap_used Java heap used gauge Bytes jetty_nonheap_committed Java non heap committed gauge Bytes jetty_nonheap_max Java non heap max gauge Bytes jetty_nonheap_used Java non heap used gauge Bytes jetty_peakthreadcount Peak amount of running threads gauge None jetty_requests_rate Requests per seconds executed on server rate OPS jetty_requestsactive Current active requests gauge None jetty_requesttimemean Mean requests time gauge Milliseconds jetty_responses1xx Responses of type 1xx counter None jetty_responses2xx Responses of type 2xx counter None jetty_responses4xx Responses of type 4xx counter None jetty_responses5xx Responses of type 5xx counter None jetty_threadcount Jetty running threads gauge None","title":"Jetty"},{"location":"agent/webservers/#lighttpd","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_lighttpd.py ./ Configure Lighttpd is a lightweight HTTP servers build with performance and security in mind. In order to collect metrics from Lighttpd servers you need first to enable and configure stats module. Loading module: server.modules = ( ..., \"mod_status\" , ... ) Status page is disabled by default so you need to enable it status.status-url = \"/server-status\" You can restrict access to status url by allowing access only from certain subnet : $HTTP [ \"remoteip\" ] == \"192.168.0.0/24\" { status.status-url = \"/server-status\" } Or requesting authentication: auth.require = ( \"/server-status\" = > ( \"realm\" ... ) ) Please make sure that you configure URL and HOST in conf/webservers.ini file. Default configuration looks like this: [Lighttpd] address : http://127.0.0.1 stats : /server-status?auto auth : False user : netangels pass : bololo","title":"Lighttpd"},{"location":"agent/webservers/#http-api","text":"check_http_api is basic check for measuring performance of HTTP API servers. Any HTTP backend can act as monitoring point for this check. It will do GET request to your api server and calculate its response time, which will be sent to PuyPuy. check_http_api supports HTTP basic authentication. Parameters for this check ate in HTTP section of webservers.ini file: [HTTP] upstream : http://your.api.com:8080, https://yoursecure.api.com:8443 user : netangels pass : bololo auth : True You can add as many upstreams as you wish to monitor. The only limit is that you must provide full URL of monitored endpoint. Final metrics names will look like this : http_your_api_com_8080 http_your_secure_api_com_8443 Where 8080 amd 8443 are ports of configured API server. If your api server binds on default HTTP/HTTPS ports, you can exclude port number from upstream of HTTP config: [HTTP] upstream : http://your.api.com, https://yoursecure.api.com user : netangels pass : bololo auth : True In this case check names at PuyPuy will look like this: http_your_api_com_80 http_your_secure_api_com_443 Please note that http_ prefix is not describing exact protocol, but just prefixing check name for easy check. Thus both HTTP and HTTPS checks will have http_ prefix.","title":"HTTP API"},{"location":"agent/zookeeper/","text":"Apache Zookeeper is a highly reliable distributed coordination system, which is build on ideas of Google's Chubby. Lots of distributed systems (HBase, Kafka, etc .. ) use Apache Zookeeper coordinator service, so monitoring of Zookeeper service is very critical for these infrastructures. Agent natively supports Zookeeper metrics and all is needed to point Agent to right Zookeeper host/port. Configuration of check_zookeeper is stored in conf/hadoop.ini file. For most of setups it does not needs extra configuration, but if you run Zookeeper on different from default host/port, edit conf/hadoop.ini section ZooKeeper with setting of your ZooKeeper service: Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_zookeeper.py ./ Configure [ZooKeeper] host : 127.0.0.1 port : 2181 Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit zk_approximate_data_size Approximate data size in bytes gauge Bytes zk_avg_latency Average latency of requests gauge Milliseconds zk_ephemerals_count Ephemeral items count gauge None zk_max_latency Requests max latency gauge Milliseconds zk_min_latency Requests min latency gauge Milliseconds zk_open_file_descriptor_count ZooKeeper daemon open files descriptors count gauge None zk_outstanding_requests Outstanding requests count gauge None zk_packets_received ZooKeeper packets received per second rate OPS zk_packets_sent ZooKeeper packets sent per second rate OPS zk_watch_count ZooKeeper watches count gauge None zk_znode_count ZooKeeper Znodes count gauge None","title":"Zookeeper"},{"location":"agent/zookeeper/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_zookeeper.py ./","title":"Install"},{"location":"agent/zookeeper/#configure","text":"[ZooKeeper] host : 127.0.0.1 port : 2181","title":"Configure"},{"location":"agent/zookeeper/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/zookeeper/#provides","text":"Name Description Type Unit zk_approximate_data_size Approximate data size in bytes gauge Bytes zk_avg_latency Average latency of requests gauge Milliseconds zk_ephemerals_count Ephemeral items count gauge None zk_max_latency Requests max latency gauge Milliseconds zk_min_latency Requests min latency gauge Milliseconds zk_open_file_descriptor_count ZooKeeper daemon open files descriptors count gauge None zk_outstanding_requests Outstanding requests count gauge None zk_packets_received ZooKeeper packets received per second rate OPS zk_packets_sent ZooKeeper packets sent per second rate OPS zk_watch_count ZooKeeper watches count gauge None zk_znode_count ZooKeeper Znodes count gauge None","title":"Provides"},{"location":"agent/lb/envoy/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_envoy.py ./ Configure Start Envoy with following parameters admin : access_log_path : \"/dev/null\" address : socket_address : address : 127.0.0.1 port_value : 8001 Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [Envoy] metrics : http://127.0.0.1:8001/stats/prometheus Restart PuyPuy agent and Envoy. Provides Name Type Description downstream_cx_total counter Total connections downstream_cx_ssl_total counter Total TLS connections downstream_cx_http1_total counter Total HTTP/1.1 connections downstream_cx_websocket_total counter Total WebSocket connections downstream_cx_http2_total counter Total HTTP/2 connections downstream_cx_destroy counter Total connections destroyed downstream_cx_destroy_remote counter Total connections destroyed due to remote close downstream_cx_destroy_local counter Total connections destroyed due to local close downstream_cx_destroy_active_rq counter Total connections destroyed with 1+ active request downstream_cx_destroy_local_active_rq counter Total connections destroyed locally with 1+ active request downstream_cx_destroy_remote_active_rq counter Total connections destroyed remotely with 1+ active request downstream_cx_active gauge Total active connections downstream_cx_ssl_active gauge Total active TLS connections downstream_cx_http1_active gauge Total active HTTP/1.1 connections downstream_cx_websocket_active gauge Total active WebSocket connections downstream_cx_http2_active gauge Total active HTTP/2 connections downstream_cx_protocol_error counter Total protocol errors downstream_cx_length_ms histogram Connection length milliseconds downstream_cx_rx_bytes_total counter Total bytes received downstream_cx_rx_bytes_buffered gauge Total received bytes currently buffered downstream_cx_tx_bytes_total counter Total bytes sent downstream_cx_tx_bytes_buffered gauge Total sent bytes currently buffered downstream_cx_drain_close counter Total connections closed due to draining downstream_cx_idle_timeout counter Total connections closed due to idle timeout downstream_flow_control_paused_reading_total counter Total number of times reads were disabled due to flow control downstream_flow_control_resumed_reading_total counter Total number of times reads were enabled on the connection due to flow control downstream_rq_total counter Total requests downstream_rq_http1_total counter Total HTTP/1.1 requests downstream_rq_http2_total counter Total HTTP/2 requests downstream_rq_active gauge Total active requests downstream_rq_response_before_rq_complete counter Total responses sent before the request was complete downstream_rq_rx_reset counter Total request resets received downstream_rq_tx_reset counter Total request resets sent downstream_rq_non_relative_path counter Total requests with a non-relative HTTP path downstream_rq_too_large counter Total requests resulting in a 413 due to buffering an overly large body downstream_rq_1xx counter Total 1xx responses downstream_rq_2xx counter Total 2xx responses downstream_rq_3xx counter Total 3xx responses downstream_rq_4xx counter Total 4xx responses downstream_rq_5xx counter Total 5xx responses downstream_rq_ws_on_non_ws_route counter Total WebSocket upgrade requests rejected by non WebSocket routes downstream_rq_time histogram Request time milliseconds rs_too_large counter Total response errors due to buffering an overly large body","title":"Envoy"},{"location":"agent/lb/envoy/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_envoy.py ./","title":"Install"},{"location":"agent/lb/envoy/#configure","text":"Start Envoy with following parameters admin : access_log_path : \"/dev/null\" address : socket_address : address : 127.0.0.1 port_value : 8001 Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [Envoy] metrics : http://127.0.0.1:8001/stats/prometheus Restart PuyPuy agent and Envoy.","title":"Configure"},{"location":"agent/lb/envoy/#provides","text":"Name Type Description downstream_cx_total counter Total connections downstream_cx_ssl_total counter Total TLS connections downstream_cx_http1_total counter Total HTTP/1.1 connections downstream_cx_websocket_total counter Total WebSocket connections downstream_cx_http2_total counter Total HTTP/2 connections downstream_cx_destroy counter Total connections destroyed downstream_cx_destroy_remote counter Total connections destroyed due to remote close downstream_cx_destroy_local counter Total connections destroyed due to local close downstream_cx_destroy_active_rq counter Total connections destroyed with 1+ active request downstream_cx_destroy_local_active_rq counter Total connections destroyed locally with 1+ active request downstream_cx_destroy_remote_active_rq counter Total connections destroyed remotely with 1+ active request downstream_cx_active gauge Total active connections downstream_cx_ssl_active gauge Total active TLS connections downstream_cx_http1_active gauge Total active HTTP/1.1 connections downstream_cx_websocket_active gauge Total active WebSocket connections downstream_cx_http2_active gauge Total active HTTP/2 connections downstream_cx_protocol_error counter Total protocol errors downstream_cx_length_ms histogram Connection length milliseconds downstream_cx_rx_bytes_total counter Total bytes received downstream_cx_rx_bytes_buffered gauge Total received bytes currently buffered downstream_cx_tx_bytes_total counter Total bytes sent downstream_cx_tx_bytes_buffered gauge Total sent bytes currently buffered downstream_cx_drain_close counter Total connections closed due to draining downstream_cx_idle_timeout counter Total connections closed due to idle timeout downstream_flow_control_paused_reading_total counter Total number of times reads were disabled due to flow control downstream_flow_control_resumed_reading_total counter Total number of times reads were enabled on the connection due to flow control downstream_rq_total counter Total requests downstream_rq_http1_total counter Total HTTP/1.1 requests downstream_rq_http2_total counter Total HTTP/2 requests downstream_rq_active gauge Total active requests downstream_rq_response_before_rq_complete counter Total responses sent before the request was complete downstream_rq_rx_reset counter Total request resets received downstream_rq_tx_reset counter Total request resets sent downstream_rq_non_relative_path counter Total requests with a non-relative HTTP path downstream_rq_too_large counter Total requests resulting in a 413 due to buffering an overly large body downstream_rq_1xx counter Total 1xx responses downstream_rq_2xx counter Total 2xx responses downstream_rq_3xx counter Total 3xx responses downstream_rq_4xx counter Total 4xx responses downstream_rq_5xx counter Total 5xx responses downstream_rq_ws_on_non_ws_route counter Total WebSocket upgrade requests rejected by non WebSocket routes downstream_rq_time histogram Request time milliseconds rs_too_large counter Total response errors due to buffering an overly large body","title":"Provides"},{"location":"agent/lb/haproxy/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_haproxy.py ./ Configure Statistics for HAProxy can be enabled by adding following to haproxy.conf : listen stats bind : 8888 mode http stats enable stats hide-version stats realm Haproxy\\ Statistics stats uri /haproxy?stats stats auth User : Pass Then you need to configure Agent to start gathering statistics from Haproxy server. [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True upstream : MyApp1 Config parameter upstream is name of upstream server configured in Haproxy. listen MyApp1 192.168.0.1 : 80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10 : 8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20 : 8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor = len 32 rspidel ^Set-cookie : \\ IP= From above mentioned example it is obvious, that upstream name is MyApp1, so this name should be placed as upstream parameter in HAProxy section of webservers.ini If you have more sophisticated HAProxy configuration with multiple upstreams and need to monitor several upstreams, you should write comma and separate names in upstream configuration of Agent: So if your HAProxy configuration looks like this : listen MyApp1 192.168.0.1:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= listen MyApp2 192.168.0.2:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.11:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.22:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= Agent should be configured as follows: [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type haproxy_connrate Connections per second rate nhaproxy_sessions Current active sessions gauge","title":"HAProxy"},{"location":"agent/lb/haproxy/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_haproxy.py ./","title":"Install"},{"location":"agent/lb/haproxy/#configure","text":"Statistics for HAProxy can be enabled by adding following to haproxy.conf : listen stats bind : 8888 mode http stats enable stats hide-version stats realm Haproxy\\ Statistics stats uri /haproxy?stats stats auth User : Pass Then you need to configure Agent to start gathering statistics from Haproxy server. [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True upstream : MyApp1 Config parameter upstream is name of upstream server configured in Haproxy. listen MyApp1 192.168.0.1 : 80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10 : 8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20 : 8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor = len 32 rspidel ^Set-cookie : \\ IP= From above mentioned example it is obvious, that upstream name is MyApp1, so this name should be placed as upstream parameter in HAProxy section of webservers.ini If you have more sophisticated HAProxy configuration with multiple upstreams and need to monitor several upstreams, you should write comma and separate names in upstream configuration of Agent: So if your HAProxy configuration looks like this : listen MyApp1 192.168.0.1:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.10:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.20:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= listen MyApp2 192.168.0.2:80 option httpchk balance roundrobin option httpchk HEAD / HTTP/1.0 option forwardfor cookie SERVERID insert indirect nocache server app1 192.168.0.11:8888 cookie app1 check inter 10000 fall 3 weight 1 server app2 192.168.0.22:8888 cookie app2 check inter 10000 fall 3 weight 1 capture cookie vgnvisitor= len 32 rspidel ^Set-cookie:\\ IP= Agent should be configured as follows: [HAProxy] url : http://127.0.0.1/haproxy?stats ;csv user : User pass : Pass auth : True","title":"Configure"},{"location":"agent/lb/haproxy/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/lb/haproxy/#provides","text":"Name Description Type haproxy_connrate Connections per second rate nhaproxy_sessions Current active sessions gauge","title":"Provides"},{"location":"agent/lb/traefik/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_traefik.py ./ Configure Start Traefik with following parameters [entryPoints.metrics] address = \":8081\" [metrics] [metrics.prometheus] entryPoint = \"metrics\" Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [traefik] metrics : http://127.0.0.1:8081/metrics Restart PuyPuy agent and Envoy. Provides Name Type Description traefik_entrypoint_http_duration_seconds_count counter How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_entrypoint_http_duration_seconds_sum gauge How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_go_gc_duration_seconds_count counter A summary of the GC invocation durations. traefik_go_gc_duration_seconds_sum gauge A summary of the GC invocation durations. traefik_process_cpu_seconds_total counter Total user and system CPU time spent in seconds. traefik_process_max_fds gauge Maximum number of open file descriptors. traefik_process_open_fds gauge Number of open file descriptors. traefik_process_resident_memory_bytes gauge Resident memory size in bytes. traefik_process_start_time_seconds gauge Start time of the process since unix epoch in seconds. traefik_process_virtual_memory_bytes gauge Virtual memory size in bytes. traefik_process_virtual_memory_max_bytes gauge Maximum amount of virtual memory available in bytes.","title":"Traefik"},{"location":"agent/lb/traefik/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_traefik.py ./","title":"Install"},{"location":"agent/lb/traefik/#configure","text":"Start Traefik with following parameters [entryPoints.metrics] address = \":8081\" [metrics] [metrics.prometheus] entryPoint = \"metrics\" Edit conf/loadbalancer.ini and set Envoy URL to prometheus stats. [traefik] metrics : http://127.0.0.1:8081/metrics Restart PuyPuy agent and Envoy.","title":"Configure"},{"location":"agent/lb/traefik/#provides","text":"Name Type Description traefik_entrypoint_http_duration_seconds_count counter How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_entrypoint_http_duration_seconds_sum gauge How long it took to process the request on an entrypoint, partitioned by status code, protocol, and method. traefik_go_gc_duration_seconds_count counter A summary of the GC invocation durations. traefik_go_gc_duration_seconds_sum gauge A summary of the GC invocation durations. traefik_process_cpu_seconds_total counter Total user and system CPU time spent in seconds. traefik_process_max_fds gauge Maximum number of open file descriptors. traefik_process_open_fds gauge Number of open file descriptors. traefik_process_resident_memory_bytes gauge Resident memory size in bytes. traefik_process_start_time_seconds gauge Start time of the process since unix epoch in seconds. traefik_process_virtual_memory_bytes gauge Virtual memory size in bytes. traefik_process_virtual_memory_max_bytes gauge Maximum amount of virtual memory available in bytes.","title":"Provides"},{"location":"agent/ws/apache/","text":"Install In order to get statiscics from Apache2 web server, you should enable status module and define status URL. On Debian like system, you can do it by a2enmod status or adding following to Apache main config file: LoadModule status_module /path/to/apache/mod_status.so After enabling status module you should configure status URL. <Location /server-status > SetHandler server-status </Location> Its STRONGLY recommended to limit access to this page ether by limiting by source IP, or enabling authentication on this page : <Location /server-status > SetHandler server-status Order deny,allow Deny from all Allow from 127.0.0.1 ::1 Allow from 192.0.1.0/24 </Location> This will allow access to status page only from Localhost and 192.168.1.0/24 subnet. <Location /server-status > SetHandler server-status AuthUserFile /etc/apache2/USERLIST AuthName \"restricted stuff\" AuthType Basic require valid-user </Location> This will require authentication for status page. In real life cluster installation HDFS NameNode doesn't use loopback interface, so make sure that you put right IP of NameNode in config file. Configure At Agent side you should make config changes in order to tell Agent how to get statistics from Apache server. Config file for Webservers is {AGENT_HOME}/conf/webservers.ini. and it should look like this [Apache] url : http://127.0.0.1:8080/server-status?auto user : user pass : password auth : True If you have not configured Apache to require login for status page just set auth: True and write something as username and password. Do not delete user/pass/auth sections, even if you do not use it. Symlink or copy checks_available/check_apache.py to checks_enabled/check_apache.py . Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit apache_busyworkers Worker processes that servers client requests gauge None apache_bytesperreq Served bytes per request gauge Bytes apache_bytespersec Served bytes per second rate Bytes apache_idleworkers Started workers which do not serve any request gauge None apache_reqpersec Requests per second served by HTTTPD server rate OPS apache_totalaccesses Accesses to server since last restart counter None apache_totalkbytes Bytes served since last restart counter kBytes","title":"Apache"},{"location":"agent/ws/apache/#install","text":"In order to get statiscics from Apache2 web server, you should enable status module and define status URL. On Debian like system, you can do it by a2enmod status or adding following to Apache main config file: LoadModule status_module /path/to/apache/mod_status.so After enabling status module you should configure status URL. <Location /server-status > SetHandler server-status </Location> Its STRONGLY recommended to limit access to this page ether by limiting by source IP, or enabling authentication on this page : <Location /server-status > SetHandler server-status Order deny,allow Deny from all Allow from 127.0.0.1 ::1 Allow from 192.0.1.0/24 </Location> This will allow access to status page only from Localhost and 192.168.1.0/24 subnet. <Location /server-status > SetHandler server-status AuthUserFile /etc/apache2/USERLIST AuthName \"restricted stuff\" AuthType Basic require valid-user </Location> This will require authentication for status page. In real life cluster installation HDFS NameNode doesn't use loopback interface, so make sure that you put right IP of NameNode in config file.","title":"Install"},{"location":"agent/ws/apache/#configure","text":"At Agent side you should make config changes in order to tell Agent how to get statistics from Apache server. Config file for Webservers is {AGENT_HOME}/conf/webservers.ini. and it should look like this [Apache] url : http://127.0.0.1:8080/server-status?auto user : user pass : password auth : True If you have not configured Apache to require login for status page just set auth: True and write something as username and password. Do not delete user/pass/auth sections, even if you do not use it. Symlink or copy checks_available/check_apache.py to checks_enabled/check_apache.py .","title":"Configure"},{"location":"agent/ws/apache/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/ws/apache/#provides","text":"Name Description Type Unit apache_busyworkers Worker processes that servers client requests gauge None apache_bytesperreq Served bytes per request gauge Bytes apache_bytespersec Served bytes per second rate Bytes apache_idleworkers Started workers which do not serve any request gauge None apache_reqpersec Requests per second served by HTTTPD server rate OPS apache_totalaccesses Accesses to server since last restart counter None apache_totalkbytes Bytes served since last restart counter kBytes","title":"Provides"},{"location":"agent/ws/jetty/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jetty.py ./ Configure Jetty comes with pre built support of Jolokia, but module is disabled by default. All is needed is just to enable jolokia and restart Jetty. cd $JETTY_HOME bin/jetty.sh stop java -jar start.jar --add-to-start = jolokia bin/jetty.sh start After enabling Jetty-Jolokia copy or symlink checks_available/check_jetty.py to checks_enabled/check_jetty.py , Change IP:PORT of Jetty server at section [Jetty] of conf/webservers.ini to match IP:PORT of your server. Provides Name Description Type Unit jetty_asyncrequests Number of async requests to Jetty gauge None jetty_daemonthreadcount Number of running daemon threads gauge None jetty_dispatchedactive Number of dispatched threads gauge None jetty_{G1,CMS}_old_collectioncount Number of old gen GC collections counter None jetty_{G1,CMS}_old_collectiontime Time spend for old gen GC counter Milliseconds jetty_{G1,CMS}_old_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_{G1,CMS}_young_collectioncount Number of young gen GC collections counter None jetty_{G1,CMS}_young_collectiontime Time spend for young gen GC counter Milliseconds jetty_{G1,CMS}_young_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_heap_committed Java heap committed gauge Bytes jetty_heap_max Java heap max gauge Bytes jetty_heap_used Java heap used gauge Bytes jetty_nonheap_committed Java non heap committed gauge Bytes jetty_nonheap_max Java non heap max gauge Bytes jetty_nonheap_used Java non heap used gauge Bytes jetty_peakthreadcount Peak amount of running threads gauge None jetty_requests_rate Requests per seconds executed on server rate OPS jetty_requestsactive Current active requests gauge None jetty_requesttimemean Mean requests time gauge Milliseconds jetty_responses1xx Responses of type 1xx counter None jetty_responses2xx Responses of type 2xx counter None jetty_responses4xx Responses of type 4xx counter None jetty_responses5xx Responses of type 5xx counter None jetty_threadcount Jetty running threads gauge None","title":"Jetty"},{"location":"agent/ws/jetty/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_jetty.py ./","title":"Install"},{"location":"agent/ws/jetty/#configure","text":"Jetty comes with pre built support of Jolokia, but module is disabled by default. All is needed is just to enable jolokia and restart Jetty. cd $JETTY_HOME bin/jetty.sh stop java -jar start.jar --add-to-start = jolokia bin/jetty.sh start After enabling Jetty-Jolokia copy or symlink checks_available/check_jetty.py to checks_enabled/check_jetty.py , Change IP:PORT of Jetty server at section [Jetty] of conf/webservers.ini to match IP:PORT of your server.","title":"Configure"},{"location":"agent/ws/jetty/#provides","text":"Name Description Type Unit jetty_asyncrequests Number of async requests to Jetty gauge None jetty_daemonthreadcount Number of running daemon threads gauge None jetty_dispatchedactive Number of dispatched threads gauge None jetty_{G1,CMS}_old_collectioncount Number of old gen GC collections counter None jetty_{G1,CMS}_old_collectiontime Time spend for old gen GC counter Milliseconds jetty_{G1,CMS}_old_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_{G1,CMS}_young_collectioncount Number of young gen GC collections counter None jetty_{G1,CMS}_young_collectiontime Time spend for young gen GC counter Milliseconds jetty_{G1,CMS}_young_lastgcinfo Duration in milliseconds of previous old gen GC gauge Milliseconds jetty_heap_committed Java heap committed gauge Bytes jetty_heap_max Java heap max gauge Bytes jetty_heap_used Java heap used gauge Bytes jetty_nonheap_committed Java non heap committed gauge Bytes jetty_nonheap_max Java non heap max gauge Bytes jetty_nonheap_used Java non heap used gauge Bytes jetty_peakthreadcount Peak amount of running threads gauge None jetty_requests_rate Requests per seconds executed on server rate OPS jetty_requestsactive Current active requests gauge None jetty_requesttimemean Mean requests time gauge Milliseconds jetty_responses1xx Responses of type 1xx counter None jetty_responses2xx Responses of type 2xx counter None jetty_responses4xx Responses of type 4xx counter None jetty_responses5xx Responses of type 5xx counter None jetty_threadcount Jetty running threads gauge None","title":"Provides"},{"location":"agent/ws/lighty/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_lighttpd.py ./ Configure Lighttpd is a lightweight HTTP servers build with performance and security in mind. In order to collect metrics from Lighttpd servers you need first to enable and configure stats module. Loading module: server.modules = ( ..., \"mod_status\" , ... ) Status page is disabled by default so you need to enable it status.status-url = \"/server-status\" You can restrict access to status url by allowing access only from certain subnet : $HTTP [ \"remoteip\" ] == \"192.168.0.0/24\" { status.status-url = \"/server-status\" } Or requesting authentication: auth.require = ( \"/server-status\" = > ( \"realm\" ... ) ) Please make sure that you configure URL and HOST in conf/webservers.ini file. Default configuration looks like this: [Lighttpd] address : http://127.0.0.1 stats : /server-status?auto auth : False user : netangels pass : bololo","title":"Lighttpd"},{"location":"agent/ws/lighty/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_lighttpd.py ./","title":"Install"},{"location":"agent/ws/lighty/#configure","text":"Lighttpd is a lightweight HTTP servers build with performance and security in mind. In order to collect metrics from Lighttpd servers you need first to enable and configure stats module. Loading module: server.modules = ( ..., \"mod_status\" , ... ) Status page is disabled by default so you need to enable it status.status-url = \"/server-status\" You can restrict access to status url by allowing access only from certain subnet : $HTTP [ \"remoteip\" ] == \"192.168.0.0/24\" { status.status-url = \"/server-status\" } Or requesting authentication: auth.require = ( \"/server-status\" = > ( \"realm\" ... ) ) Please make sure that you configure URL and HOST in conf/webservers.ini file. Default configuration looks like this: [Lighttpd] address : http://127.0.0.1 stats : /server-status?auto auth : False user : netangels pass : bololo","title":"Configure"},{"location":"agent/ws/nginx/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_nginx.py ./ Configure Status page os Nginx is disabled by default. You can enable it by adding following to NginX config file and restarting daemon. Code below will do the trick: location /nginx_status { stub_status on; allow 127.0.0.1; deny all; } We recommend to use separate Server directive status for dedicated port. server { listen 127 .0.0.1:8088 ; root /var/www ; index index.html ; server_name localhost ; location /nginx_status { stub_status on ; } } This way your NginX server will bind to port 8088 on loop back interface. Its very easy and secure way to provide status. After enabling NginX Status, You should add status page parameters to {AGENT_HOME}/conf/webservers.ini . [NginX] address : http://127.0.0.1:8888 stats : /nginx_status auth : False user : user pass : password Change auth enabled from False to True, if you have anabled authentication on NginX status URL. Please do not delete user/pass/auth, just put some placeholders, if authentication is disabled. Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit nginx_accept NginX Accepts per second rate OPS nginx_connections Current connections count gauge None nginx_handled Handled requests per second rate OPS nginx_reading Nginx reading requests gauge None nginx_requests Total requests handled by per second rate OPS nginx_waiting Nginx Waiting for client counter None nginx_writing Nginx writing requests counter None \ud83d\udcc8 Example Grafana Dashboard","title":"NginX"},{"location":"agent/ws/nginx/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_nginx.py ./","title":"Install"},{"location":"agent/ws/nginx/#configure","text":"Status page os Nginx is disabled by default. You can enable it by adding following to NginX config file and restarting daemon. Code below will do the trick: location /nginx_status { stub_status on; allow 127.0.0.1; deny all; } We recommend to use separate Server directive status for dedicated port. server { listen 127 .0.0.1:8088 ; root /var/www ; index index.html ; server_name localhost ; location /nginx_status { stub_status on ; } } This way your NginX server will bind to port 8088 on loop back interface. Its very easy and secure way to provide status. After enabling NginX Status, You should add status page parameters to {AGENT_HOME}/conf/webservers.ini . [NginX] address : http://127.0.0.1:8888 stats : /nginx_status auth : False user : user pass : password Change auth enabled from False to True, if you have anabled authentication on NginX status URL. Please do not delete user/pass/auth, just put some placeholders, if authentication is disabled.","title":"Configure"},{"location":"agent/ws/nginx/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/ws/nginx/#provides","text":"Name Description Type Unit nginx_accept NginX Accepts per second rate OPS nginx_connections Current connections count gauge None nginx_handled Handled requests per second rate OPS nginx_reading Nginx reading requests gauge None nginx_requests Total requests handled by per second rate OPS nginx_waiting Nginx Waiting for client counter None nginx_writing Nginx writing requests counter None \ud83d\udcc8 Example Grafana Dashboard","title":"Provides"},{"location":"agent/ws/php/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_phpfpm.py ./ Configure PHP-FPM provides very usefull statistics about its internal processes. To enable stats for php-fpm edit php.ini file and add following pm.status_path = /fpm-status . FPM status page should be configured at webserver as well. Asuming you are using NginX. So cinfig will look like this: location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; allow 127.0.0.1; deny all; } In conjunction with NginX config above, full config file for NginX+FPM status will look like this : server { listen 127.0.0.1:8088; root /var/www; index index.html ; server_name localhost; location /nginx_status { stub_status on; } location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } This is easy way to keep stats related configs in the same place and keep tracking of configuration files. After PHP-FPM is configured you can copy or symlink checks_available/check_phpfpm.py to checks_enabled/check_phpfpm.py , configure Agent in conf/webservers.ini and restart Agent daemon. [PhpFPM] address : http://127.0.0.1:8888 stats : /fpm-status auth : False user : User pass : Pass Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit phpfpm_conns_per_sec FastCGI Connections per second rate OPS phpfpm_max_active Number of maximum active connections gauge None phpfpm_max_children Maximum allowed child processes gauge None phpfpm_proc_active Number of active processes gauge None phpfpm_proc_idle Number of idle processes gauge None phpfpm_proc_total Total number of processes gauge None phpfpm_slow_request Number of slow requests gauge OPS","title":"PHP-FPM"},{"location":"agent/ws/php/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_phpfpm.py ./","title":"Install"},{"location":"agent/ws/php/#configure","text":"PHP-FPM provides very usefull statistics about its internal processes. To enable stats for php-fpm edit php.ini file and add following pm.status_path = /fpm-status . FPM status page should be configured at webserver as well. Asuming you are using NginX. So cinfig will look like this: location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; allow 127.0.0.1; deny all; } In conjunction with NginX config above, full config file for NginX+FPM status will look like this : server { listen 127.0.0.1:8088; root /var/www; index index.html ; server_name localhost; location /nginx_status { stub_status on; } location /fpm-status { fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } This is easy way to keep stats related configs in the same place and keep tracking of configuration files. After PHP-FPM is configured you can copy or symlink checks_available/check_phpfpm.py to checks_enabled/check_phpfpm.py , configure Agent in conf/webservers.ini and restart Agent daemon. [PhpFPM] address : http://127.0.0.1:8888 stats : /fpm-status auth : False user : User pass : Pass","title":"Configure"},{"location":"agent/ws/php/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/ws/php/#provides","text":"Name Description Type Unit phpfpm_conns_per_sec FastCGI Connections per second rate OPS phpfpm_max_active Number of maximum active connections gauge None phpfpm_max_children Maximum allowed child processes gauge None phpfpm_proc_active Number of active processes gauge None phpfpm_proc_idle Number of idle processes gauge None phpfpm_proc_total Total number of processes gauge None phpfpm_slow_request Number of slow requests gauge OPS","title":"Provides"},{"location":"agent/ws/rest/","text":"check_http_api is basic check for measuring performance of HTTP API servers. Any HTTP backend can act as monitoring point for this check. It will do GET request to your api server and calculate its response time, which will be sent to PuyPuy. check_http_api supports HTTP basic authentication. Parameters for this check ate in HTTP section of webservers.ini file: [HTTP] upstream : http://your.api.com:8080, https://yoursecure.api.com:8443 user : netangels pass : bololo auth : True You can add as many upstreams as you wish to monitor. The only limit is that you must provide full URL of monitored endpoint. Final metrics names will look like this : http_your_api_com_8080 http_your_secure_api_com_8443 Where 8080 amd 8443 are ports of configured API server. If your api server binds on default HTTP/HTTPS ports, you can exclude port number from upstream of HTTP config: [HTTP] upstream : http://your.api.com, https://yoursecure.api.com user : netangels pass : bololo auth : True In this case check names at PuyPuy will look like this: http_your_api_com_80 http_your_secure_api_com_443 Please note that http_ prefix is not describing exact protocol, but just prefixing check name for easy check. Thus both HTTP and HTTPS checks will have http_ prefix.","title":"HTTP API"},{"location":"agent/ws/tomcat/","text":"Install cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_tomcat.py ./ Configure Apache Tomcat also ships with by default disabled status page. In order to get stats from tomcat, you should edit CATALINA_HOME/conf/tomcat-users.xml and enable role manager-jmx . To do this enter following to tomcat-users.xml and restart Tomcat . <role rolename= \"manager-jmx\" /> <user username= \"User\" password= \"Pass\" roles= \"manager-jmx\" /> If you see 403 Access Denied, try to edit CATALINA_HOME/webapps/manager/META-INF/context.xml and somment Valve : <Context antiResourceLocking= \"false\" privileged= \"true\" > <!-- <Valve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" /> --> </Context> Restart ${ PUYPUY_HOME } /puypuy.sh restart Provides Name Description Type Unit tomcat_daemonthreadcount Amount of running Java daemon threads gauge None tomcat_heap_commited Java Heap committed gauge Bytes tomcat_heap_init Java Heap init gauge Bytes tomcat_heap_max Java Heap max gauge Bytes tomcat_heap_used Java Heap used gauge Bytes tomcat_lastgc_0 Young generation GC time gauge Milliseconds tomcat_lastgc_1 Old generation GC time gauge Milliseconds tomcat_nonheap_commited Java non Heap committed gauge Bytes tomcat_nonheap_init Java non Heap init gauge Bytes tomcat_nonheap_max Java non Heap max gauge Bytes tomcat_nonheap_used Java non Heap used gauge Bytes tomcat_peakthreadcount Peak amount of Java threads gauge Bytes tomcat_threadcount Running threads of tomcat gauge None tomcat_totalstartedthreadcount Total amount of threads started by tomcat counter None","title":"Tomcat"},{"location":"agent/ws/tomcat/#install","text":"cd ${ PUYPUY_HOME } /checks_enabled ln -s ../checks_available/check_tomcat.py ./","title":"Install"},{"location":"agent/ws/tomcat/#configure","text":"Apache Tomcat also ships with by default disabled status page. In order to get stats from tomcat, you should edit CATALINA_HOME/conf/tomcat-users.xml and enable role manager-jmx . To do this enter following to tomcat-users.xml and restart Tomcat . <role rolename= \"manager-jmx\" /> <user username= \"User\" password= \"Pass\" roles= \"manager-jmx\" /> If you see 403 Access Denied, try to edit CATALINA_HOME/webapps/manager/META-INF/context.xml and somment Valve : <Context antiResourceLocking= \"false\" privileged= \"true\" > <!-- <Valve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" /> --> </Context>","title":"Configure"},{"location":"agent/ws/tomcat/#restart","text":"${ PUYPUY_HOME } /puypuy.sh restart","title":"Restart"},{"location":"agent/ws/tomcat/#provides","text":"Name Description Type Unit tomcat_daemonthreadcount Amount of running Java daemon threads gauge None tomcat_heap_commited Java Heap committed gauge Bytes tomcat_heap_init Java Heap init gauge Bytes tomcat_heap_max Java Heap max gauge Bytes tomcat_heap_used Java Heap used gauge Bytes tomcat_lastgc_0 Young generation GC time gauge Milliseconds tomcat_lastgc_1 Old generation GC time gauge Milliseconds tomcat_nonheap_commited Java non Heap committed gauge Bytes tomcat_nonheap_init Java non Heap init gauge Bytes tomcat_nonheap_max Java non Heap max gauge Bytes tomcat_nonheap_used Java non Heap used gauge Bytes tomcat_peakthreadcount Peak amount of Java threads gauge Bytes tomcat_threadcount Running threads of tomcat gauge None tomcat_totalstartedthreadcount Total amount of threads started by tomcat counter None","title":"Provides"},{"location":"articles/hbasecompactions/","text":"HBase is an distributed wide column database optimized for read performance. To chive high read performance it needs to reduce disk seeks, which requires less files per Column Family. This approach is not always possible, that\u2019s why HBase periodically merges small files onto one bigger one to reduce disk seek operations for reading requested information. This process is called Compaction. There are two types of HBase compaction: Minor Compaction Major Compaction Minor compactions Combines configurable amount of small files and merge it into bigger one. Minor compaction is less resource intensive that Major compaction and takes less time, but it happens more frequently. Major Compactions During Major Compaction HBase reads all store files for a Region and writes to a single one. Both Major and Minor compactions are resource intensive intensive, so it needs to be properly configured and monitored. It's very informative to have proper Dashboard for monitoring Compacted bytes and Compacted Cells. These metrics are collected per Region Server so better to create aggregated graph which will display cluster level information . It will be also usefull to create HBase Regionservers cumulative network charts, to see Cluster wide traffic overview. During compaction there is huge impact on network, so you should be aware of your traffic to make proper decisions. Image below illustrated difference of cumulative traffic of all nodes of HBase cluster during compaction processs: This gives an idkea sbout impact of compaction on your cluster. For sure CPU and load average status of nodes are also changed, but networking changes are more obvious. In this image we can see that compaction began at about 11:37 AM. This is Off peak hour for us so its has started at good time. But it may happen at the most peak hour as well when traffic is usually several times bigger. Fortunately HBase is highly configurable systems and allows very granular configuration of compactions lifecycle. It allows you to set peak and non peak hours of your cluster and configure compaction speed in accordance to that. Below are some configuration parameters from hbase-site.xml which can help you to control speed and resource consumption for compactions. Here are some parameters that can help you with fine tuning of compactions: <property> <name> hbase.hstore.compaction.max </name> <value> 10 </value> </property> Maximum number of StoreFiles to compact per minor compaction (default 10) <property> <name> hbase.hstore.compaction.min.size </name> <value> 134217728 </value> </property> Minimal store file size to consider file a candidate for compaction. Defaults to hbase.hregion.memstore.flush.size (128 mb). Also there are several very handy parameters which allows you to set up peak and off peak hours for your cluster and respectively limit bandwidth per interval. Value of these settings should be hours passed since 00:00. So examples below configures Off-Peak start hour at 11:00 AM and end hour at 4:00 PM respectively. <property> <name> hbase.offpeak.start.hour </name> <value> 11 </value> </property> <property> <name> hbase.offpeak.end.hour </name> <value> 16 </value> </property> Next is to configure proper compaction controller : <property><name> hbase.hstore.compaction.throughput.controller </name> <value> org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController </value> </property> Now when we set up Peak and Off-Peak hours we can set bandwidth thresholds for these periods. Peak hours <property> <name> hbase.hstore.compaction.throughput.higher.bound </name> <value> 20971520 </value> <description> The default is 20 MB/sec </description> </property> <property> <name> hbase.hstore.compaction.throughput.lower.bound </name> <value> 10485760 </value> <description> The default is 10 MB/sec </description> </property> Off Peak hours <property> <name> hbase.hstore.compaction.throughput.offpeak </name> <value> 9223372036854775807 </value> </property> The default is Long.MAX_VALUE, which effectively means no limitation","title":"Hbasecompactions"},{"location":"articles/hbasecompactions/#minor-compactions","text":"Combines configurable amount of small files and merge it into bigger one. Minor compaction is less resource intensive that Major compaction and takes less time, but it happens more frequently.","title":"Minor compactions"},{"location":"articles/hbasecompactions/#major-compactions","text":"During Major Compaction HBase reads all store files for a Region and writes to a single one. Both Major and Minor compactions are resource intensive intensive, so it needs to be properly configured and monitored. It's very informative to have proper Dashboard for monitoring Compacted bytes and Compacted Cells. These metrics are collected per Region Server so better to create aggregated graph which will display cluster level information . It will be also usefull to create HBase Regionservers cumulative network charts, to see Cluster wide traffic overview. During compaction there is huge impact on network, so you should be aware of your traffic to make proper decisions. Image below illustrated difference of cumulative traffic of all nodes of HBase cluster during compaction processs: This gives an idkea sbout impact of compaction on your cluster. For sure CPU and load average status of nodes are also changed, but networking changes are more obvious. In this image we can see that compaction began at about 11:37 AM. This is Off peak hour for us so its has started at good time. But it may happen at the most peak hour as well when traffic is usually several times bigger. Fortunately HBase is highly configurable systems and allows very granular configuration of compactions lifecycle. It allows you to set peak and non peak hours of your cluster and configure compaction speed in accordance to that. Below are some configuration parameters from hbase-site.xml which can help you to control speed and resource consumption for compactions. Here are some parameters that can help you with fine tuning of compactions: <property> <name> hbase.hstore.compaction.max </name> <value> 10 </value> </property> Maximum number of StoreFiles to compact per minor compaction (default 10) <property> <name> hbase.hstore.compaction.min.size </name> <value> 134217728 </value> </property> Minimal store file size to consider file a candidate for compaction. Defaults to hbase.hregion.memstore.flush.size (128 mb). Also there are several very handy parameters which allows you to set up peak and off peak hours for your cluster and respectively limit bandwidth per interval. Value of these settings should be hours passed since 00:00. So examples below configures Off-Peak start hour at 11:00 AM and end hour at 4:00 PM respectively. <property> <name> hbase.offpeak.start.hour </name> <value> 11 </value> </property> <property> <name> hbase.offpeak.end.hour </name> <value> 16 </value> </property> Next is to configure proper compaction controller : <property><name> hbase.hstore.compaction.throughput.controller </name> <value> org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController </value> </property> Now when we set up Peak and Off-Peak hours we can set bandwidth thresholds for these periods.","title":"Major Compactions"},{"location":"articles/hbasecompactions/#peak-hours","text":"<property> <name> hbase.hstore.compaction.throughput.higher.bound </name> <value> 20971520 </value> <description> The default is 20 MB/sec </description> </property> <property> <name> hbase.hstore.compaction.throughput.lower.bound </name> <value> 10485760 </value> <description> The default is 10 MB/sec </description> </property>","title":"Peak hours"},{"location":"articles/hbasecompactions/#off-peak-hours","text":"<property> <name> hbase.hstore.compaction.throughput.offpeak </name> <value> 9223372036854775807 </value> </property> The default is Long.MAX_VALUE, which effectively means no limitation","title":"Off Peak hours"},{"location":"articles/hdecommissionin/","text":"Decommissioning a DataNode replicated its data to active nodes and gracefully removes is from cluster. If its not done yet, you should add property to hdfs-site.xml and restart NameNode. Configure NameNode <property> <name> dfs.hosts.exclude </name> <value> /etc/hadoop/conf/dfs.exclude </value> <property> To decommission a DataNode: Create a file named /etc/hadoop/conf/dfs.exclude Add the name of each DataNode host to be decommissioned to it(one host per line). Run Command $ hdfs dfsadmin -refreshNodes Monitor the process Now DataNode is marked for decommission and all its blocks are marked as under replicated. You can create or import Hadoop Namenode dashboard and view decommissioning process. Or at NameNode UI to view informatin about decommissioning process. Its will be very informative to create chart for cumulative traffic of datanodes like this below and monitor traffic of all nodes . This chart clearly shows that decommissioning process is started ate 10:38 and not is actively syncing data between nodes. Be Aware Decommission is resource intensive operation , It's recommended to decommission no more than two DataNodes at a time and carefully monitor systems load average during decommission process. Stop Decommissioning If you see that the Sys-Load of DataNodes is getting higher that servers can handle, or have any other reason to stop the decommissioning process : Remove the DataNode name from /etc/hadoop/conf/dfs.exclude. Run the command $ hdfs dfsadmin -refreshNodes","title":"Hdecommissionin"},{"location":"articles/hdecommissionin/#configure-namenode","text":"<property> <name> dfs.hosts.exclude </name> <value> /etc/hadoop/conf/dfs.exclude </value> <property> To decommission a DataNode: Create a file named /etc/hadoop/conf/dfs.exclude Add the name of each DataNode host to be decommissioned to it(one host per line).","title":"Configure NameNode"},{"location":"articles/hdecommissionin/#run-command","text":"$ hdfs dfsadmin -refreshNodes","title":"Run Command"},{"location":"articles/hdecommissionin/#monitor-the-process","text":"Now DataNode is marked for decommission and all its blocks are marked as under replicated. You can create or import Hadoop Namenode dashboard and view decommissioning process. Or at NameNode UI to view informatin about decommissioning process. Its will be very informative to create chart for cumulative traffic of datanodes like this below and monitor traffic of all nodes . This chart clearly shows that decommissioning process is started ate 10:38 and not is actively syncing data between nodes.","title":"Monitor the process"},{"location":"articles/hdecommissionin/#be-aware","text":"Decommission is resource intensive operation , It's recommended to decommission no more than two DataNodes at a time and carefully monitor systems load average during decommission process.","title":"Be Aware"},{"location":"articles/hdecommissionin/#stop-decommissioning","text":"If you see that the Sys-Load of DataNodes is getting higher that servers can handle, or have any other reason to stop the decommissioning process : Remove the DataNode name from /etc/hadoop/conf/dfs.exclude. Run the command $ hdfs dfsadmin -refreshNodes","title":"Stop Decommissioning"},{"location":"articles/hedgedreads/","text":"New feature called Hedged Reads was been introduced in Hadoop 2.4. The main propose of this feature is to help to speed up reads when is takes more time than specified threshold. So if read from block takes longer than desired , HDFS starts another parallel thread for reading data from another block replica. This process is called Hedged Reads .First returned response is used and the outstanding read is cancelled.This feature is not for solving systematic problems, but for situation when some reads occasionally takes a long time. The benefits of Hedged Reads are: Reads on secondary replica Strongly consistent Works at HDFS level By default Hedged Reads are disabled and can be used only when HFiles are stored in HDFS . Following is example of enabling and setting up Hedged Reads in hbase-site.xml , there are no default values as by its desabled by default. Setting Thread pool size for Hedged Reads . <property> <name> dfs.client.hedged.read.threadpool.size </name> <value> 20 </value> </property> In accordance to this configuration HBase HDFS Client will spin up 20 threads to read data from another replica of read block. <property> <name> dfs.client.hedged.read.threshold.millis </name> <value> 10 </value> </property> Here we set desired threshold for reads in milliseconds. So in above example is read takes lokger that 10ms Hedged Reads are started Monitoring the Performance of Hedged Reads Following metrics for monitoring Hedged Reads are emitted by Hadoop at http://$REGIONSERVER:$PORT/jmx . hedgedReadOps : The number of hedged reads that have occurred hedgeReadOpsWin : The number of times the hedged read returned faster than the original read PuyPuy agent will automatically detect if Hedged Reads are enabled and working and these metrics will appear.: hregion_node_hedgedreads hregion_node_hedgedreadwins","title":"Hedgedreads"}]}